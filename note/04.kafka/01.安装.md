# 安装

- 先安装ZK

- 计划

| hadoop102 | hadoop103 | hadoop104 |
| --------- | --------- | --------- |
| zk        | zk        | zk        |
| kafka     | kafka     | kafka     |

- jar包版本
  - kafka_2.11-0.11.0.2.tgz
    - 2.11是scala的版本
    - 0.11.02是kafka版本
- 解压安装，修改名称

```bash
[ttshe@hadoop102 software]$ tar -zvxf kafka_2.11-0.11.0.2.tgz -C /opt/module/
[ttshe@hadoop102 module]$ mv kafka_2.11-0.11.0.2/ kafka
```

- 在/opt/module/kafka目录下创建logs文件夹（保存数据、日志）

```bash
[ttshe@hadoop102 kafka]$ mkdir logs
```



## 配置server.properties

```bash
[ttshe@hadoop102 kafka]$ cd config/
[ttshe@hadoop102 config]$ vi server.properties
```

```bash
#broker的全局唯一编号，不能重复 *** 其他主机需要修改
broker.id=0
#删除topic功能*** 默认false，表示逻辑删除，true表示物理删除
delete.topic.enable=true
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘IO的现成数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接收套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka运行日志存放的路径	 ***
log.dirs=/opt/module/kafka/logs
#topic在当前broker上的分区个数
num.partitions=1
#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment文件保留的最长时间，超时将被删除 ***
log.retention.hours=168
#配置连接Zookeeper集群地址 ***
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181
```

- 配置环境变量
  - 每个主机都要配置一下

```bash
[ttshe@hadoop102 module]$ sudo vi /etc/profile
```

```bash
#KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin
```

```bash
[ttshe@hadoop102 module]$ source /etc/profile
```

- 分发安装包

```bash
[ttshe@hadoop102 module]$ xsync kafka/
```

- 依次修改`server.properties`中的`broker.id`
  - 分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2
  - 注意：broker.id不得重复



# 启动

```bash
[ttshe@hadoop104 kafka]$ bin/kafka-server-start.sh config/server.properties &
```



## ZK群起脚本

- 创建启动脚本
  - 在/home/ttshe/bin下创建zkstart.sh

```bash
#!/bin/bash
for i in ttshe@hadoop102 ttshe@hadoop103 ttshe@hadoop104
do
	echo "================           $i             ================"
	ssh $i '/opt/module/zookeeper-3.4.5/bin/zkServer.sh start'
done
```

- 创建关闭脚本zkstop.sh

```bash
#!/bin/bash
for i in ttshe@hadoop102 ttshe@hadoop103 ttshe@hadoop104
do
	echo "================           $i             ================"
	ssh $i '/opt/module/zookeeper-3.4.5/bin/zkServer.sh stop'
done
```

- 修改权限

```bash
[ttshe@hadoop101 bin]$ chmod 777 zkstart.sh 
[ttshe@hadoop101 bin]$ chmod 777 zkstop.sh 
```



## 启动Kafka集群

- 启动ZK

```bash
[ttshe@hadoop102 zookeeper-3.4.5]$ zkstart.sh
```

- 手动启动kafka集群
  - 依次在hadoop102、hadoop103、hadoop104节点上启动kafka

```bash
[ttshe@hadoop102 kafka]$ bin/kafka-server-start.sh config/server.properties &
[ttshe@hadoop103 kafka]$ bin/kafka-server-start.sh config/server.properties &
[ttshe@hadoop104 kafka]$ bin/kafka-server-start.sh config/server.properties &
```

- 手动关闭kafka集群

```bash
[ttshe@hadoop102 kafka]$ bin/kafka-server-stop.sh stop
[ttshe@hadoop103 kafka]$ bin/kafka-server-stop.sh stop
[ttshe@hadoop104 kafka]$ bin/kafka-server-stop.sh stop
```



## Kafka群起脚本

- 在/home/ttshe/bin下创建kkstart.sh

```bash
#!/bin/bash
for i in ttshe@hadoop102 ttshe@hadoop103 ttshe@hadoop104
do
        echo "================           $i             ================"
        ssh $i '/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties'
done
```

- 在/home/ttshe/bin下创建kkstop.sh

```bash
#!/bin/bash
for i in ttshe@hadoop102 ttshe@hadoop103 ttshe@hadoop104
do
        echo "================           $i             ================"
        ssh $i '/opt/module/kafka/bin/kafka-server-stop.sh /opt/module/kafka/config/server.properties'
done
```

- 设置权限

```bash
[ttshe@hadoop102 bin]$ chmod 777 kkstart.sh 
[ttshe@hadoop102 bin]$ chmod 777 kkstop.sh
```

- 写法2

```bash
#!/bin/bash

case $1 in
"start"){
	for i in hadoop102 hadoop103 hadoop104
    do
    	echo " --------启动 $i Kafka-------"
        # 用于KafkaManager监控
        ssh $i "export JMX_PORT=9988 && /opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties "
    done
};;
"stop"){
	for i in hadoop102 hadoop103 hadoop104
    do
    	echo " --------停止 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"
    done
};;
esac
```

- 启动Kafka时要先开启JMX端口，是用于后续KafkaManager监控
- -daemon 表示后台执行
- kafka依赖zk的启动，那么zk启动之后才能启动kafka
  - kafka的状态信息保存在zk中

