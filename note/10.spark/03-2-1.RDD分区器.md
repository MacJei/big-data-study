# key-value型 RDD 数据分区器

- Spark目前支持
  - Hash分区
    - 默认
  - Range分区
  - 自定义分区
- 分区器决定
  - RDD中分区的个数
  - RDD中每条数据经过Shuffle过程属于哪个分区
  - Reduce的个数
- ==注意==
  - Key-Value类型的RDD才有分区器的
  - 非Key-Value类型的RDD分区器的值是None
  - 每个RDD的分区ID范围
    - 0~numPartitions-1
    - 决定这个值是属于哪个分区



## 获取分区器

```scala
scala> var rdd = sc.makeRDD(Array(("a",1),("b",2),("c",3),("d",4)))
rdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[22] at makeRDD at <console>:25
// 非key-Value的默认分区器是None
scala> rdd.partitioner
res0: Option[org.apache.spark.Partitioner] = None

// 默认8个分区，cpu是8核
scala> rdd.glom.collect
res1: Array[Array[(String, Int)]] = Array(Array(), Array((a,1)), Array(), Array((b,2)), Array(), Array((c,3)), Array(), Array((d,4)))

// 导入HashPartitioner
scala> import org.apache.spark.HashPartitioner
scala> var rdd2 = rdd.partitionBy(new HashPartitioner(2))

scala> rdd2.partitioner
res2: Option[org.apache.spark.Partitioner] = Some(org.apache.spark.HashPartitioner@2)

scala> rdd2.glom.collect
res3: Array[Array[(String, Int)]] = Array(Array((b,2), (d,4)), Array((a,1), (c,3)))
```



## Hash分区器

- HashPartitioner分区的原理
  - 对于给定的key，计算其hashCode除以分区的个数取余
    - 如果余数小于0，则用余数+分区的个数
      - 否则加0
    - 最后返回该key所属的分区ID

```scala
// Partitioner.scala
class HashPartitioner(partitions: Int) extends Partitioner {
    require(partitions >= 0, s"Number of partitions ($partitions) cannot be negative.")

    def numPartitions: Int = partitions

    def getPartition(key: Any): Int = key match {
        case null => 0
        // hashMap中使用hashCode进行&运算
        // 其他的一般使用%运算
        // 2的n次方分区，使用&，而其他分区，如3,5则使用%
        // redis的slot就是16384，可以使用&进行计算
        case _ => Utils.nonNegativeMod(key.hashCode, numPartitions)
    }

    override def equals(other: Any): Boolean = other match {
        case h: HashPartitioner =>
        h.numPartitions == numPartitions
        case _ =>
        false
    }
    override def hashCode: Int = numPartitions
}

def nonNegativeMod(x: Int, mod: Int): Int = {
    val rawMod = x % mod
    rawMod + (if (rawMod < 0) mod else 0)
}
```



## Ranger分区器

- 预设分区范围，类似HBase中的预设分区
  - key要求可以进行比较
  - 如是一个对象，使用比较少
- HashPartitioner分区弊端
  - 热点数据的可能
  - 可能导致每个分区中数据量的不均匀
  - 极端情况下会导致某些分区拥有RDD的全部数据
- RangePartitioner作用
  - 将一定范围内的数映射到某一个分区内，尽量保证每个分区中数据量的均匀
  - 分区与分区之间是有序的
  - 分区内的数据不一定有序
  - 一个分区中的元素肯定都是比另一个分区内的元素小或者大
  - 将一定范围内的数映射到某一个分区内
- 实现过程
  - 先重整个RDD中抽取出样本数据，将样本数据排序，计算出每个分区的最大key值，形成一个Array[KEY]类型的数组变量rangeBounds
  - 判断key在rangeBounds中所处的范围，给出该key值在下一个RDD中的分区id下标
  - 该分区器要求RDD中的KEY类型必须是可以排序的



## 自定义分区器

- 实现自定义的分区器要继承 org.apache.spark.Partitioner 类并实现
  - numPartitions: Int
    - 返回创建出来的分区数
  - getPartition(key: Any): Int
    - 返回给定键的分区编号(0到numPartitions-1)
  - equals():Java
    - 判断相等性的标准方法
    - 这个方法的实现非常重要，Spark 需要用这个方法来检查你的分区器对象是否和其他分区器实例相同，这样 Spark 才可以判断两个 RDD 的分区方式是否相同
- 需求
  - 将相同后缀的数据写入相同的文件
  - 通过将相同后缀的数据分区到相同的分区并保存输出来实现

```scala
package com.stt.spark

import org.apache.spark.{Partitioner, SparkConf, SparkContext}

object Ch05_SelfPartitioner {
    def main(args: Array[String]): Unit = {
        val conf: SparkConf = new SparkConf().setAppName("serial").setMaster("local[*]")
        val sc: SparkContext = new SparkContext(conf)

        val rdd = sc.makeRDD(Array(("aac",1),("bb",2),("cc",3)))
        //    (7,(bb,2))
        //    (11,(cc,3))
        //    (3,(aac,1))
        rdd.mapPartitionsWithIndex((index,items)=>{items.map(item=>(index,item))}).foreach(println)

        val rdd2 = rdd.partitionBy(new CustomerPartitioner(2))
        //    (1,(aac,1))
        //    (0,(bb,2))
        //    (1,(cc,3))
        rdd2.mapPartitionsWithIndex((index,items)=>{items.map(item=>(index,item))}).foreach(println)

        sc.stop()
    }
}

class CustomerPartitioner(numPartition: Int) extends Partitioner{
    override def numPartitions: Int = numPartition

    override def getPartition(key: Any): Int = {
        // 取得最后一个字符进行分区
        key.toString.last.toInt%numPartitions
    }
}
```

- 使用自定义的Partitioner 是很容易
  - 把它传给 partitionBy() 方法
  - Spark 中有许多依赖于数据混洗的方法
    - 如 join() 和 groupByKey()
      - 可接收一个可选的 Partitioner 对象来控制输出数据的分区方式