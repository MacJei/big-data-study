# 数据说明

- 数据集是货品交易数据集
- 每个订单可能包含多个货品
- 每个订单可以产生多次交易，不同的货品有不同的单价
- tbStockDetail 的 ordernumber和itemid构成唯一键，相同订单号的tbStockDetail有多个
  - 同一订单号有多个itemid
  - 同一个ordernumber 对应一个tbStock
  - amount 是该订单ordernumber的该商品itemid的销售额，而非整个订单ordernumber的销售额

<img src="img/79.png" style="zoom:120%;" /> 



# 加载数据

- tbStock

```scala
scala> case class tbStock(ordernumber:String,locationid:String,dateid:String) extends Serializable
defined class tbStock

scala> val tbStockRdd = spark.sparkContext.textFile("/opt/software/data/tbStock.txt")
tbStockRdd: org.apache.spark.rdd.RDD[String] = tbStock.txt MapPartitionsRDD[1] at textFile at <console>:23

scala> val tbStockDS = tbStockRdd.map(_.split(",")).map(attr=>tbStock(attr(0),attr(1),attr(2))).toDS
tbStockDS: org.apache.spark.sql.Dataset[tbStock] = [ordernumber: string, locationid: string ... 1 more field]

scala> tbStockDS.show()
+------------+----------+---------+
| ordernumber|locationid|   dateid|
+------------+----------+---------+
|BYSL00000893|      ZHAO|2007-8-23|
|BYSL00000897|      ZHAO|2007-8-24|
...
+------------+----------+---------+
only showing top 20 rows
```

- tbStockDetail
  - 一个订单有多个商品

```scala
scala> case class tbStockDetail(ordernumber:String, rownum:Int, itemid:String, number:Int, price:Double, amount:Double) extends Serializable
defined class tbStockDetail

scala> val tbStockDetailRdd = spark.sparkContext.textFile("/opt/software/data/tbStockDetail.txt")
tbStockDetailRdd: org.apache.spark.rdd.RDD[String] = tbStockDetail.txt MapPartitionsRDD[13] at textFile at <console>:23

scala> val tbStockDetailDS = tbStockDetailRdd.map(_.split(",")).map(attr=> tbStockDetail(attr(0),attr(1).trim().toInt,attr(2),attr(3).trim().toInt,attr(4).trim().toDouble, attr(5).trim().toDouble)).toDS
tbStockDetailDS: org.apache.spark.sql.Dataset[tbStockDetail] = [ordernumber: string, rownum: int ... 4 more fields]

scala> tbStockDetailDS.show()
+------------+------+--------------+------+-----+------+
| ordernumber|rownum|        itemid|number|price|amount|
+------------+------+--------------+------+-----+------+
|BYSL00000893|     0|FS527258160501|    -1|268.0|-268.0|
...
|BYSL00000897|    10|FS527258160501|     1|198.0| 198.0|
|BYSL00000897|    11|ST040000010000|    13|  0.0|   0.0|
+------------+------+--------------+------+-----+------+
only showing top 20 rows
```

- tbDate

```scala
scala> case class tbDate(dateid:String, years:Int, theyear:Int, month:Int, day:Int, weekday:Int, week:Int, quarter:Int, period:Int, halfmonth:Int) extends Serializable

scala> val tbDateRdd = spark.sparkContext.textFile("/opt/software/data/tbDate.txt")

scala> val tbDateDS = tbDateRdd.map(_.split(",")).map(attr=> tbDate(attr(0),attr(1).trim().toInt, attr(2).trim().toInt,attr(3).trim().toInt, attr(4).trim().toInt, attr(5).trim().toInt, attr(6).trim().toInt, attr(7).trim().toInt, attr(8).trim().toInt, attr(9).trim().toInt)).toDS

scala> tbDateDS.show()
+---------+------+-------+-----+---+-------+----+-------+------+---------+
|   dateid| years|theyear|month|day|weekday|week|quarter|period|halfmonth|
+---------+------+-------+-----+---+-------+----+-------+------+---------+
| 2003-1-1|200301|   2003|    1|  1|      3|   1|      1|     1|        1|
...
|2003-1-19|200301|   2003|    1| 19|      7|   3|      1|     2|        2|
|2003-1-20|200301|   2003|    1| 20|      1|   4|      1|     2|        2|
+---------+------+-------+-----+---+-------+----+-------+------+---------+
only showing top 20 rows
```



## 创建视图

```scala
tbStockDS.createOrReplaceTempView("tbStock")
tbDateDS.createOrReplaceTempView("tbDate")
tbStockDetailDS.createOrReplaceTempView("tbStockDetail")
```



# 计算所有订单中每年的销售单数、销售总额

统计所有订单中每年的销售单数、销售总额

三个表连接后以count(distinct a.ordernumber)计销售单数，sum(b.amount)计销售总额

- 一个订单有多个商品，需要去重

```scala
select d.theyear,sum(sd.amount),count(distinct sd.ordernumber)
from 
	tbStockDetail sd
join tbStock s on sd.ordernumber = s.ordernumber
join tbDate d on s.dateid = d.dateid
group by d.theyear 
order by d.theyear

spark.sql("select d.theyear,sum(sd.amount),count(distinct sd.ordernumber) from tbStockDetail sd join tbStock s on sd.ordernumber = s.ordernumber join tbDate d on s.dateid = d.dateid group by d.theyear order by d.theyear").show
```



# 计算所有订单中每年最大金额订单的销售总额

- 统计每年，每个订单一共有多少销售额
- 以上一步查询结果为基础表，和表tbDate使用dateid join，求出每年最大金额订单的销售额

```scala
select d.theyear, max(t.sumOfAmount)
from(
    select s.dateid, sd.ordernumber, sum(sd.amount) as sumOfAmount
    from 
        tbStockDetail sd
    join tbStock s on sd.ordernumber = s.ordernumber
    group by sd.ordernumber,s.dateid
) t 
join tbDate d on t.dateid = d.dateid
group by d.theyear 
order by d.theyear desc


spark.sql("select s.dateid, sd.ordernumber, sum(sd.amount) as sumOfAmount from tbStockDetail sd join tbStock s on sd.ordernumber = s.ordernumber group by sd.ordernumber,s.dateid").show

spark.sql("select d.theyear, max(t.sumOfAmount) from( select s.dateid, sd.ordernumber, sum(sd.amount) as sumOfAmount from tbStockDetail sd join tbStock s on sd.ordernumber = s.ordernumber group by sd.ordernumber,s.dateid) t join tbDate d on t.dateid = d.dateid group by d.theyear order by d.theyear desc").show
```



# 计算所有订单中每年最畅销货品

- 统计每年最畅销货品（哪个货品销售额amount在当年最高，哪个就是最畅销货品）

```scala
select t.theyear,t.itemid, max(t.sumOfAmount)
from(
    select sd.itemid, d.theyear,sum(sd.amount) as sumOfAmount
    from 
        tbStockDetail sd
    join tbStock s on sd.ordernumber = s.ordernumber
    join tbDate d on s.dateid = d.dateid
    group by sd.itemid, d.theyear
) t 
group by d.theyear 
order by t.theyear desc
```



