# 概述

- 减少底层存储系统HDFS读写字节数
- 提高网络带宽和磁盘空间
- 提高Hadoop运行效率的一种优化**策略**
- 针对运行MR程序时，IO操作，网络传输，Shuffe和Merge需要耗费大量时间
  - 数据规模大，工作负载密集的情况下使用数据压缩
- 可以在MapReduce的任意阶段启用压缩
- 压缩和解压操作CPU开销不大
- **压缩基本原则**：
  - 运算密集型job，少用压缩
  - IO密集型job，多用压缩



# 压缩编码



## 编码种类

| 压缩格式   | hadoop自带？ | 算法    | 文件扩展名 | 是否可切分 | 换成压缩格式后，原来的程序是否需要修改 |
| ---------- | ------------ | ------- | ---------- | ---------- | -------------------------------------- |
| DEFLATE    | 是           | DEFLATE | .deflate   | 否         | 和文本处理一样，不需要修改             |
| Gzip       | 是           | DEFLATE | .gz        | 否         | 和文本处理一样，不需要修改             |
| bzip2      | 是           | bzip2   | .bz2       | ==是==     | 和文本处理一样，不需要修改             |
| **LZO**    | 需要安装     | LZO     | .lzo       | ==是==     | **需要建索引**，还需要指定输入格式     |
| **Snappy** | 需要安装     | Snappy  | .snappy    | 否         | 和文本处理一样，不需要修改             |



## 编码器/解码器

| 压缩格式 | 对应的编码/解码器                          |
| -------- | ------------------------------------------ |
| DEFLATE  | org.apache.hadoop.io.compress.DefaultCodec |
| gzip     | org.apache.hadoop.io.compress.GzipCodec    |
| bzip2    | org.apache.hadoop.io.compress.BZip2Codec   |
| LZO      | com.hadoop.compression.lzo.LzopCodec       |
| Snappy   | org.apache.hadoop.io.compress.SnappyCodec  |



## 性能比较

| 压缩算法 | 原始文件大小 | 压缩文件大小 | 压缩速度 | 解压速度 |
| -------- | ------------ | ------------ | -------- | -------- |
| gzip     | 8.3GB        | 1.8GB        | 17.5MB/s | 58MB/s   |
| bzip2    | 8.3GB        | 1.1GB        | 2.4MB/s  | 9.5MB/s  |
| LZO      | 8.3GB        | 2.9GB        | 49.3MB/s | 74.6MB/s |

- Snappy 
  - <http://google.github.io/snappy/>
  - On a single core of a Core i7 processor in 64-bit mode
  -  Snappy compresses at about **250 MB**/sec or more and decompresses at about **500 MB/sec** or more
  - 压缩和解压速度最快



# 压缩方式选择



## Gzip

- 优点
  - 压缩率比较高
  - 解压、压缩速度比较快
  - Hadoop自带支持
    - 在处理Gzip格式的文件与直接处理文本一致
  - Linux系统也自带Gzip命令
- 缺点
  - 不支持Split
- 应用场景
  - 每个文件压缩之后在130M以内，1个block大小，那么可以考虑使用
  - 如日志文件，一个小时或者一天的日志压缩成一个130M的Gzip文件



## Bzip2

- 优点

  - 支持Split
  - 具有最高压缩率
  - Hadoop自带支持

- 缺点

  - 压缩/解压时间长

- 应用场景

  - 适合对速度要求不高
  - 要求压缩率高的场景
  - 输出之后的数据比较大，处理之后数据要压缩存档减少磁盘空间并且以后使用较少
  - 单个很大文件要压缩很小的空间，同时又要支持split
  - 不考虑压缩、解压时间的场景

  

## LZO

- 优点
  - 压缩，解压速度快
  - 压缩率合理
  - 支持split
  - Hadoop中流行
  - 可以在Linux下安装lzop命令
- 缺点
  - 压缩率比Gzip低
  - 需要安装
  - 支持split，但是需要建立索引，指定InputFormat为Lzo格式
- 应用场景
  - 大文本文件，压缩之后依然大于200M以上
  - 单个文件越大，Lzo的优势明显



## Snappy

- 优点
  - 压缩，解压速度最高
  - 压缩率合理
- 缺点
  - 不支持Split
  - 压缩率低于Gzip
  - Hadoop不支持，需要安装
- 应用场景
  - Map端输出数据较大，作为Map到Reduce中间数据的压缩格式
  - 作为一个MapReduce的job输出给另一个MapReduce的job的输入



# 压缩位置选择

- 压缩可以在MapReduce的任意阶段使用

- Map前阶段

  - 输入端采用压缩
    - 在大量数据并计划复杂处理器的情况下
    - 对数据进行压缩
    - Hadoop==自动检查文件扩展名==
      - ==如果扩展名匹配就会自动识别编码方式==
      - 对文件进行压缩和解压缩
      - 如果识别不出，不会使用任何编解码器

- Map->Reduce阶段

  - Mapper输出采用压缩

    - 当Map的任务输出的中间数据量很大，考虑在此阶段采用压缩技术

    - 可以改善内部数据的Shuffe过程

    - 在此阶段可以使用**LZO**或者**Snappy**

      - LZO 

        - 设计目标是达到和磁盘读取速度相当的压缩速度
        - **压缩/解压速度**是优先考虑
        - 压缩速度是Gzip的5倍
        - 解压速度是Gzip的2倍
        - Map阶段完成时间可以提升4倍

        

- Reduce

  - Reducer输出采用压缩
    - 减少要存储的数据量
    - 降低所需的磁盘空间
    - 当MapReduce的job形成链，输入的是压缩的文件，也会进行解压操作，启用压缩的配置也会生效



# 压缩参数配置

要在Hadoop中启用压缩，可以配置如下参数：

| 参数                                                         | 默认值                                                       | 阶段        | 建议                                          |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- | --------------------------------------------- |
| io.compression.codecs（在core-site.xml中配置）               | org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec | 输入压缩    | Hadoop使用文件扩展名判断是否支持某种编解码器  |
| mapreduce.map.output.compress（在mapred-site.xml中配置）     | false                                                        | mapper输出  | 这个参数设为true启用压缩                      |
| mapreduce.map.output.compress.codec（在mapred-site.xml中配置） | org.apache.hadoop.io.compress.DefaultCodec                   | mapper输出  | 企业多使用LZO或Snappy编解码器在此阶段压缩数据 |
| mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置） | false                                                        | reducer输出 | 这个参数设为true启用压缩                      |
| mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置） | org.apache.hadoop.io.compress. DefaultCodec                  | reducer输出 | 使用标准工具或者编解码器，如gzip和bzip2       |
| mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置） | RECORD                                                       | reducer输出 | SequenceFile输出使用的压缩类型：NONE和BLOCK   |



# 示例



## 数据流压缩-解压

- CompressionCodec
  - 压缩
    - createOutputStream(OutputStream)
  - 解压
    - createInputStream(InputStream)

- 参数

| 格式    | 参数                                       |
| ------- | ------------------------------------------ |
| DEFLATE | org.apache.hadoop.io.compress.DefaultCodec |
| gzip    | org.apache.hadoop.io.compress.GzipCodec    |
| bzip2   | org.apache.hadoop.io.compress.BZip2Codec   |

- 代码

```java
package com.stt.demo.mr.Ch15_compress;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionCodecFactory;
import org.apache.hadoop.io.compress.CompressionInputStream;
import org.apache.hadoop.io.compress.CompressionOutputStream;
import org.apache.hadoop.util.ReflectionUtils;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.util.Objects;

import static com.stt.demo.mr.Constant.INPUT;

public class TestCompress {

	public static void main(String[] args) throws Exception {

		//org.apache.hadoop.io.compress.DefaultCodec
		//org.apache.hadoop.io.compress.GzipCodec
		//org.apache.hadoop.io.compress.BZip2Codec
		compress(INPUT+"ch15/input.txt","org.apache.hadoop.io.compress.BZip2Codec");
		decompress(INPUT+"ch15/input.txt.bz2");
	}
	
	// 压缩
	private static void compress(String fileName,String className) throws Exception {

		FileInputStream fis = new FileInputStream(new File(fileName));

		CompressionCodec codec = (CompressionCodec) ReflectionUtils
				.newInstance(Class.forName(className),new Configuration());

		CompressionOutputStream cos = codec.createOutputStream(
				new FileOutputStream(
						new File(fileName+codec.getDefaultExtension())));
		// 流的对拷
		IOUtils.copyBytes(fis,cos,1024*1024,false);

		fis.close();
		cos.close();
	}

	// 解压
	private static void decompress(String fileName) throws Exception {
		// 校验是否可以解压缩
		CompressionCodecFactory factory = new CompressionCodecFactory(new Configuration());
		CompressionCodec codec = factory.getCodec(new Path(fileName));

		if(Objects.isNull(codec)){
			System.out.println("cannot find codec for file:"+fileName);
			return;
		}
		// 获取输入流
		CompressionInputStream cis = codec.createInputStream(new FileInputStream(new File(fileName)));

		FileOutputStream fos = new FileOutputStream(new File(fileName+".decoded"));

		IOUtils.copyBytes(cis,fos,1024*1024,false);

		cis.close();
		fos.close();
	}
}
```



## Map端输出采用压缩

- 对Map的中间结果进行压缩处理
- 压缩后的文件通过网络传递给Reduce节点
- 在WordCount示例中进行修改

- 主要对Driver进行修改

```java
package com.stt.demo.mr.Ch15_Compress;

import com.stt.demo.mr.Ch01_WordCount.WordCountMapper;
import com.stt.demo.mr.Ch01_WordCount.WordCountReducer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.compress.BZip2Codec;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

import static com.stt.demo.mr.Constant.INPUT;
import static com.stt.demo.mr.Constant.OUTPUT;


public class WordCountDriver {

	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

		args = new String[]{INPUT+"ch15/wordcount.txt", OUTPUT+"ch15/output"};

		Configuration conf = new Configuration();
		// 开启map端输出压缩
		conf.setBoolean("mapreduce.map.output.compress", true);
		// 设置map端输出压缩方式 BZip2Codec 
        // 如果没有setClass，那么默认是DefaultCodec
		conf.setClass("mapreduce.map.output.compress.codec", BZip2Codec.class, CompressionCodec.class);
		Job job = Job.getInstance(conf);
		job.setJarByClass(WordCountDriver.class);
		job.setMapperClass(WordCountMapper.class);
		job.setReducerClass(WordCountReducer.class);
		job.setMapOutputKeyClass(Text.class);
		job.setMapOutputValueClass(IntWritable.class);
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
        
		FileInputFormat.setInputPaths(job,new Path(args[0]));
		FileOutputFormat.setOutputPath(job,new Path(args[1]));
		boolean result = job.waitForCompletion(true);
		System.exit(result ? 0 : 1);
	}
}
```



## Reduce端输出采用压缩

- 修改Driver

```java
package com.stt.demo.mr.Ch15_Compress;

import com.stt.demo.mr.Ch01_WordCount.WordCountMapper;
import com.stt.demo.mr.Ch01_WordCount.WordCountReducer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.compress.BZip2Codec;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

import static com.stt.demo.mr.Constant.INPUT;
import static com.stt.demo.mr.Constant.OUTPUT;

public class WordCountDriverReduceCompress {

	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

		args = new String[]{INPUT+"ch15/wordcount.txt", OUTPUT+"ch15/output"};
		Configuration conf = new Configuration();

		Job job = Job.getInstance(conf);
		job.setJarByClass(WordCountDriverReduceCompress.class);
		job.setMapperClass(WordCountMapper.class);
		job.setReducerClass(WordCountReducer.class);
		job.setMapOutputKeyClass(Text.class);
		job.setMapOutputValueClass(IntWritable.class);
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);

		FileInputFormat.setInputPaths(job,new Path(args[0]));
		FileOutputFormat.setOutputPath(job,new Path(args[1]));

		// 设置reduce端输出压缩开启
		FileOutputFormat.setCompressOutput(job, true);
		// 设置压缩的方式
		FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);

		boolean result = job.waitForCompletion(true);
		System.exit(result ? 0 : 1);
	}
}
```

