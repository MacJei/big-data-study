# 基本操作



## 启动 `hive`

```bash
[ttshe@hadoop102 hive]$ bin/hive

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> 
```



## 查看数据库 `show databases;`

```sql
hive> show databases;
OK
default
Time taken: 0.18 seconds, Fetched: 1 row(s)
```



## 打开数据库 `use xxx;`

```sql
hive> use default;
OK
Time taken: 0.022 seconds
```



## 显示数据库的表 `show tables;`

```sql
hive> show tables;
OK
Time taken: 0.029 seconds
```



## 创建表 `create table ...`

```sql
hive> create table student(
    > id int,
    > name string
    > );
OK
Time taken: 0.246 seconds

hive> show tables;
OK
student
Time taken: 0.019 seconds, Fetched: 1 row(s)
```



## 查看表结构 `desc xxx;`

```sql
hive> desc student;
OK
id                  	int                 	                    
name                	string              	                    
Time taken: 0.184 seconds, Fetched: 2 row(s)
```



## 插入数据 `insert into ...`

```sql
hive> insert into student values(1000,"stt");
Query ID = ttshe_20190830191515_6a853ec5-d83b-48cf-9e2e-869ddd7ae9fa
Total jobs = 3
Launching Job 1 out of 3
...
```

- 插入数据就是对HDFS进行操作
- 执行了相应的job
- 文件夹的名称就是表名

![1](img/4.png)



## 查询表中的数据 `select ...`

```sql
hive> select * from student;
OK
1000	stt
Time taken: 0.058 seconds, Fetched: 1 row(s)
```



## 删除表 `drop table xxx;`

```sql
drop table student;
```



## 退出

```bash
hive> quit;
```



## 将本地文件导入Hive

- 将本地/opt/module/datas/student.txt目录下的数据导入到hive的student(id int, name string)表中
- 创建数据
  - 注意使用 tab `\t` 进行分割

```bash
1001	zhangshan
1002	lishi
1003	zhaoliu
```

- 执行导入

```sql
[ttshe@hadoop102 hive]$ bin/hive
hive> use default;

hive> load data local inpath '/opt/module/datas/student.txt' into table student;
Loading data to table default.student
Table default.student stats: [numFiles=2, numRows=0, totalSize=48, rawDataSize=0]
OK
Time taken: 0.545 seconds
```

![1](img/5.png)

- 查询
  - 由于建表的时候没有定义分割符，因此查询是null

```sql
hive> select * from student;
OK
1000	stt
NULL	NULL
NULL	NULL
NULL	NULL
Time taken: 0.291 seconds, Fetched: 4 row(s)
```



### 正确操作

- 删除表，重新建表导入

```sql
hive> drop table student;
OK
Time taken: 0.471 seconds
hive> create table student(
    > id int,
    > name string
    > )
    > row format delimited fields terminated by '\t';
OK
Time taken: 0.079 seconds
```

```sql
hive> load data local inpath '/opt/module/datas/student.txt' into table student;

Loading data to table default.student
Table default.student stats: [numFiles=1, totalSize=39]
OK
Time taken: 0.115 seconds
```

```sql
hive> select * from student;
OK
1001	zhangshan
1002	lishi
1003	zhaoliu
Time taken: 0.032 seconds, Fetched: 3 row(s)
```



# 常用交互命令



## 查看帮助

- `-help` 命令

```bash
[ttshe@hadoop102 hive]$ bin/hive -help
usage: hive
 -d,--define <key=value>          Variable subsitution to apply to hive
                                  commands. e.g. -d A=B or --define A=B
    --database <databasename>     Specify the database to use
 -e <quoted-query-string>         SQL from command line
 -f <filename>                    SQL from files
 -H,--help                        Print help information
    --hiveconf <property=value>   Use value for given property
    --hivevar <key=value>         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar A=B
 -i <filename>                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the
                                  console)
```



## 执行sql语句

- 不进入hive的交互窗口执行sql语句
- `-e`
- ==默认是default库，如果有其他库，则使用xxx.yyy的方式访问==

```bash
[ttshe@hadoop102 hive]$ bin/hive -e "select * from default.student;"

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
1001	zhangshan
1002	lishi
1003	zhaoliu
1001	zhangshan
1002	lishi
1003	zhaoliu
Time taken: 1.098 seconds, Fetched: 6 row(s)
```



## 执行sql脚本

- 执行脚本中sql语句

- `-f`  命令

  - 在/opt/module/datas目录下创建hive.sql文件

  ```sql
  select *from student;
  ```

  - 执行文件中的sql语句

  ```bash
  [ttshe@hadoop102 hive]$ bin/hive -f /opt/module/datas/hive.sql 
  ```

  - 执行文件中的sql语句并将结果写入文件中

  ```bash
  [ttshe@hadoop102 hive]$ bin/hive -f /opt/module/datas/hive.sql > /opt/module/datas/hive_result.txt
  ```



## 关于退出

```bash
hive(default)>exit;
hive(default)>quit;
```

- 新版的hive中没区别
- 旧版本版本中
  - exit
    - 先隐性提交数据，再退出
  - quit
    - 不提交数据，退出



## 执行HDFS命令

```bash
hive (default)> dfs -ls /user;
Found 1 items
drwxr-xr-x   - ttshe supergroup          0 2019-08-30 19:02 /user/hive
```



## 执行Linux命令

- 添加 `!` 执行
  - 注意与HiveJDBC的执行的区别，这里要添加 `;`

```bash
hive (default)> ! cat /etc/profile;
```



## 查看操作历史

- 进入到当前用户的根目录/root或/home/atguigu
- 查看`. hivehistory`文件

```bash
[ttshe@hadoop102 ~]$ cat /home/ttshe/.hivehistory
```



# HiveJDBC访问

> 使用基于JDBC的客户端执行操作
> 等价于使用JDBC实现了CLI的功能操作



关于连接方式

![hive的连接方式](img/7.png)



## 启动 hiveserver2服务

- 启动后占用控制台
  - 服务端口10000
  - 可以看到操作日志
  - 如果想在后台运行，添加 `&`

```bash
[ttshe@hadoop102 hive]$ bin/hiveserver2
```



## 启动 beeline 客户端

```bash
[ttshe@hadoop102 hive]$ bin/beeline
Beeline version 1.2.1 by Apache Hive
beeline> 
```



## 连接 hiveserver2

- `!connect`
  - 注意用户名是当前系统登录用户

```bash
beeline> !connect jdbc:hive2://hadoop102:10000
Connecting to jdbc:hive2://hadoop102:10000
Enter username for jdbc:hive2://hadoop102:10000: ttshe # 回车
Enter password for jdbc:hive2://hadoop102:10000: # 直接回车
Connected to: Apache Hive (version 1.2.1)
Driver: Hive JDBC (version 1.2.1)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://hadoop102:10000> 
```



## 查看帮助

- `!help` 打印所有命令

```bash
0: jdbc:hive2://hadoop102:10000> !help
!addlocaldriverjar  Add driver jar file in the beeline client side.
!addlocaldrivername Add driver name that needs to be supported in the beeline
                    client side.
!all                Execute the specified SQL against all the current connections
!autocommit         Set autocommit mode on or off
!batch              Start or execute a batch of statements
!brief              Set verbose mode off
!call               Execute a callable statement
!close              Close the current connection to the database
!closeall           Close all current open connections
!columns            List all the columns for the specified table
!commit             Commit the current transaction (if autocommit is off)
!connect            Open a new connection to the database.
!dbinfo             Give metadata information about the database
!describe           Describe a table
!dropall            Drop all tables in the current database
!exportedkeys       List all the exported keys for the specified table
!go                 Select the current connection
!help               Print a summary of command usage
!history            Display the command history
!importedkeys       List all the imported keys for the specified table
!indexes            List all the indexes for the specified table
!isolation          Set the transaction isolation for this connection
!list               List the current connections
!manual             Display the BeeLine manual
!metadata           Obtain metadata information
!nativesql          Show the native SQL for the specified statement
!nullemptystring    Set to true to get historic behavior of printing null as
                    empty string. Default is false.
!outputformat       Set the output format for displaying results
                    (table,vertical,csv2,dsv,tsv2,xmlattrs,xmlelements, and
                    deprecated formats(csv, tsv))
!primarykeys        List all the primary keys for the specified table
!procedures         List all the procedures
!properties         Connect to the database specified in the properties file(s)
!quit               Exits the program
!reconnect          Reconnect to the database
!record             Record all output to the specified file
!rehash             Fetch table and column names for command completion
!rollback           Roll back the current transaction (if autocommit is off)
!run                Run a script from the specified file
!save               Save the current variabes and aliases
!scan               Scan for installed JDBC drivers
!script             Start saving a script to a file
!set                Set a beeline variable
!sh                 Execute a shell command
!sql                Execute a SQL command
!tables             List all the tables in the database
!typeinfo           Display the type map for the current connection
!verbose            Set verbose mode on
```



## 查看数据库

- 查看当前hive中的数据库

```bash
0: jdbc:hive2://hadoop102:10000> show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
+----------------+--+
1 row selected (0.906 seconds)
```



## 执行linux命令

- 使用`!sh` 可以执行linux的命令

```bash
0: jdbc:hive2://hadoop102:10000> !sh ls -al /
总用量 110
dr-xr-xr-x.  25 root root  4096 4月  21 09:55 .
dr-xr-xr-x.  25 root root  4096 4月  21 09:55 ..
-rw-r--r--.   1 root root     0 4月  21 09:55 .autofsck
dr-xr-xr-x.   2 root root  4096 3月  30 10:25 bin
...
```





# 常见属性配置



## 数据仓库位置配置

- `default`数据仓库的最原始位置是在hdfs上
  - `/user/hive/warehouse`
- 在仓库目录下
  - 没有对默认的数据库default创建文件夹
  - ==若某张表属于`default`数据库，直接在数据仓库目录`warehouse`下创建一个文件夹==
- 修改`default`数据仓库原始位置
  - 将hive-default.xml.template 如下配置信息拷贝到hive-site.xml文件中进行覆盖

```xml
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
</property>
```

- 注意配置同组用户有执行权限

```bash
bin/hdfs dfs -chmod g+w /user/hive/warehouse
```



## 查询信息显示配置

- 在hive-site.xml文件中添加配置信息
  - 实现显示当前数据库
  - 查询表的头信息配置

```xml
<property>
	<name>hive.cli.print.header</name>
	<value>true</value>
</property>

<property>
	<name>hive.cli.print.current.db</name>
	<value>true</value>
</property>
```

- 重新启动hive，对比配置前后差异
  - 显示了当前的数据库
  - 显示了表的列名称

```bash
hive (default)> select * from student;
OK
student.id	student.name
1001	zhangshan
1002	lishi
1003	zhaoliu
1001	zhangshan
1002	lishi
1003	zhaoliu
Time taken: 0.867 seconds, Fetched: 6 row(s)
```



## 日志位置配置

- Hive的log默认存放在/tmp/ttshe/hive.log目录下

  - 当前用户名下

- 修改hive的log存放日志到/opt/module/hive/logs

  - 修改/opt/module/hive/conf/hive-log4j.properties.template文件名称为

    hive-log4j.properties

  ```bash
  [ttshe@hadoop102 conf]$ pwd
  /opt/module/hive/conf
  [ttshe@hadoop102 conf]$ cp hive-log4j.properties.template hive-log4j.properties
  ```

  - 在hive-log4j.properties文件中修改log存放位置

  ```bash
  hive.log.dir=/opt/module/hive/logs
  ```



## 参数配置方式

- 查看当前所有的配置信息

```bash
hive (default)> set;
```



### 配置文件方式

- 默认配置文件：hive-default.xml 
- 用户自定义配置文件：hive-site.xml
- 用户自定义配置会覆盖默认配置
- Hive也会读入Hadoop的配置
  - Hive是作为Hadoop的客户端启动的
  - Hive的配置会覆盖Hadoop的配置
- 配置文件的设定对本机启动的所有Hive进程都有效



### 命令行参数方式

- 启动Hive时在命令行添加`-hiveconf param=value`来设定参数
  - 仅对本次hive启动有效

```bash
[ttshe@hadoop102 hive]$ bin/hive -hiveconf mapred.reduce.tasks=10;
```

- 查看参数设置

```bash
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=10
```

- 关于`mapred.reduce.tasks`
  - 默认值-1
    - 表示按照实际任务自动生成的MR执行模板中reduce的个数



### 参数声明方式

- 在HQL中使用`set`关键字设定参数
  - 仅对本次hive启动有效

```bash
hive (default)> set mapred.reduce.tasks = 100;
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=100
```



### 优先级

- 上述三种设定方式的优先级依次递增
- 配置文件<命令行参数<参数声明
- 注意某些系统级的参数，必须用前两种方式设定
  - 如log4j相关的设定
  - 那些参数的读取在会话建立以前已经完成