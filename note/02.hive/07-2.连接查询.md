# Join 子句



## 等值连接特性

- Hive支持通常的SQL  JOIN语句
- ==只支持等值连接==
- ==不支持非等值连接==

示例

- 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称

```sql
select e.empno,e.ename,d.deptno,d.dname from emp e join dept d on e.deptno = d.deptno;
```



## 表的别名

- 好处
  - 使用别名可以简化查询
  - 使用表名前缀可以提高执行效率

示例

- 合并员工表和部门表

```sql
select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;
```



## 内连接 `join`

- 只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来

```sql
select e.empno,e.ename,d.deptno,d.dname from emp e join dept d on e.deptno = d.deptno;
```



## 左外连接 `left join`

- JOIN操作符**左边表**中符合WHERE子句的所有记录将会被返回
- 如果**左边表**的指定字段没有符合条件的值使用NULL值替代

```sql
select e.empno,e.ename,d.deptno,d.dname from emp e 
left join dept d 
on e.deptno = d.deptno;
```



## 左半连接 [left semi join]

- 使用左半连接可以提高性能

```sql

```



- 注意：使用左半连接，右侧的表的列不可用



## 右外连接 `right join`

- JOIN操作符**右边表**中符合WHERE子句的所有记录将会被返回
- 如果**右边表**的指定字段没有符合条件的值使用NULL值替代

```sql
select e.empno,e.ename,d.deptno,d.dname from emp e 
right join dept d 
on e.deptno = d.deptno;
```



## 满外连接 `full join`

- MySQL不支持
- Hive支持
- 将会返回**所有表**中符合WHERE语句条件的所有记录
- 如果任一表的指定字段没有符合条件的值使用NULL值替代

```sql
select e.empno,e.ename,d.deptno,d.dname from emp e 
full join dept d 
on e.deptno = d.deptno;

+----------+----------+-----------+-------------+
| e.empno  | e.ename  | d.deptno  |   d.dname   |
+----------+----------+-----------+-------------+
| 7934     | MILLER   | 10        | ACCOUNTING  |
| 7839     | KING     | 10        | ACCOUNTING  |
| 7782     | CLARK    | 10        | ACCOUNTING  |
| 7876     | ADAMS    | 20        | RESEARCH    |
| 7788     | SCOTT    | 20        | RESEARCH    |
| 7369     | SMITH    | 20        | RESEARCH    |
| 7566     | JONES    | 20        | RESEARCH    |
| 7902     | FORD     | 20        | RESEARCH    |
| 7844     | TURNER   | 30        | SALES       |
| 7499     | ALLEN    | 30        | SALES       |
| 7698     | BLAKE    | 30        | SALES       |
| 7654     | MARTIN   | 30        | SALES       |
| 7521     | WARD     | 30        | SALES       |
| 7900     | JAMES    | 30        | SALES       |
| NULL     | NULL     | 40        | OPERATIONS  |
+----------+----------+-----------+-------------+
```



## 多表连接

- 连接 n个表，**至少需要n-1个连接条件**
- 如连接三个表，至少需要两个连接条件
- 大多数情况下，Hive会对每对JOIN连接对象启动一个MapReduce任务
- **Hive按照从左到右的顺序执行JOIN**
- 示例
  - 首先启动一个MapReduce job对表e和表d进行连接操作
  - 然后会再启动一个MapReduce job将第一个MapReduce job的输出和表 l 进行连接操作

```sql
select e.ename, d.dname, l.loc_name
from   emp e 
join   dept d
on     e.deptno = d.deptno 
join   location l
on     d.loc = l.loc;

+----------+-------------+-------------+
| e.ename  |   d.dname   | l.loc_name  |
+----------+-------------+-------------+
| SMITH    | RESEARCH    | London      |
| ALLEN    | SALES       | Tokyo       |
| WARD     | SALES       | Tokyo       |
| JONES    | RESEARCH    | London      |
| MARTIN   | SALES       | Tokyo       |
| BLAKE    | SALES       | Tokyo       |
| CLARK    | ACCOUNTING  | Beijing     |
| SCOTT    | RESEARCH    | London      |
| KING     | ACCOUNTING  | Beijing     |
| TURNER   | SALES       | Tokyo       |
| ADAMS    | RESEARCH    | London      |
| JAMES    | SALES       | Tokyo       |
| FORD     | RESEARCH    | London      |
| MILLER   | ACCOUNTING  | Beijing     |
+----------+-------------+-------------+
```



### 优化

- 当对3个或者更多表进行join连接时，每个on子句都==使用相同的连接键==的话，只产生一个MapReduce job

- Hadoop 默认使用 MapJoin ，可以减少Job个数

  - 参数

  ```bash
  set hive.auto.convert.join = true; 默认为true
  ```

  - 将该参数设置为false，执行示例sql，可以看到有2个job

  ```sql
  Query ID = ttshe_20190902154557_654d394f-2204-4e5f-88cc-7799bf1eb27d
  Total jobs = 2
  Launching Job 1 out of 2
  Number of reduce tasks not specified. Estimated from input data size: 1
  In order to change the average load for a reducer (in bytes):
    set hive.exec.reducers.bytes.per.reducer=<number>
  In order to limit the maximum number of reducers:
    set hive.exec.reducers.max=<number>
  In order to set a constant number of reducers:
    set mapreduce.job.reduces=<number>
  Starting Job = job_1567162357920_0027, Tracking URL = http://hadoop103:8088/proxy/application_1567162357920_0027/
  Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job  -kill job_1567162357920_0027
  Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
  2019-09-02 15:46:02,487 Stage-1 map = 0%,  reduce = 0%
  2019-09-02 15:46:07,807 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.62 sec
  2019-09-02 15:46:13,001 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.87 sec
  MapReduce Total cumulative CPU time: 6 seconds 870 msec
  Ended Job = job_1567162357920_0027
  Launching Job 2 out of 2
  Number of reduce tasks not specified. Estimated from input data size: 1
  In order to change the average load for a reducer (in bytes):
    set hive.exec.reducers.bytes.per.reducer=<number>
  In order to limit the maximum number of reducers:
    set hive.exec.reducers.max=<number>
  In order to set a constant number of reducers:
    set mapreduce.job.reduces=<number>
  Starting Job = job_1567162357920_0028, Tracking URL = http://hadoop103:8088/proxy/application_1567162357920_0028/
  Kill Command = /opt/module/hadoop-2.7.2/bin/hadoop job  -kill job_1567162357920_0028
  Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
  2019-09-02 15:46:22,560 Stage-2 map = 0%,  reduce = 0%
  2019-09-02 15:46:28,748 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.9 sec
  2019-09-02 15:46:32,840 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.33 sec
  MapReduce Total cumulative CPU time: 6 seconds 330 msec
  Ended Job = job_1567162357920_0028
  MapReduce Jobs Launched: 
  Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 6.87 sec   HDFS Read: 14765 HDFS Write: 574 SUCCESS
  Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 6.33 sec   HDFS Read: 12810 HDFS Write: 293 SUCCESS
  Total MapReduce CPU Time Spent: 13 seconds 200 msec
  OK
  e.ename	d.dname	l.loc_name
  MILLER	ACCOUNTING	Beijing
  KING	ACCOUNTING	Beijing
  CLARK	ACCOUNTING	Beijing
  JONES	RESEARCH	London
  FORD	RESEARCH	London
  SMITH	RESEARCH	London
  SCOTT	RESEARCH	London
  ADAMS	RESEARCH	London
  MARTIN	SALES	Tokyo
  WARD	SALES	Tokyo
  ALLEN	SALES	Tokyo
  TURNER	SALES	Tokyo
  JAMES	SALES	Tokyo
  BLAKE	SALES	Tokyo
  Time taken: 36.32 seconds, Fetched: 14 row(s)
  ```

  

## 笛卡尔积

- 要避免笛卡尔积出现
- 产生条件
  - 省略连接条件
  - 连接条件无效
  - 所有表中的所有行互相连接

```sql
select empno, dname from emp, dept;
```



## 连接谓词中不支持 or

- hive join目前不支持在on子句中使用谓词or

```sql
select e.empno, e.ename, d.deptno 
from emp e 
join dept d 
on e.deptno = d.deptno or e.ename=d.ename;

FAILED: SemanticException [Error 10019]: Line 4:3 OR not supported in JOIN currently 'ename'
```

