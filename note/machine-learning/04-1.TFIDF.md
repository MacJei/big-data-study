# TF-IDF 



### 0.引入依赖




```python
import numpy as np
import pandas as pd
```



### 1.定义数据和预处理


```python
docA = "The cat sat on my bed"
docB = "The dog sat on my kneets"

bowA = docA.split(" ")
bowB = docB.split(" ")

# 构建词库
wordSet = set(bowA).union(bowB)
wordSet
```

- 结果


    {'The', 'bed', 'cat', 'dog', 'kneets', 'my', 'on', 'sat'}



### 2.进行词数的统计


```python
# 用统计字典，保存词出现的次数
wordDictA = dict.fromkeys(wordSet, 0)
wordDictB = dict.fromkeys(wordSet, 0)

# 遍历文档，统计词数
for w in bowA:
    wordDictA[w] += 1
for w in bowB:
    wordDictB[w] += 1
    
pd.DataFrame([wordDictA,wordDictB])
```

- 结果

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>The</th>
      <th>bed</th>
      <th>cat</th>
      <th>dog</th>
      <th>kneets</th>
      <th>my</th>
      <th>on</th>
      <th>sat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>



### 3.计算词频TF


```python
def computTF( wordDict, bow):
    # 用一个字典对象记录tf，把所有的词对应在bow文档的tf都算出来
    tfDict = {}
    bowCount = len(bow)
    
    for word, count in wordDict.items():
        tfDict[word] = count / bowCount
    return tfDict

tfA = computTF(wordDictA,bowA)
tfB = computTF(wordDictB,bowB)
tfA
```

- 结果


    {'on': 0.16666666666666666,
     'The': 0.16666666666666666,
     'sat': 0.16666666666666666,
     'bed': 0.16666666666666666,
     'kneets': 0.0,
     'my': 0.16666666666666666,
     'cat': 0.16666666666666666,
     'dog': 0.0}



### 4.计算逆文档频率 IDF


```python
def computIDF(wordDictList):
    # 用一个字典保存对象IDF的结果，每个词作为key，初始值为0
    idfDict = dict.fromkeys(wordDictList[0], 0)
    N = len(wordDictList)
    for wDict in wordDictList:
        for w ,count in wDict.items():
            if(count > 0):
                # 计算所有Ni
                idfDict[w] += 1
    import math
    # 将计算的Ni转换为IDF值
    for w ,count in idfDict.items():
        idfDict[w] = math.log10((N + 1)  / (count + 1))
        
    return idfDict
    
idfs = computIDF([wordDictA, wordDictB])
idfs
```

- 结果


```json
{'on': 0.0,
 'The': 0.0,
 'sat': 0.0,
 'bed': 0.17609125905568124,
 'kneets': 0.17609125905568124,
 'my': 0.0,
 'cat': 0.17609125905568124,
 'dog': 0.17609125905568124}
# on The sat 所有文档都包含，所以idf为0
```

- TFIDF 函数


```python
def computTFIDF(tf, idfs):
    tfidf = {}
    for w, tfVal in tf.items():
        tfidf[w] = tfVal * idfs[w]
    return tfidf

tfidfA = computTFIDF(tfA, idfs)
tfidfB = computTFIDF(tfB, idfs)

pd.DataFrame([tfidfA, tfidfB])
```

- 运行结果
  - 通用的词被过滤掉，留下了热点词

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>The</th>
      <th>bed</th>
      <th>cat</th>
      <th>dog</th>
      <th>kneets</th>
      <th>my</th>
      <th>on</th>
      <th>sat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.029349</td>
      <td>0.029349</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.029349</td>
      <td>0.029349</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>

