测试集群IO。 

100个128MB文件，共计10G多。 

一、测试写性能 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

client-jobclient-2.6.0-tests.jar \ 

TestDFSIO -write -nrFiles 100 -size 128MB 

二、测试读性能 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

client-jobclient-2.6.0-tests.jar \ 

TestDFSIO -read -nrFiles 100 -size 128MB 

三、删除测试生成的数据 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

client-jobclient-2.6.0-tests.jar \ 

TestDFSIO -clean 

四、使用sort程序评测MapReduce 

1、使用RandomWriter来产生随机数，每个节点运行10个map任务，每个map产生大约 

1G大小的二进制随机数 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

examples-2.6.0.jar randomwriter random-data 

2、执行sort程序 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

examples-2.6.0.jar sort random-data sorted-data 

3、验证数据是否真正排好序了 

hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce- 

examples-2.6.0.jar testmapredsort -sortInput random-data -sortOutput sorted-data