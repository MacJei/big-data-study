i. dfs.namenode.handler.count=20 * log2(Cluster Size)，比如集群规模为20台时，此参数设置为80，可以理解处理的线程数

```text
The Hadoop RPC server consists of a single RPC queue per port and multiple handler (worker) threads that dequeue and process requests. If the number of handlers is insufficient, then the RPC queue starts building up and eventually overflows. You may start seeing task failures and eventually job failures and unhappy users. It is recommended that the RPC handler count be set to 20 * log2(Cluster Size) with an upper limit of 200.
```

ii. dfs.namenode.service.handler.count=上面参数的一半

```text
There is no precise calculation for the Service RPC handler count however the default value of 10 is too low for most production clusters. We have often seen this initialized to 50% of the dfs.namenode.handler.count in busy clusters and this value works well in practice.
```

iii. dfs.namenode.edits.dir设置与dfs.namenode.name.dir尽量分开，达到最低写入延迟

iv. dfs.namenode.accesstime.precision=0

```text
The setting dfs.namenode.accesstime.precision controls how often the NameNode will update the last accessed time for each file. It is specified in milliseconds. If this value is too low, then the NameNode is forced to write an edit log transaction to update the file's last access time for each read request and its performance will suffer.
The default value of this setting is a reasonable 3600000 milliseconds (1 hour). We recommend going one step further and setting it to zero so last access time updates are turned off. Add the following to your hdfs-site.xml.
```



