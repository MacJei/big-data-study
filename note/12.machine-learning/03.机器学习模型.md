# 监督学习



## 回归模型



### 线性回归



#### 一元线性回归

<img src="img/58.png" alt="1575004140217" style="zoom:80%;" />

<img src="img/59.png" alt="1575004183988" style="zoom:80%;" />



#### 多元线性回归

<img src="img/60.png" alt="1575004226469" style="zoom:80%;" />



#### 最小二乘法

- 求解线性回归函数的方法

<img src="img/61.png" alt="1575004328494" style="zoom:80%;" />

<img src="img/62.png" alt="1575004348018" style="zoom:80%;" />

<img src="img/63.png" alt="1575004414356" style="zoom:80%;" />



#### 梯度下降法

- 对于多元线性回归，采用最小二乘法特别复杂，一般使用梯度下降法实现
- 梯度下降法求得近似解

<img src="img/64.png" alt="1575004567673" style="zoom:80%;" />

<img src="img/65.png" alt="1575004593857" style="zoom:80%;" />

##### 求一元线性回归

<img src="img/66.png" alt="1575004646162" style="zoom:80%;" />

##### 注意事项

<img src="img/67.png" alt="1575004689250" style="zoom:80%;" />

##### 与最小二乘法区别

<img src="img/68.png" alt="1575004734137" style="zoom:80%;" />



## 分类模型



### k近邻 KNN

<img src="img/75.png" alt="1575099971196" style="zoom:80%;" />

#### 示例

<img src="img/76.png" alt="1575099998460" style="zoom:80%;" />

#### 距离计算

<img src="img/77.png" alt="1575100029504" style="zoom:80%;" />

#### 算法

<img src="img/78.png" alt="1575100085072" style="zoom:80%;" />





### 逻辑斯蒂回归



#### 线性回归解决分类问题

<img src="img/81.png" alt="1575192428690" style="zoom:80%;" />

<img src="img/82.png" alt="1575192480923" style="zoom:80%;" />

#### 使用逻辑回归解决分类问题

<img src="img/83.png" alt="1575192571101" style="zoom:80%;" />

##### 压缩函数 sigmoid

- 使用压缩函数的特性对原先的函数进行结果判断
- 结果只有2种

<img src="img/84.png" alt="1575192604537" style="zoom:80%;" />

<img src="img/85.png" alt="1575192631501" style="zoom:80%;" />

<img src="img/86.png" alt="1575192671302" style="zoom:80%;" />

<img src="img/87.png" alt="1575192749964" style="zoom:80%;" />



##### 逻辑斯蒂回归损失函数

<img src="img/88.png" alt="1575192814749" style="zoom:80%;" />

- 使用平方损失函数计算，对于复杂的曲线只能使用梯度下降处理，容易出现局部最小值，获得不到全局最小值

  - 平方损失函数适用于凸函数，可以使用梯度下降近似获得全局最小值

  <img src="img/89.png" alt="1575192951187" style="zoom:80%;" />

###### 引入新的损失函数

<img src="img/90.png" alt="1575193046931" style="zoom:80%;" />

<img src="img/91.png" alt="1575193074672" style="zoom:80%;" />

<img src="img/92.png" alt="1575193097113" style="zoom:80%;" />

<img src="img/94.png" alt="1575193152363" style="zoom:80%;" />



###### 使用梯度下降求解

<img src="img/95.png" alt="1575193252330" style="zoom:80%;" />





### 决策树

<img src="img/96.png" alt="1575193302499" style="zoom:80%;" />

#### 示例

<img src="img/97.png" alt="1575193327691" style="zoom:80%;" />

<img src="img/98.png" alt="1575193345214" style="zoom:80%;" />

<img src="img/99.png" alt="1575193371458" style="zoom:80%;" />



#### if-then 规则

<img src="img/100.png" alt="1575193414398" style="zoom:80%;" />

- 互斥且完备
  - 互斥，条件互斥
  - 完备，条件全集



#### 目标

![1575193478122](img/101.png)



#### 特征选择

<img src="img/102.png" alt="1575193547734"  />

#### 随机变量

![1575193583248](img/103.png)

- HH表示2次正面，TT表示2次反面



#### 熵

![1575193736655](img/104.png)

![1575193780432](img/105.png)

##### 示例

![1575193826093](img/106.png)

![1575193844646](img/107.png)

![1575193935055](img/108.png)

#### 目标

![1575193950556](img/109.png)



#### 条件熵

![1575194038734](img/110.png)



#### 信息增益

![1575194108212](img/111.png)

- 评判标准
  - 求信息增益的最大值



#### 生成算法

![1575194258914](img/112.png)

- 剪枝
  - 防止过拟合



# 无监督学习

- 聚类
  - K 均值
  - 基于密度的聚类
  - 最大期望聚类
- 降维
  - 潜语义分析 LSA
  - 主成分分析 PCA
  - 奇异值分解 SVD



## 聚类



### k 均值 k-means

![1575194646771](img/113.png)

![1575194660709](img/114.png)



## 降维



