## 引入依赖

```python
import numpy as np
import pandas as pd # 科学计算和数值分析

# 引入sklearn 里面的数据集 iris 鸢尾花的原始数据
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split # 切分数据集为训练集和测试集
from sklearn.metrics import accuracy_score # 准确率评分，用于计算分类预测的准确率
```



## 导入数据

```python
# 数据加载与预处理
iris = load_iris()
type(iris)
iris
```

- 结果


```bash
# iris
# data是输入的样本点二维数组，二维矩阵
# data中数据的具体分类 'feature_names': ['sepal length (cm)', 'sepal width (cm)','petal length (cm)','petal width (cm)'], 花萼长宽，花瓣长宽
# target是分类的结果，一维数组
# target_names 表示具体分类的名称: array(['setosa', 'versicolor', 'virginica'] 山鸢尾，杂色鸢尾，维吉尼亚鸢尾
{'data': array([[5.1, 3.5, 1.4, 0.2],
        [4.9, 3. , 1.4, 0.2],
        [4.7, 3.2, 1.3, 0.2],
      ...
        [6.7, 3. , 5.2, 2.3],
        [6.3, 2.5, 5. , 1.9],
        [6.5, 3. , 5.2, 2. ],
        [6.2, 3.4, 5.4, 2.3],
        [5.9, 3. , 5.1, 1.8]]),
 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),

 'feature_names': ['sepal length (cm)',
  'sepal width (cm)',
  'petal length (cm)',
  'petal width (cm)'],
 'filename': 'd:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\data\\iris.csv'}
```




```python
df = pd.DataFrame(data=iris.data, columns= iris.feature_names)
df['class'] = iris.target # 可以增加一列 class类别

# 可以对DataFrame使用map等函数式编程
# df['class'] = df['class'].map({0: iris.target_names[0], 1: iris.target_names[1], 2: iris.target_names[2]})
df['class'] = df['class'].map(lambda i : iris.target_names[i])
df.head(10)
df
```

- 显示打印信息

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.4</td>
      <td>3.9</td>
      <td>1.7</td>
      <td>0.4</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.6</td>
      <td>3.4</td>
      <td>1.4</td>
      <td>0.3</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>7</th>
      <td>5.0</td>
      <td>3.4</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4.4</td>
      <td>2.9</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>...</th>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    </tbody></table>   

-  显示统计信息


```python
df.describe()
```

- 结果

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.843333</td>
      <td>3.057333</td>
      <td>3.758000</td>
      <td>1.199333</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.828066</td>
      <td>0.435866</td>
      <td>1.765298</td>
      <td>0.762238</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.300000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.100000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.100000</td>
      <td>2.800000</td>
      <td>1.600000</td>
      <td>0.300000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.800000</td>
      <td>3.000000</td>
      <td>4.350000</td>
      <td>1.300000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.400000</td>
      <td>3.300000</td>
      <td>5.100000</td>
      <td>1.800000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.900000</td>
      <td>4.400000</td>
      <td>6.900000</td>
      <td>2.500000</td>
    </tr>
  </tbody>
</table>



## 数据处理


```python
x = iris.data
y = iris.target.reshape(-1,1)
print(x.shape, y.shape)
```

    (150, 4) (150, 1)



## 数据集划分

```python
# 划分训练集和测试集
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=35, stratify = y) 
# s折划分，留一划分，比例划分 random_state 随机种子，test_size 测试集比例，stratify 按照y进行等比例分层
print(x_train.shape,y_train.shape)
print(x_test.shape, y_test.shape)
```

    (105, 4) (105, 1)
    (45, 4) (45, 1)



## 核心算法实现

```python
# 核心算法实现
# 定义距离函数
# l1距离 曼哈顿距离 直接开根号
# a 可以是一个矩阵 b 必须是一个行向量
def l1_distance(a, b):
    # axis 轴 =1 表示运算保存的结果是一列
    # sum 操作 如果没有axis参数，那么将所有矩阵元素相加，如果axis = 1 则将每一行相加
    return np.sum(np.abs(a-b),axis = 1)

def l2_distance(a, b):
    return np.sqrt(np.sum((a-b)**2,axis = 1))

# 分类器实现
class KNN(object):
    # 定义一个初始化方法
    # n_neighbors 表示近邻的数量
    def __init__(self,n_neighbors = 1,dist_func = l1_distance):
        self.n_neighbors = n_neighbors
        self.dist_func = dist_func
        
    # 训练模型方法
    def fit(self, x, y):
        self.x_train = x
        self.y_train = y
        
    # 模型预测方法    
    def predict(self, x):
        # 初始化预测数组，形式要与输入相同，行的个数要一致
        # zeros第一个参数表示返回值的格式，(n,m) 表示n行m列 dtype 表示元素数据的类型，这里与y_train保持一致
        y_pred = np.zeros((x.shape[0],1), dtype = self.y_train.dtype)
        
        # 遍历输入的数据点，通过枚举，获取一个元组对象
        # 取出每个数据点的序号和数据x_item
        for i, x_item in enumerate(x):
            # x_item与所有训练数据计算距离
            distances = self.dist_func(self.x_train,x_item)
            
            # 得到距离按照由近到远排序,得到排序后的索引数组,排序距离从小到大
            nn_indexs = np.argsort(distances)
            
            # 选取最近的k个点，保存它们对应的分类类别，要取出n_neighbors 个点
            # ravel 将多维数组转换为一维数组
            nn_y = self.y_train[nn_indexs[:self.n_neighbors]].ravel() 
            
            # 统计类别出现频率最高的赋给y_pred[i]
            # bincount 将nn_y中出现的频率进行计数，同时下标表示key，value表示次数
            # np.argmax 获取value最大的下标，得到key
            y_pred[i] = np.argmax(np.bincount(nn_y))
            
        return y_pred
    

```



## 测试

```python
# 测试
knn = KNN(n_neighbors = 3)
# 训练模型
knn.fit(x_train, y_train)
# 传入测试数据做预测
y_pred = knn.predict(x_test)

# 求出预测准确率
accuracy = accuracy_score(y_test, y_pred)

print("预测准确率：",accuracy)
```

- 结果

```txt
预测准确率： 0.9333333333333333
```



```python
knn = KNN()
# 训练模型
knn.fit(x_train, y_train)

result_list = []

for p in [1, 2]:
    knn.dist_func = l1_distance if p == 1 else l2_distance
    
    # 取得奇数，k要为奇数，否则无法确定最终结果
    for k in range(1, 10, 2):
        knn.n_neighbors = k
        y_pred = knn.predict(x_test)
        accuracy = accuracy_score(y_test, y_pred)
        result_list.append([k, knn.dist_func.__name__, accuracy])

df = pd.DataFrame(result_list, columns = ['K','距离函数','预测准确率'])        
df        
```

- 结果

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>K</th>
      <th>距离函数</th>
      <th>预测准确率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>l1_distance</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>l1_distance</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>l1_distance</td>
      <td>0.977778</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>l1_distance</td>
      <td>0.955556</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9</td>
      <td>l1_distance</td>
      <td>0.955556</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>l2_distance</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3</td>
      <td>l2_distance</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <th>7</th>
      <td>5</td>
      <td>l2_distance</td>
      <td>0.977778</td>
    </tr>
    <tr>
      <th>8</th>
      <td>7</td>
      <td>l2_distance</td>
      <td>0.977778</td>
    </tr>
    <tr>
      <th>9</th>
      <td>9</td>
      <td>l2_distance</td>
      <td>0.977778</td>
    </tr>
  </tbody>
</table>


