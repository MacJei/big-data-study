# Hadoop运行模式

> 官网 http://hadoop.apache.org/ 
> http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html



# 本地运行模式



## 官方grep案例

> 查阅官方案例
>
> By default, Hadoop is configured to run in a non-distributed mode, as a single Java process. This is useful for debugging.
>
> The following example copies the unpacked conf directory to use as input and then finds and displays every match of the given regular expression. Output is written to the given output directory.
>
> ```
> $ mkdir input
> $ cp etc/hadoop/*.xml input
> $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar grep input output 'dfs[a-z.]+'
> $ cat output/*
> ```

- 在hadoop目录下创建input文件夹，用于存放要分析的数据

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir input
```

- 将要分析的文件拷贝到input文件夹下

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cp etc/hadoop/*.xml input
```

- 运行hadoop命令，解析所有dfs开头的数据，同时将结果输出到output文件夹

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
```

- 查看输出

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cd output/
[ttshe@hadoop101 output]$ ll
总用量 4
-rw-r--r--. 1 ttshe root 11 4月   7 13:21 part-r-00000
-rw-r--r--. 1 ttshe root  0 4月   7 13:21 _SUCCESS
[ttshe@hadoop101 hadoop-2.7.2]$ cat output/*
1	dfsadmin
```



## 官方wordCount案例

- 创建一个wcinput文件夹，并添加一个文件，在该文件中添加要使用的数据素材

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir wcinput
[ttshe@hadoop101 hadoop-2.7.2]$ cd wcinput/
[ttshe@hadoop101 wcinput]$ touch wc.input
[ttshe@hadoop101 wcinput]$ cat wc.input 
hadoop yarn
hadoop mapreduce
study
deep-learning
ttshe
dd
atguigu
```

- 执行命令

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput
```

- 查看结果

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cat wcoutput/*
atguigu	1
dd	1
deep-learning	1
hadoop	2
mapreduce	1
study	1
ttshe	1
yarn	1
```



# 伪分布式模式



## 启动HDFS-运行MapReduce 程序

> **Pseudo-Distributed Operation**
> Hadoop can also be run on a single-node in a pseudo-distributed mode where each Hadoop daemon runs in a separate Java process.



### 配置集群

- 配置 hadoop-env.sh

  - 这里env.sh可以看到注释上说明，只需要修改JAVA_HOME，其他都是可选的，在分布式配置的时候，需要修改JAVA_HOME

  ```shell
  [ttshe@hadoop101 hadoop]$ pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [ttshe@hadoop101 hadoop]$ echo $JAVA_HOME
  /opt/module/jdk1.8.0_144
  [ttshe@hadoop101 hadoop]$ vi hadoop-env.sh 
  # Set Hadoop-specific environment variables here.
  # The only required environment variable is JAVA_HOME.  All others are
  # optional.  When running a distributed configuration it is best to
  # set JAVA_HOME in this file, so that it is correctly defined on
  # remote nodes.
  # The java implementation to use.
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

- 配置core-site.xml

  - 关于配置项介绍，在官网配置页面的左下角可见：http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml

  | 参数           | 默认值                                     | 描述                                                         |
  | -------------- | ------------------------------------------ | ------------------------------------------------------------ |
  | fs.defaultFS   | file:/// 表示本地                          | The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem.<br />指定HDFS中的**NameNode**的地址 |
  | hadoop.tmp.dir | /tmp/hadoop-${user.name} 表示在tmp文件夹下 | A base for other temporary directories.<br />指定Hadoop运行时产生的文件存储目录，一般需要磁盘比较大，否则文件会很多，需要搬移 |

  ```xml
  [ttshe@hadoop101 hadoop]$ vi core-site.xml 
  <configuration>
    <property>
        <name>fs.defaultFS</name>
        # 注意配置该项目后，本地模式不生效，如果还要使用本地模式，则需要去除该配置或者配置file:///
        <value>hdfs://hadoop101:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.7.2/data/tmp</value>
    </property>
  </configuration>
  ```

- 配置hdfs-site.xml

  - 在官网配置 http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml 可以查看

  | 参数            | 默认值 | 描述                                                         |
  | --------------- | ------ | ------------------------------------------------------------ |
  | dfs.replication | 3      | Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.<br />指定HDFS的副本数量，只在集群中的副本的个数，因为是伪分布式配置，就一台机器，复制多余1个没有意义。 |

  ```xml
  [ttshe@hadoop101 hadoop]$ vi hdfs-site.xml
  <configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
  </configuration>
  ```



### 启动集群



#### 格式化NameNode

> 第一次启动时格式化，以后不要总格式化

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs namenode -format
```



#### 启动NameNode

> 关闭使用stop

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-namenode-hadoop101.out
```



#### 启动DataNode

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode
starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-datanode-hadoop101.out
```



#### 查看是否启动成功

```shell
# 查看进程是否存在，存在则表示启动成功
[ttshe@hadoop101 hadoop-2.7.2]$ jps -l
8903 sun.tools.jps.Jps
8680 org.apache.hadoop.hdfs.server.namenode.NameNode
8812 org.apache.hadoop.hdfs.server.datanode.DataNode
```



#### 通过Web查看HDFS文件系统

访问：http://192.168.1.101:50070/dfshealth.html#tab-datanode

推荐配置host（C:/Windows/System32/drivers/etc/hosts）

```shell
192.168.1.100 hadoop100
192.168.1.101 hadoop101
192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104
192.168.1.105 hadoop105
192.168.1.106 hadoop106
```

可以指定名称访问如http://hadoop101:50070/dfshealth.html#tab-datanode

![1554733334932](img/hadoop/02.hadoop%E5%85%A5%E9%97%A807.png)

重点关注Utilities中的Browse the file system，完全仿照Linux的目录树结构搜索数据。



#### 查看日志

```shell
[root@hadoop101 logs]# ll
总用量 64
-rw-r--r--. 1 ttshe root 24121 4月   8 00:08 hadoop-ttshe-datanode-hadoop101.log
-rw-r--r--. 1 ttshe root   716 4月   8 00:08 hadoop-ttshe-datanode-hadoop101.out
-rw-r--r--. 1 ttshe root 27765 4月   8 00:08 hadoop-ttshe-namenode-hadoop101.log
-rw-r--r--. 1 ttshe root  5007 4月   8 22:24 hadoop-ttshe-namenode-hadoop101.out
-rw-r--r--. 1 ttshe root     0 4月   8 00:06 SecurityAuth-ttshe.audit
[root@hadoop101 logs]# pwd
/opt/module/hadoop-2.7.2/logs
```



### 操作集群

> 在HDFS系统上操作目录，和Linux上的命令一致

- 创建一个input文件夹

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -mkdir -p /user/ttshe/input
  ```

  在HDFS系统页面上可以查询得到相应的结果

  ![1554735248179](img/hadoop/02.hadoop%E5%85%A5%E9%97%A808.png)

  注意Owner 和Group与Linux的区别

- 上传测试文件到HDFS中，将wcinput中的wc.input文件上传

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -put wcinput/wc.input /user/ttshe/input/
  ```

- 查看是否上传成功

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -ls /user/ttshe/input
  Found 1 items
  -rw-r--r--   1 ttshe supergroup         66 2019-04-08 22:57 /user/ttshe/input/wc.input
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/input/wc.input
  hadoop yarn
  hadoop mapreduce
  study
  deep-learning
  ttshe
  dd
  atguigu
  ```

- 运行MapReduce程序

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
  ```

- 查看结果

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/output/*
  atguigu	1
  dd	1
  deep-learning	1
  hadoop	2
  mapreduce	1
  study	1
  ttshe	1
  yarn	1
  ```

  通过浏览器可以查看

  ![1554736023270](img/hadoop/02.hadoop%E5%85%A5%E9%97%A809.png)



### 注意事项

- 不能一直格式化NameNode，格式化NameNode需要注意的事项

  ```shell
  # 查看当前name节点版本
  [root@hadoop101 current]# pwd
  /opt/module/hadoop-2.7.2/data/tmp/dfs/name/current # 在core-site.xml中配置的路径
  [root@hadoop101 current]# cat VERSION
  #Mon Apr 08 00:05:15 CST 2019
  namespaceID=392562494
  clusterID=CID-7ef31aad-4d5c-4aba-94f6-a4cfe9af7ae4
  cTime=0
  storageType=NAME_NODE
  blockpoolID=BP-1865658710-192.168.1.101-1554653114984
  layoutVersion=-63
  ```

  格式化NameNode，会产生新的集群ID，导致NameNode和DataNode的CID不一致（都在各自的current下存储），集群找不到以往数据，所以在格式化NameNode的时候，需要先删除data数据和log日志（rm -rf data/ logs/），然后再格式化NameNode

  ![1554738823304](img/hadoop/02.hadoop%E5%85%A5%E9%97%A810.png)





## 启动YARN-运行MapReduce程序

- 配置集群在YARN上运行MR
- 启动，测试集群增删改
- 在YARN上执行WordCount案例



### 配置集群

- 配置yarn-env.sh

  - 配置参数说明：http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
  - 配置JAVA_HOME

  ```shell
  [root@hadoop101 hadoop]# pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [root@hadoop101 hadoop]# vim yarn-env.sh
  # 在23行的位置进行配置当前的JAVA_HOME
   22 # some Java parameters
   23 export JAVA_HOME=/opt/module/jdk1.8.0_144
   24 if [ "$JAVA_HOME" != "" ]; then
  ```

- 配置yarn-site.xml

  - 配置nodemanager
  - 配置resourcemanager

  ```xml
  <configuration>
      <!--reducer获取数据的方式 shuffle是mapreduce的核心，需要重点掌握的知识点 -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>
      <!-- 指定YARN的ResourceManager的地址,当前resourcemanager放在那台主机上运行 -->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hadoop101</value>
      </property>
  <!-- Site specific YARN configuration properties -->
  </configuration>
  ```

- 配置mapred-env.sh

  - 配置JAVA_HOME

  ```shell
  [root@hadoop101 hadoop]# vim mapred-env.sh
  # 可以在第16行找到注释掉的配置
  16 export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

- 配置mapred-site.xml

  - 配置参数说明：http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
  - 对mapred-site.xml.template 重命名为mapred-site.xml

  | 参数名                   | 默认值 | 说明                                                         |
  | ------------------------ | ------ | ------------------------------------------------------------ |
  | mapreduce.framework.name | local  | The runtime framework for executing MapReduce jobs. Can be one of local, classic or yarn.<br />说明默认的mapreduce是运行在本地的，这里要配置运行在yarn上 |

  ```xml
  [root@hadoop101 hadoop]# mv mapred-site.xml.template mapred-site.xml
  [root@hadoop101 hadoop]# vim mapred-site.xml 
  # 配置如下参数
  <configuration>
      <!-- 指定MR运行在YARN上 -->
      <property>
          <name>mapreduce.framework.name</name>           
          <value>yarn</value>
      </property>
  </configuration>
  ```



### 启动集群

- 启动前必须保证NameNode和DataNode已经启动

- 启动ResourceManager

  ```shell
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh start resourcemanager
  starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop101.out
  ```

- 启动NodeManager

  ```shell
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh start nodemanager
  starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop101.out
  ```

- 查看是否启动成功

  ```shell
  [root@hadoop101 hadoop-2.7.2]# jps
  11314 Jps
  8680 NameNode
  11178 NodeManager
  8812 DataNode
  10908 ResourceManager
  ```



### 操作集群

- 通过Web访问YARN
  - http://hadoop101:8088/cluster

![1554822805719](img/hadoop/02.hadoop%E5%85%A5%E9%97%A811.png)

- 删除系统上的output文件（之前启动HDFS运行MapReduce程序时，输出的文件，需要删除，由于下面操作MapReduce要重新生成一个output文件）

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -rm -R /user/ttshe/output
  19/04/09 23:17:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
  Deleted /user/ttshe/output
  ```

  - 注意用户要是创建output的用户，如ttshe，否则没有权限删除

- 执行MapReduce程序

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
  ```

- 查看结果

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/output/*
  atguigu	1
  dd	1
  deep-learning	1
  hadoop	2
  mapreduce	1
  study	1
  ttshe	1
  yarn	1
  ```

  ![1554823470152](img/hadoop/02.hadoop%E5%85%A5%E9%97%A812.png)

  运行的过程可以在页面中观察，而History需要接下来配置就可以看到运行的记录。



## 配置历史服务器

- 配置mapred-site.xml

  - 在原先的配置中增加历史的配置

  ```xml
  [ttshe@hadoop101 hadoop]$ pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [ttshe@hadoop101 hadoop]$ vim mapred-site.xml
  # 增加如下配置参数
  <!-- 历史服务器端地址 -->
  <property>
      <name>mapreduce.jobhistory.address</name>
      <value>hadoop101:10020</value>
  </property>
  <!-- 历史服务器web端地址 -->
  <property>
      <name>mapreduce.jobhistory.webapp.address</name>
      <value>hadoop101:19888</value>
  </property>
  ```

- 启动历史服务器

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/mr-jobhistory-daemon.sh start historyserver
  starting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-ttshe-historyserver-hadoop101.out
  [ttshe@hadoop101 hadoop-2.7.2]$ jps
  12208 Jps
  8680 NameNode
  8812 DataNode
  12158 JobHistoryServer
  ```

- 查看Web页面：http://hadoop101:19888/jobhistory

  ![1554824275728](img/hadoop/02.hadoop%E5%85%A5%E9%97%A813.png)

  点击页面中的counters，查看MapReduce的运行情况

  ![1554824374314](img/hadoop/02.hadoop%E5%85%A5%E9%97%A814.png)

  点击configuration，可以看到该job运行的配置信息

  ![1554824487172](img/hadoop/02.hadoop%E5%85%A5%E9%97%A815.png)

  这里的logs需要开启配置日志信息

  

## 配置日志的聚集	

- 概念：应用运行完成后，将程序运行日志信息上传到HDFS系统上

- 好处：用于查看程序的运行情况，方便开发调试

- 注意：==开启日志收集，需要重启NodeManager和ResourceManager以及HistoryManager==

- 配置yarn-site.xml，添加配置

  ```shell
  [root@hadoop101 hadoop]# pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [root@hadoop101 hadoop]# vim yarn-site.xml 
  # 增加如下配置
  <!-- 日志聚集功能使能 -->
  <property>
  	<name>yarn.log-aggregation-enable</name>
  	<value>true</value>
  </property>
  <!-- 日志保留时间设置7天 -->
  <property>
  	<name>yarn.log-aggregation.retain-seconds</name>
  	<value>604800</value>
  </property>
  ```

- 关闭已经开启的NodeManager,ResourceManager,HistoryServer

  ```shell
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh stop resourcemanager
  stopping resourcemanager
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh stop nodemanager
  stopping nodemanager
  [root@hadoop101 hadoop-2.7.2]# sbin/mr-jobhistory-daemon.sh stop historyserver
  ```

- 启动NodeManger,ResourceManager,HistoryServer

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start resourcemanager
  starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-ttshe-resourcemanager-hadoop101.out
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager
  starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-ttshe-nodemanager-hadoop101.out
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/mr-jobhistory-daemon.sh start historyserver
  starting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-ttshe-historyserver-hadoop101.out
  ```

- 删除已经存在的output文件

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -rm -R /user/ttshe/output
  ```

- 执行wordCount程序

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
  ```

- 查看日志：http://hadoop101:19888/jobhistory



## 配置文件说明

- 默认配置文件：系统默认值都写在这些文件中

  | 要获取的默认文件     | 文件存放在Hadoop的jar包中的位置                            |
  | -------------------- | ---------------------------------------------------------- |
  | [core-default.xml]   | hadoop-common-2.7.2.jar/ core-default.xml                  |
  | [hdfs-default.xml]   | hadoop-hdfs-2.7.2.jar/ hdfs-default.xml                    |
  | [yarn-default.xml]   | hadoop-yarn-common-2.7.2.jar/ yarn-default.xml             |
  | [mapred-default.xml] | hadoop-mapreduce-client-core-2.7.2.jar/ mapred-default.xml |

- 自定义配置文件：需要修改值的时候在如下的配置文件中配置，覆盖默认配置

  - 路径：$HADOOP_HOME/etc/hadoop

  core-site.xml

  hdfs-site.xml

  yarn-site.xml

  mapred-site.xml

  

# 完全分布式模式（重点）

流程：

- <a href="#虚拟机环境准备">准备3台虚拟机（关闭防火墙，静态ip，配置主机名称）</a>

- <a href="# 安装JDK">安装JDK，配置环境变量</a>

- <a href="# 安装Hadoop">安装Hadoop，配置环境变量</a>

- 配置集群

- 单点启动

- 配置ssh

- 群起并测试集群

  

## 集群分发脚本编写

> 用于批量安装jdk和hadoop等



### scp 

> secure copy
> 安全拷贝，实现服务器与服务器之间的数据拷贝



基本语法

```shell
scp -r sourceDir/fileName username@hostname:targetDir/fileName
-r 表示递归
```



操作：推送

```shell
# 在hadoop101上将 /opt/module目录下的软件进行拷贝到hadoop102下的/opt/module
[root@hadoop101 opt]# scp -r module root@hadoop102:/opt/module

# 注意:需要修改拷贝之后的权限 注意-R命令表示文件夹中所有的文件都是该用户组和用户
[ttshe@hadoop101 opt]$ sudo chown ttshe:ttshe -R module/
[ttshe@hadoop101 opt]$ cd module/
[ttshe@hadoop101 module]$ ll
总用量 8
drwxr-xr-x. 15 ttshe ttshe 4096 4月  20 18:59 hadoop-2.7.2
drwxr-xr-x.  8 ttshe ttshe 4096 4月  20 18:59 jdk1.8.0_144
```



操作：拉取

```shell
# 在hadoop103上从hadoop101上拉取数据
[ttshe@103 opt]$ sudo scp -r ttshe@hadoop101:/opt/module root@hadoop103:/opt/module

# 注意修改权限
[ttshe@hadoop103 opt]$ sudo chown ttshe:ttshe -R module
```



操作：第三方客户端操作另外2个客户端拷贝操作

```shell
# 在hadoop103上将hadoop101的内容拷贝到hadoop104上
[ttshe@hadoop103 tmp]$ scp -r ttshe@hadoop101:/opt/module root@hadoop104:/opt/module
# 设置权限
[ttshe@hadoop104 opt]$ sudo chown ttshe:ttshe -R module
```



操作：将hadoop101上的配置文件/etc/profile 拷贝到hadoop102-hadoop104上

```shell
[root@hadoop101 module] scp /etc/profile root@hadoop102:/etc/profile
[ttshe@hadoop101 module]$ sudo scp /etc/profile root@hadoop103:/etc/profile
[root@hadoop101 module] scp /etc/profile root@hadoop104:/etc/profile
# 都执行完之后，需要source /etc/profile
```



### rsync 

> 远程同步工具，用于备份和镜像，速度快，避免复制重复内容，支持符号连接的优点
> 与scp的区别：rsync比scp快，只做差异文件更新，而scp则是直接拷贝

基本语法

```shell
rsync -rvl sourceDir/fileName username@hostname:targetDir/fileName
参数说明：
-r	递归
-v	显示复制过程 view
-l	拷贝符号连接
-a  增量拷贝
```

操作：把hadoop101上的/opt/software目录同步到hadoop102服务器的root用户目录下

```shell
[ttshe@hadoop101 module]$ rsync -rvl /opt/software/ root@hadoop102:/opt/software
# 注意要修改一下权限为ttshe
```



### xsync 脚本实现

> 集群分发脚本，功能：可以循环复制文件到所有节点的相同目录下，基本思路是调用rsync语句

实现思路：

```shell
# 使用rsync 命令拷贝编写脚本，原始拷贝命令
rsync -rvl /opt/module root@hadoop103:/opt/
# 期望脚本：xsync 要同步的文件名称
# 说明：在/home/ttshe/bin下放置该脚本，ttshe可以在系统的任意地方运行
```

脚本简单实现

```shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径 注意这里使用-P
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=102; host<105; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -avl $pdir/$fname $user@hadoop$host:$pdir
done
```

修改脚本权限

```shell
[ttshe@hadoop101 module]$ cd /home/ttshe/bin
[ttshe@hadoop101 bin]$ chmod 777 xsync 
```

执行脚本

```shell
[ttshe@hadoop101 ~]$ sh bin/xsync bin/
fname=bin
pdir=/home/ttshe
# 注意执行完成后，在其他的机器上对xsync文件添加权限
```

注意：如果将xsync放到/home/atguigu/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下，或者查看路径echo $PATH 看当前路径/home/ttshe/bin是否在PATH中，添加。



## 集群配置



### 规划

|      | hadoop102              | hadoop103                        | hadoop104                       |
| ---- | ---------------------- | -------------------------------- | ------------------------------- |
| HDFS | NameNode<br />DataNode | DataNode                         | SecondaryNameNode<br />DataNode |
| YARN | NodeManager            | NodeManager<br />ResourceManager | NodeManager                     |

- NameNode和SecondaryNameNode配置的内存是一样的
- NameNode是HDFS的索引节点，需要有充足的内存

- ResourceManager也需要有充足的内存
- NameNode和SecondaryNameNode，ResourceManager需要部署在不同的机器上，分配足够的内存。



### 配置



#### core-site.xml

> 核心文件，在 core-site.xml下配置如下参数

```shell
# 配置nameNode的服务的后台访问地址，由于nameNode是在hadoop102上部署，因此需要指定
[ttshe@hadoop102 hadoop]$ pwd
/opt/module/hadoop-2.7.2/etc/hadoop
[ttshe@hadoop102 hadoop]$ vi core-site.xml 

<configuration>
    <property>
        <name>fs.defaultFS</name>
        # 配置的是hadoop102服务
        <value>hdfs://hadoop102:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.7.2/data/tmp</value>
    </property>
</configuration>
```



#### hadoop-env.sh

> HDFS文件，主要是配置JAVA_HOME

```shell
[ttshe@hadoop102 hadoop]$ vi hadoop-env.sh

 24 # The java implementation to use.
 25 export JAVA_HOME=/opt/module/jdk1.8.0_144
```



#### hdfs-site.xml

- 配置副本集是3，如果不配置也是可以，默认值就是3
- 配置SecondaryNameNode的访问地址
- 此处指定在Hadoop104上配置

```shell
[ttshe@hadoop102 hadoop]$ vi hdfs-site.xml 
# 配置内容如下
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <!-- #指定Hadoop辅助名称节点主机配置 -->
    <property>
         <name>dfs.namenode.secondary.http-address</name>       
         <value>hadoop104:50090</value>
    </property>
</configuration>
```



#### yarn-env.sh

> YARN 文件，配置JAVA_HOME

```shell
[ttshe@hadoop102 hadoop]$ vi yarn-env.sh 
 22 # some Java parameters
 23 export JAVA_HOME=/opt/module/jdk1.8.0_144
```



#### yarn-site.xml

```shell
[ttshe@hadoop102 hadoop]$ vi yarn-site.xml 

<configuration>
    <!--reducer获取数据的方式 -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 指定YARN的ResourceManager的地址 -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        # 注意配置resourcemanager的后端访问主机
        <value>hadoop103</value>
    </property>
    <!-- 日志聚集功能使能 -->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <!-- 日志保留时间设置7天 -->
    <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>604800</value>
    </property>
</configuration>
```



#### mapred-env.sh

> 配置JAVA_HOME位置

```shell
[ttshe@hadoop102 hadoop]$ vi mapred-env.sh
 16 export JAVA_HOME=/opt/module/jdk1.8.0_144
```



#### mapred-site.xml

```shell
# 先备份
[ttshe@hadoop102 hadoop]$ cp mapred-site.xml mapred-site.xml.template
# 进行设置
<!-- 指定MR运行在YARN上 -->
<property>
	<name>mapreduce.framework.name</name>
	<value>yarn</value>
</property>
```



### 分发配置文件

> 通过脚本分发配置好的文件

```shell
[ttshe@hadoop102 hadoop]$ xsync /opt/module/hadoop-2.7.2/
```

然后查看文件的分配情况



## 集群单点启动



### `rm -rf data logs`

> 如果有data文件夹和logs文件夹，需要清除
> 注意由于是集群，其他机器都要清除

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ rm -rf data
[ttshe@hadoop102 hadoop-2.7.2]$ rm -rf logs
```



### `hadoop namenode -format`

> 第一次启动，需要格式化NameNode，格式化要部署nameNode的机器

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ hadoop namenode -format
# 也可以输入命令bin/hdfs namenode -format
```



### `hadoop-daemon.sh start namenode`

> 在hadoop102上启动NameNode

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
[ttshe@hadoop102 hadoop-2.7.2]$ jps
3541 NameNode
```



### `hadoop-daemon.sh start datanode`

- 在hadoop102，hadoop103，hadoop104上启动DataNode

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode
[ttshe@hadoop102 hadoop-2.7.2]$ jps
3762 Jps
3541 NameNode
3673 DataNode
```



### web访问NameNode

- 访问NameNode后台服务hadoop102:50070，查看集群是否启动完成

![1555816737988](img/hadoop/02.hadoop%E5%85%A5%E9%97%A816.png)





## SSH 无密登录配置

> 通过配置ssh，分发证书后，不需要输入密码就可以远程登录其他主机，便于以后编写脚本进行集群启动关闭控制操作



### 配置ssh

基本语法

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ ssh hadoop103
ttshe@hadoop103's password: 
Last login: Sat Apr 20 18:11:17 2019 from 192.168.1.1
[ttshe@hadoop103 ~]$ 
```

注意，不光是可以连接不同的机器，也可以远程连接当前的机器，这样也便于将脚本统一规划编写



### 无秘钥配置

原理如下

<img src="img/hadoop/02.hadoop%E5%85%A5%E9%97%A817.png" alt="1555817915559" style="zoom: 33%;" />



- 生成公钥私钥

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/ttshe/.ssh/id_rsa):
```

​	键入三个回车，生成的公钥和私钥存放在.ssh文件夹下，id_rsa.pub的表示公钥，id_rsa表示私钥

```shell
[ttshe@hadoop102 .ssh]$ pwd
/home/ttshe/.ssh
[ttshe@hadoop102 .ssh]$ ll
总用量 12
-rw-------. 1 ttshe ttshe 1679 4月  21 11:39 id_rsa
-rw-r--r--. 1 ttshe ttshe  397 4月  21 11:39 id_rsa.pub
-rw-r--r--. 1 ttshe ttshe 1215 4月  20 21:01 known_hosts
```

- .ssh 文件夹下的文件说明

| 名称            | 描述                                    |
| --------------- | --------------------------------------- |
| known_hosts     | 记录ssh访问过计算机的公钥（public key） |
| id_rsa          | 生成的私钥                              |
| id_rsa.pub      | 生成的公钥                              |
| authorized_keys | 存放授权过的无密登录服务器的公钥        |

- 将公钥分发到目标机器上

```shell
[ttshe@hadoop102 .ssh]$ ssh-copy-id hadoop104
[ttshe@hadoop102 .ssh]$ ssh-copy-id hadoop103
[ttshe@hadoop102 .ssh]$ ssh-copy-id hadoop102
[ttshe@hadoop102 .ssh]$ ll
总用量 16
-rw-------. 1 ttshe ttshe  397 4月  21 11:44 authorized_keys
-rw-------. 1 ttshe ttshe 1679 4月  21 11:39 id_rsa
-rw-r--r--. 1 ttshe ttshe  397 4月  21 11:39 id_rsa.pub
-rw-r--r--. 1 ttshe ttshe 1215 4月  20 21:01 known_hosts
[ttshe@hadoop102 .ssh]$ cat authorized_keys 
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA0j5vpr8DffvTkzBKcQXlvDwqCpj0Tt2z8moo1Yl6U+CHNhbg82nHJNbhBeN1b35+I37Y74UktGHM66MffS3I1GbKd3uF5aN9PCPWLLt9DcGrtsuQC94DvTpOfE0YptmBn6H8sjLrMtW1lxwTFHeoGBt/+depT2HAGvqQ44hUtrYSWivUr8CB1Mh2mrqwdWidZbqcDdJOy0plinmAhbjnoqThNsmTMYo8f1E20i7GtE4MY2btbNp7RW9ywtHQyDbVKWUU5QdTUCNfLxWgMMo0Eik5BcytfLBYizmsqYtLlTmI7t5JEzmPJKt+jO2I2y7WNFsZWekcRySKVAd/aYV4bw== ttshe@hadoop102
```

​	分发完成会看到公钥存储在对应的机器上

- 配置root的免密登录

  对于root用户而言，是没有认证信息的，说root用户不能通过免密登录其他主机，需要再次配置一遍

```shell
[root@hadoop103 home]# cd ~
[root@hadoop103 ~]# pwd
/root
[root@hadoop103 ~]# cd .ssh
[root@hadoop103 .ssh]# ll
总用量 4
-rw-r--r--. 1 root root 405 4月  20 19:04 known_hosts
[root@hadoop103 .ssh]# pwd
/root/.ssh
```

​	具体命令

```shell
[root@hadoop103 .ssh]# ssh-keygen -t rsa
[root@hadoop103 .ssh]# ssh-copy-id hadoop104
[root@hadoop103 .ssh]# ssh-copy-id hadoop103
[root@hadoop103 .ssh]# ssh-copy-id hadoop102
```



## 群起集群



### 配置slaves

> 比较简单，配置相应的hostname即可，但是要注意slaves是作为shell脚本的入参，不能在hostname后有空格以及换行，否则会将空格和换行作为hostname为入参的。

```shell
[ttshe@hadoop102 ~]$ cd /opt/module/hadoop-2.7.2/etc/hadoop
[ttshe@hadoop102 hadoop]$ vi slaves
[ttshe@hadoop102 hadoop]$ cat slaves 
hadoop102
hadoop103
hadoop104
```

注意：该文件中添加的内容结尾不能有空格，文件中不能有空行

同步所有节点的配置文件，同步完成后检查一下

```shell
[ttshe@hadoop102 hadoop]$ xsync slaves 
```



### 启动集群

> 如果是第一次启动，需要格式化NameNode

-  注意格式化之前需要先停止活动所有的NameNode和DataNode进程
- 删除data和log数据



### 启动HDFS `start-dfs.sh`

在NameNode节点上启动其他从机的dataNode 以及 secondaryNameNode

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh 
Starting namenodes on [hadoop102]
hadoop102: starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-namenode-hadoop102.out
hadoop104: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-datanode-hadoop104.out
hadoop102: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-datanode-hadoop102.out
hadoop103: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-datanode-hadoop103.out
Starting secondary namenodes [hadoop104]
hadoop104: starting secondarynamenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-secondarynamenode-hadoop104.out
```

然后使用jps查看各个服务器节点是否启动成功，如

```shell
[ttshe@hadoop104 hadoop-2.7.2]$ jps
9592 SecondaryNameNode
9482 DataNode
9645 Jps
```



### 启动YARN `start-yarn.sh`

> 注意NameNode和ResourceManager不是在同一台机器上，不能在NameNode上启动YARN，应该在ResourceManager所在的机器上启动

```shell
[ttshe@hadoop103 hadoop-2.7.2]$ sbin/start-yarn.sh
```



### web查看SNameNode

- 在浏览器中：http://hadoop104:50090/status.html

<img src="img/hadoop/02.hadoop%E5%85%A5%E9%97%A818.png" alt="1555829271421" style="zoom: 67%;" />



### 基本测试

- 上传文件到集群

```shell
# 上传小文件
[ttshe@hadoop102 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/ttshe/input
[ttshe@hadoop102 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input /user/ttshe/input
# 上传大文件
[ttshe@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz /user/ttshe/input
```

可以在http://hadoop102:50070/explorer.html#/user/ttshe/input上看到相应的记录

- 查看上传完成的文件所在的位置
  - 查看HDFS文件存储路径
  - 查看HDFS在磁盘中存储的内容

```shell
[ttshe@hadoop102 subdir0]$ pwd
/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-1602399591-192.168.1.102-1555816186845/current/finalized/subdir0/subdir0
# 查看内容
[ttshe@hadoop102 subdir0]$ ll
总用量 208712
-rw-rw-r--. 1 ttshe ttshe        66 4月  21 14:52 blk_1073741825
-rw-rw-r--. 1 ttshe ttshe        11 4月  21 14:52 blk_1073741825_1001.meta
-rw-rw-r--. 1 ttshe ttshe 134217728 4月  21 14:54 blk_1073741826
-rw-rw-r--. 1 ttshe ttshe   1048583 4月  21 14:54 blk_1073741826_1002.meta
-rw-rw-r--. 1 ttshe ttshe  77829046 4月  21 14:54 blk_1073741827
-rw-rw-r--. 1 ttshe ttshe    608047 4月  21 14:54 blk_1073741827_1003.meta
[ttshe@hadoop102 subdir0]$ cat blk_1073741825
hadoop yarn
hadoop mapreduce
study
deep-learning
ttshe
dd
atguigu
```

执行计算单词数目

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
[ttshe@hadoop102 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/output/*
```



## 集群启动/停止总结

- 各个服务组件依次逐一启动/停止
  - 分别启动/停止 HDFS 组件
    hadoop-daemon.sh start/stop namenode/datanode/secondarynamenode
  - 启动/停止 YARN
    yarn-daemon.sh start/stop resourcemanager/nodemanager
- 各个模块分开启动/停止（配置ssh为前提）常用
  - 整体启动/停止 HDFS
    start-dfs.sh / stop-dfs.sh
  - 整体启动/停止 YARN
    start-yarn.sh / stop-yarn.sh



## 集群时间同步

> 不同的机器在规定的时间点上进行时间的校对工作，以一台机器为标准，使用crontab设置定时，使用ntp服务进行时间的校对



![1555831904472](img/hadoop/02.hadoop%E5%85%A5%E9%97%A819.png)



### 配置时间服务器

> 注意：要是root用户才可以进行操作

- 检查ntp是否安装

```shell
[ttshe@hadoop102 hadoop-2.7.2]$ rpm -qa | grep ntp
ntp-4.2.6p5-15.el6.centos.x86_64
fontpackages-filesystem-1.41-1.1.el6.noarch
ntpdate-4.2.6p5-15.el6.centos.x86_64
```

- 修改ntp配置文件

```shell
[root@hadoop102 hadoop-2.7.2]$ vi /etc/ntp.conf 
# 修改的地方有3个
# 第一个，修改指定的网段的服务可以获取时间服务
 17 # Hosts on local network are less restricted. 
 18 restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap

# 第二个，集群在局域网中，不使用互联网上的时间，注释掉配置
 22 #server 0.centos.pool.ntp.org iburst
 23 #server 1.centos.pool.ntp.org iburst
 24 #server 2.centos.pool.ntp.org iburst
 25 #server 3.centos.pool.ntp.org iburst

# 第三个，当该网络节点丢失网络连接，依然可以采用本地的时间作为时间服务器为集群中的其他节点提供时间同步服务，添加如下配置，stratum表示准确度，15个等级。可以查询扩展的参考资料
 55 server 127.127.1.0
 56 fudge 127.127.1.0 stratum 10 
```

- 修改/etc/sysconfig/ntpd 文件

```shell
[root@hadoop102 hadoop-2.7.2]# vim /etc/sysconfig/ntpd
# 增加如下内容，让硬件时间和系统时间一起同步
SYNC_HWCLOCK=yes
```

- 重新启动ntpd服务，并设置开机启动

```shell
[root@hadoop102 hadoop-2.7.2]# service ntpd status
ntpd 已停
[root@hadoop102 hadoop-2.7.2]# service ntpd start
正在启动 ntpd：                                            [确定]
[root@hadoop102 hadoop-2.7.2]# chkconfig ntpd on
```



### 其他服务器配置

> 其他服务器要配置10分钟与时间服务器同步一次
> 注意要在root用户下进行配置

```shell
[root@hadoop103 hadoop-2.7.2]$ crontab -e
# 添加配置
*/10 * * * * /usr/sbin/ntpdate hadoop102
```

测试：修改任意时间，等待验证是否更新

```shell
[root@hadoop103 hadoop-2.7.2]# date -s "2017-9-11 11:11:11"
2017年 09月 11日 星期一 11:11:11 CST
[root@hadoop103 hadoop-2.7.2]# date
2017年 09月 11日 星期一 11:11:13 CST
```



# 训练

按照如下配置hadoop集群

|      | hadoop105         | hadoop106   | hadoop107       |
| ---- | ----------------- | ----------- | --------------- |
| HDFS | SecondaryNameNode | NameNode    |                 |
|      | DataNode          | DataNode    | DataNode        |
| YARN |                   |             | ResourceManager |
|      | NodeManager       | NodeManager | NodeManager     |



# 基本命令总结



## 格式化NameNode

```bash
hadoop namenode -format
#也可以输入命令bin/hdfs namenode -format
```



> 各个服务组件依次逐一启动/停止

## 启动HDFS

```bash
# 启动namenode
hadoop-daemon.sh start namenode

# 启动datanode
hadoop-daemon.sh start datanode

# 启动secondarynamenode
hadoop-daemon.sh start secondarynamenode
```



## 停止HDFS

```bash
# 关闭namenode
hadoop-daemon.sh stop namenode

# 关闭datanode
hadoop-daemon.sh stop datanode

# 关闭secondarynamenode
hadoop-daemon.sh stop secondarynamenode
```



## 启动YARN

```bash
# 启动resourcemanager
yarn-daemon.sh start resourcemanager

# 启动nodemanager
yarn-daemon.sh start nodemanager
```



## 停止YARN

```bash
# 停止 resourcemanager
yarn-daemon.sh stop resourcemanager

# 停止 nodemanger
yarn-daemon.sh stop nodemanager
```



> 配置SSH为前提

## 整体启动HDFS

```bash
start-dfs.sh
```



## 整体停止HDFS

```bash
stop-dfs.sh
```



## 整体启动YARN

```bash
start-yarn.sh
```



## 整体停止YARN

```bash
stop-yarn.sh
```



# 访问页面



## NameNode

http://hadoop102:50070/dfshealth.html#tab-overview



## SecondaryNameNode

http://hadoop104:50090/status.html



## ResourceManager

http://hadoop103:8088/cluster



## 历史服务器

http://hadoop101:19888/jobhistory