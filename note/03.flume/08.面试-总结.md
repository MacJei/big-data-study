# 面试



## wait和sleep的区别

- wait
  - 释放锁
  - 调用者是对象，==调用对象的线程==进行wait操作
- sleep
  - 不释放锁
  - 调用者是类对象Thread，==调用的当前线程==进行sleep操作



## 如何实现Flume数据传输的监控

- 使用第三方框架Ganglia实时监控Flume



## Flume的Source，Sink，Channel的作用

- Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy

- Channel组件对采集到的数据进行缓存
  - 可以存放在Memory或File中
- Sink组件是用于把数据发送到目的地的组件
  - 目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义



## Source是什么类型

- 我公司采用的Source类型为
  - 监控后台日志：exec
  - 监控后台产生日志的端口
    - netcat
    - Exec
    - spooldir



## Flume参数调优

- Source
  - 增加Source个数
    - 使用Tair Dir Source时可增加FileGroups个数
    - 可以增大Source的读取数据的能力
  - 例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据

- batchSize
  - 决定Source一次批量运输到Channel的event条数
  - 适当调大该参数可以提高Source搬运Event到Channel时的性能
  - 参数决定Sink一次批量从Channel读取的event条数
  - 适当调大这个参数可以提高Sink从Channel搬出event的性能

- Channel 
  - type 选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据
  - type选择file时Channel的容错性更好，但是性能上会比memory channel差
    - 使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能

- Capacity
  - 决定Channel可容纳最大的event条数
- transactionCapacity 
  - 决定每次Source往channel里面写的最大event条数
  - 每次Sink从channel里面读的最大event条数
  - transactionCapacity需要大于Source和Sink的batchSize参数

- Sink 
  - 增加Sink的个数可以增加Sink消费event的能力
  - Sink也不是越多越好够用就行
  - 过多的Sink会占用系统资源，造成系统资源不必要的浪费



## Flume的事务机制

- 类似数据库的事务机制
- Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递
- 比如spooling directory source 为文件的每一行创建一个事件
- 一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成
- 事务以类似的方式处理从Channel到Sink的传递过程
  - 如果因为某种原因使得事件无法记录，那么事务将会回滚
- 所有的事件都会保持到Channel中，等待重新传递



## Flume采集数据会丢失吗

- 使用memoryChannel会丢失
  - 解决
    - Channel存储可以存储在File中，数据传输自身有事务



# 总结

- 定义
- 高可靠，高可用，海量日志数据采集聚合系统，可传输数据
- ==修改配置文件后会自动重新读取重置agent==
  - 默认开启的配置，可关闭，查询官网
  - 设置-Dflume.root.logger=DEBUG,console显示日志

```log
2020-01-19 21:17:23,591 (conf-file-poller-0) [DEBUG - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:127)] Checking file:job/flume2hdfs.conf for changes
```

- 组件

  - Agent
  - Source
  - Sink
  - Channel

- 流程

  ![1](img/26.png)

- 自定义

- 优点

  - 数据采集的多样化
  - 解耦，如下解耦
    - 数据的来源
    - 数据的目标
  - 数据不丢失
    - 使用FileChannel
  - 传输的组合很多

- 缺点

  - 数据无法保存
    - flume是传输工具，不进行保存
    - 无法做延时获取
  - 增加消费者
    - 增加channel，增加sink
      - 增加性能消耗，数据冗余
    - 需要修改配置
      - 需要重启
        - 影响到了之前的消费者
      - 违背了OCP的原则（开放封闭原则）
  - 消费者想要重复消费做不到
  - 解决：和kafka配合使用

