# Hadoop 入门

## 大数据概论

> big data 指**无法再一定时间范围**内用常规软件工具进行捕捉，管理和处理的数据集合，需要新处理模式才能具有更强的决策力，洞察发现力，流程优化能力的**海量，高增长率和多样化的信息资产**。

主要解决：海量数据的==存储==，海量数据的==分析计算==问题

存储单位：bit，Byte，KB，MB，GB，**TB**，**PB**，**EB**，ZB

- 1 TB = 1024GB

- 1 PB = 1024TB



### 大数据特点 4V

- Volume 大量，目前，人类的所有印刷的数据量是200PB，历史上人类的总共说过的话的数据量大约是5EB，典型的个人计算机银盘的容量为TB量级，企业已接近EB

- Velocity 高速，大数据区别于传统数据的显著特征，从海量数据中快速获取期望的数据，数据处理的高效。

- Variety 多样

  - 结构化数据：数据库，文本
  - 非结构化数据：网络日志，音频，视频，图片，地理位置等

- Value 低价值密度，价值密度大小与数据总量大小成反比，最有价值的数据比较小，如何对有价值的数据提纯是当前大数据急需要解决的问题。

  
### 应用场景

- 物流仓储：大数据分析系统助力商家精细化运营，提升销量，节约成本

- 零售：分析用户消费习惯，给用户购买商品提供方便，提升商品销量

  - 典型案例：纸尿布+啤酒，在纸尿布的销量和啤酒的销量成正比，原因是有孩子的家庭买纸尿布的人是男性，从而一般会购买啤酒，那么将纸尿布和啤酒摆放的位置接近，可以提升销量。

- 旅游：深度结合大数据能力和旅游业的需求，共建旅游产业的智慧管理，智慧服务，智慧营销的未来

- 商品广告推荐：给用户推荐可能喜欢的商品

- 保险：海量数据挖掘以及风险预测，助力保险行业精准营销，提升精细化定价能力

- 金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险

- 房产：大数据全面助力房地产行业，打造精准营销，选择合适的地，建造合适楼，卖给合适的人

- 人工智能

  


### 大数据部门业务流程

- 产品人员提出需求（统计总用户数，日活跃用户数，回流用户数等）

- 数据部门搭建数据平台，分析数据指标

- 数据可视化（报表展示，邮件发送，大屏幕显示）

  


### 大数据部门组织结构

![1554542264243](img\hadoop\1.部门组织架构.jpg)



## 大数据生态 （Hadoop生态圈）

### Hadoop框架

- 一个由Apache基金会所开发的分布式系统基础架构

- 处理海量数据的==存储==，海量数据的==分析计算==问题

- 广义上而言，Hadoop通常是指一个更广泛的概念---Hadoop生态圈

![1554542688682](img\hadoop\02.hadoop入门02.png)



### Hadoop发展历史

- Lucene框架是Doug Cutting使用java开发的开源软件，实现与Google类似的全文搜索功能，提供了全文检索引擎架构，包括完整的查询引擎和索引引擎

- 2001年底Lucene成为Apache基金会的子项目

- 对于海量数据，Lucene面对与Google同样的困难，数据**存储困难**，**检索速度慢**

- 学习和模仿谷歌解决这些问题：微型版Nutch

- Google是Hadoop的思想之源，Google的三篇大数据论文

  - GFS —>HDFS
  - Map-Reduce —> MR
  - BigTable —>HBase

- 2003-2004，Google公开了部分GFS和MapReduce的思想细节，以此为基础Doug Cutting用业余时间完成了DFS以及MapReduce机制，使得Nutch性能飙升

- 2005年，Hadoop作为Lucene的子项目Nutch的一部分引入Apache基金会

- 2006年，Map-Reduce和Nutch Distributed File System （NDFS）分别被纳入到Hadoop中

- Hadoop来源是Doug Cutting儿子的玩具大象

  

### Hadoop三大发行版本

- Apache 版本：最基础，最原始的版本，入门学习使用
  - Apache Hadoop
  - 官网：http://hadoop.apache.org/releases.html
  - 下载：https://archive.apache.org/dist/hadoop/common/
- Cloudera 在中大型互联网企业中用的较多
  - 2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要包括支持，咨询服务，培训
  - 2009年，Hadoop创始人Doug Cutting加盟Cloudera公司
  - Cloudera公司产品主要为**CDH**，Cloudera Manager，Cloudera Support
  - CDH 是 Cloudera公司的Hadoop发行版本，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强
  - Cloudera Manager是集群的软件分发以及管理监控平台，可以在几个小时部署好一个Hadoop集群，并对集群节点以及服务进行实时监控
  - Cloudera Support 是对Hadoop的技术支持
  - Cloudera 开发并贡献了可实时处理大数据的Impala项目
  - 官网：https://www.cloudera.com/downloads/cdh/5-10-0.html
  - 下载：http://archive-primary.cloudera.com/cdh5/cdh/5/
- Hortonworks 文档较好
  - 2011年成立，是雅虎和谷歌风投公司Benchmark Capital合资组建
  - **公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码**
  - Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统
  - HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒
  - Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的Microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元
  - 官网：https://hortonworks.com/products/data-center/hdp/
  - 下载：https://hortonworks.com/downloads/#data-platform



### Hadoop优势

- 高可靠性：Hadoop底层维护多个数据副本，即使Hadoop某个计算单元出现故障，也不会导致数据丢失
- 高扩展性：在集群间分配任务数据，可以方便的扩展节点
- 高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度
- 高容错性：可以自动将失败的任务重新分配



### Hadoop组成

Hadoop1.x 和Hadoop 2.x的区别

![1554545221451](img\hadoop\02.hadoop入门03.png)

在Hadoop1.x的时候，MapReduce同时处理业务逻辑运算和资源调度，耦合性比较大，在Hadoop2.x的时候，增加了Yarn负责资源调度，而MapReduce只负责运算。



#### HDFS 架构

> Hadoop Distributed File System 分布式文件系统

- NameNode：nn 
  - 存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间，副本数，文件权限）
  - 存储每个文件块列表，块所在的DataNode等
  - 类似索引
- DataNode：dn

  - 在本地文件系统存储文件块数据，以及块数据的校验和
- Secondary NameNode：2nn
  - 监控HDFS状态的辅助后台程序

  - 每隔一段时间获取HDFS元数据的快照

    

#### Yarn 架构

![1554545941269](img\hadoop\02.hadoop入门04.png)



#### MapReduce架构

> 将计算过程分为2个阶段：map阶段，reduce阶段

- map阶段：并行处理输入数据

- reduce阶段：对map的结果进行汇总

  

### 大数据技术生态体系

![1554547844720](img\hadoop\02.hadoop入门05.png)

- Sqoop

  - 开源工具，主要在Hadoop，Hive与传统的数据库（Mysql）间进行数据传输，可以将一个关系型数据库中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中
- Flume
  - Cloudera提供的一个高可用，高可靠的分布式**海量日志**采集，集合，传输的系统，支持在日志系统中定制各种数据发送方，用于收集数据
  - 提供堆数据进行简单处理，并写入到各种数据接收方（可定制）的能力
- Kafka
  - 一种高吞吐量的分布式发布订阅消息系统
  - 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于刚数据在TB的消息存储也可以有长时间的稳定性
  - 高吞吐量：即使非常普通的硬件，Kafka也可以支持每秒百万的消息
  - 支持通过Kafka服务器和消费机集群来区分消息
  - 支持Hadoop**并行数据**加载
- Storm

  - 用于连续计算，对数据流进行连续查询，在计算时就将结果以流的形式输出给用户
- Spark

  - 当前最流行的开源大数据**内存计算**框架，就Hadoop上存储的大数据进行计算
- Oozie

  - 一个管理Hadoop作业（job）的工作流程调度管理系统
- Hbase
  - 分布式，面向列的开源数据库
  - 不同一般的关系型数据库，它适合于非结构化数据存储的数据库
- Hive
  - 基于Hadoop的一个**数据仓库工具**
  - 将结构化的数据映射为一张数据库表，提供简单的SQL查询功能，将SQL语句转换为MapReduce任务进行运行
  - 学习成本低，可以通过SQL快速实现简单的MapReduce统计，不用开发专门的MapReduce应用，适合数据仓库的统计分析
- R语言
  - 用于统计分析，绘图的语言，统计计算和统计制图的优秀工具
  - 属于GNU系统的一个自由，免费，源代码开放的软件
- Mahout

  - Apache Mahout 是一个可扩展的机器学习和数据挖掘库
- Zookeeper
  - Google的Chubby一个开源的实现

  - 针对大型分布式系统的可靠性协调系统

  - 功能：配置维护，名字服务，分布式同步，组服务等

  - 封装好复杂易出错的关键服务，将简单易用的接口和性能高效，功能稳定的系统提供给用户。

    

### 推荐系统架构图

![1554549003576](img\hadoop\02.hadoop入门06.png)



## Hadoop 运行环境搭建（重点）



### 虚拟机环境准备

- 克隆虚拟机

  - 选中VM左侧边框栏中要克隆的虚拟机：鼠标右键-> 管理 -> 克隆
  - 弹出对话框：下一步 -> 下一步 - 克隆类型：创建完整克隆，下一步- 填写虚拟机名称与路径，点击完成。

- 修改克隆虚拟机静态IP

  - 使用root登录后，输入命令 vim /etc/udev/rules.d/70-persistent-net.rules 对ip进行修改

    ```shell
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:d1:82:07", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
    
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:06:23:4e", ATTR{type}=="1", KERNEL=="eth*", NAME="eth1"
    ```

  - 删除 eth0 配置项，并将eth1的配置项的NAME改为eth0，并复制修改后该记录的ATTR的值(00:0c:29:06:23:4e)，修改后如下

    ```shell
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:06:23:4e", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
    ```

  - 命令修改IP和MAC地址，输入命令：vim /etc/sysconfig/network-scripts/ifcfg-eth0

    ```shell
    DEVICE=eth0
    HWADDR=00:0C:29:D1:82:07
    TYPE=Ethernet
    UUID=fa28742b-9453-4009-8074-1f2c21a83305
    ONBOOT=yes
    NM_CONTROLLED=yes
    BOOTPROTO=static
    IPADDR=192.168.1.100
    GATEWAY=192.168.1.2
    DNS1=114.114.114.114
    DNS2=8.8.8.8
    ```

    - 修改MAC地址，将HWADDR的值替换为复制的ATTR的值
    - 修改IP地址，这里将IPADDR修改为192.168.1.101

- 修改主机名

  - 输入命令：vim /etc/sysconfig/network

    ```shell
    NETWORKING=yes
    HOSTNAME=hadoop100
    ```

    - 这里将主机名称修改为hadoop101

  - 配置hosts，输入命令：vim /etc/hosts

    ```shell
    127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    192.168.1.100 hadoop100
    192.168.1.101 hadoop101
    192.168.1.102 hadoop102
    192.168.1.103 hadoop103
    192.168.1.104 hadoop104
    192.168.1.105 hadoop105
    192.168.1.106 hadoop106
    192.168.1.107 hadoop107
    192.168.1.108 hadoop108
    ```

    - 这里额外配置了其他主机和ip，以后会用到的映射

- 关闭防火墙

- 创建一个测试用户，如ttshe，配置用户具有root权限

- 在/opt目录下创建文件夹module，software，修改文件夹所有者为ttshe

  ```shell
  [ttshe@hadoop101 opt]$ mkdir module
  mkdir: 无法创建目录"module": 权限不够
  [ttshe@hadoop101 opt]$ sudo mkdir module software
  [sudo] password for ttshe: 
  [ttshe@hadoop101 opt]$ ll
  总用量 12
  drwxr-xr-x. 2 root root 4096 4月   7 11:44 module
  drwxr-xr-x. 2 root root 4096 10月  4 2017 rh
  drwxr-xr-x. 2 root root 4096 4月   7 11:44 software
  # 此时创建成功，但是所属主仍然是root，需要修改这2个文件的权限
  [ttshe@hadoop101 opt]$ sudo chown ttshe:ttshe module/ software/
  [ttshe@hadoop101 opt]$ ll
  总用量 12
  drwxr-xr-x. 2 ttshe ttshe 4096 4月   7 11:44 module
  drwxr-xr-x. 2 root  root  4096 10月  4 2017 rh
  drwxr-xr-x. 2 ttshe ttshe 4096 4月   7 11:44 software
  ```

- 重启服务：reboot

  - 输入ifconfig查看ip和mac是否修改成功
  - 使用主机和虚拟机相互ping一下，查看是否连通

- 删除克隆

  - 选中VM左侧边框栏中要删除的虚拟机，鼠标右键-> 管理 -> 从磁盘中删除

    

### 安装JDK

- 卸载现有JDK

  - 查询是否安装了Java，输入命令：rpm -qa | grep java
  ```shell
  [ttshe@hadoop101 opt]$ rpm -qa | grep java
  tzdata-java-2018i-1.el6.noarch
  java-1.6.0-openjdk-1.6.0.41-1.13.13.1.el6_8.x86_64
  java-1.7.0-openjdk-1.7.0.211-2.6.17.1.el6_10.x86_64
  ```

  - 如果JDK低于1.8版本，则卸载：sudo rpm -e 软件包

- 安装JDK，使用rz命令将JDK包传入opt的software目录下

  ```shell
  [ttshe@hadoop101 software]$ ll
  总用量 388252
  -rw-r--r--. 1 ttshe root 212046774 5月  23 2017 hadoop-2.7.2.tar.gz
  -rw-r--r--. 1 ttshe root 185515842 8月  19 2017 jdk-8u144-linux-x64.tar.gz
  ```

  - 解压缩JDK到module文件夹下

  ```shell
  [ttshe@hadoop101 software]$ tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/
  ```

- 配置环境变量

  - 获取JDK路径

  ```shell
  [ttshe@hadoop101 module]$ cd jdk1.8.0_144/
  [ttshe@hadoop101 jdk1.8.0_144]$ pwd
  /opt/module/jdk1.8.0_144
  ```

  - 打开/etc/profile文件

  ```shell
  [ttshe@hadoop101 jdk1.8.0_144]$ sudo vi /etc/profile
  # 在profile文件底部添加
  #JAVA_HOME
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  export PATH=$PATH:$JAVA_HOME/bin
  ```

  - 保存后退出，并执行：source  /etc/profile
  - 测试JDK是否安装成功，如果没有生效，尝试重启一下

  ```shell
  [ttshe@hadoop101 jdk1.8.0_144]$ source /etc/profile
  [ttshe@hadoop101 jdk1.8.0_144]$ java -version
  java version "1.8.0_144"
  Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
  Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
  ```



### 安装Hadoop

- 下载地址：https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/

- 使用rz命令，将tar包放入到opt/software下

- 解压到opt/module下

  ```shell
  [ttshe@hadoop101 software]$ tar -zvxf hadoop-2.7.2.tar.gz -C /opt/module/
  ```

- 配置环境变量

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ pwd
  /opt/module/hadoop-2.7.2
  [ttshe@hadoop101 hadoop-2.7.2]$ sudo vi /etc/profile
  # 在profile文件最后添加
  # HADOOP_HOME
  export HADOOP_HOME=/opt/module/hadoop-2.7.2
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  # 保存后退出
  [ttshe@hadoop101 hadoop-2.7.2]$ source /etc/profile
  ```

- 测试是否安装成功

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ hadoop version
  Hadoop 2.7.2
  Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41
  ```



### Hadoop 目录结构

- 查看Hadoop目录结构

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ ll
  总用量 52
  # bin目录：存放Hadoop相关服务（HDFS，YARN）进行操作的脚本
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 bin
  # etc目录：Hadoop的配置文件目录
  drwxr-xr-x. 3 ttshe root  4096 1月  26 2016 etc
  # include 目录：包含外部调用的文件，如C的.h文件
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 include
  # lib目录：存放Hadoop的本地库（对数据进行压缩解压功能）
  # hadoop有些压缩解压的功能没有支持，使用自己编译的动态编译库来支持
  drwxr-xr-x. 3 ttshe root  4096 1月  26 2016 lib
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 libexec
  -rw-r--r--. 1 ttshe root 15429 1月  26 2016 LICENSE.txt
  -rw-r--r--. 1 ttshe root   101 1月  26 2016 NOTICE.txt
  -rw-r--r--. 1 ttshe root  1366 1月  26 2016 README.txt
  # sbin目录：存放启动或停止Hadoop相关服务的脚本
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 sbin
  # share目录：存放hadoop的依赖jar包，文档，官方案例
  drwxr-xr-x. 4 ttshe root  4096 1月  26 2016 share
  ```

- 查看bin目录

  ```shell
  [ttshe@hadoop101 bin]$ ll
  总用量 452
  -rwxr-xr-x. 1 ttshe root 160351 1月  26 2016 container-executor
  -rwxr-xr-x. 1 ttshe root   6488 1月  26 2016 hadoop # 
  -rwxr-xr-x. 1 ttshe root   8786 1月  26 2016 hadoop.cmd
  -rwxr-xr-x. 1 ttshe root  12223 1月  26 2016 hdfs # 
  -rwxr-xr-x. 1 ttshe root   7478 1月  26 2016 hdfs.cmd
  -rwxr-xr-x. 1 ttshe root   5953 1月  26 2016 mapred
  -rwxr-xr-x. 1 ttshe root   6310 1月  26 2016 mapred.cmd
  -rwxr-xr-x. 1 ttshe root   1776 1月  26 2016 rcc
  -rwxr-xr-x. 1 ttshe root 205195 1月  26 2016 test-container-executor
  -rwxr-xr-x. 1 ttshe root  13352 1月  26 2016 yarn #
  -rwxr-xr-x. 1 ttshe root  11386 1月  26 2016 yarn.cmd
  ```

- 查看sbin目录

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ cd sbin/
  [ttshe@hadoop101 sbin]$ ll
  总用量 120
  -rwxr-xr-x. 1 ttshe root 2752 1月  26 2016 distribute-exclude.sh
  -rwxr-xr-x. 1 ttshe root 6452 1月  26 2016 hadoop-daemon.sh # 
  -rwxr-xr-x. 1 ttshe root 1360 1月  26 2016 hadoop-daemons.sh
  -rwxr-xr-x. 1 ttshe root 1640 1月  26 2016 hdfs-config.cmd
  -rwxr-xr-x. 1 ttshe root 1427 1月  26 2016 hdfs-config.sh
  -rwxr-xr-x. 1 ttshe root 2291 1月  26 2016 httpfs.sh
  -rwxr-xr-x. 1 ttshe root 3128 1月  26 2016 kms.sh
  -rwxr-xr-x. 1 ttshe root 4080 1月  26 2016 mr-jobhistory-daemon.sh
  -rwxr-xr-x. 1 ttshe root 1648 1月  26 2016 refresh-namenodes.sh
  -rwxr-xr-x. 1 ttshe root 2145 1月  26 2016 slaves.sh
  -rwxr-xr-x. 1 ttshe root 1779 1月  26 2016 start-all.cmd
  -rwxr-xr-x. 1 ttshe root 1471 1月  26 2016 start-all.sh #
  -rwxr-xr-x. 1 ttshe root 1128 1月  26 2016 start-balancer.sh
  -rwxr-xr-x. 1 ttshe root 1401 1月  26 2016 start-dfs.cmd
  -rwxr-xr-x. 1 ttshe root 3734 1月  26 2016 start-dfs.sh #
  -rwxr-xr-x. 1 ttshe root 1357 1月  26 2016 start-secure-dns.sh
  -rwxr-xr-x. 1 ttshe root 1571 1月  26 2016 start-yarn.cmd
  -rwxr-xr-x. 1 ttshe root 1347 1月  26 2016 start-yarn.sh #
  -rwxr-xr-x. 1 ttshe root 1770 1月  26 2016 stop-all.cmd
  -rwxr-xr-x. 1 ttshe root 1462 1月  26 2016 stop-all.sh
  -rwxr-xr-x. 1 ttshe root 1179 1月  26 2016 stop-balancer.sh
  -rwxr-xr-x. 1 ttshe root 1455 1月  26 2016 stop-dfs.cmd
  -rwxr-xr-x. 1 ttshe root 3206 1月  26 2016 stop-dfs.sh #
  -rwxr-xr-x. 1 ttshe root 1340 1月  26 2016 stop-secure-dns.sh
  -rwxr-xr-x. 1 ttshe root 1642 1月  26 2016 stop-yarn.cmd
  -rwxr-xr-x. 1 ttshe root 1340 1月  26 2016 stop-yarn.sh #
  -rwxr-xr-x. 1 ttshe root 4295 1月  26 2016 yarn-daemon.sh #
  -rwxr-xr-x. 1 ttshe root 1353 1月  26 2016 yarn-daemons.sh #
  ```



## Hadoop运行模式

> 浏览官网 http://hadoop.apache.org/ 
> http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html



### 本地运行模式



#### 官方grep案例

> 查阅官方案例
>
> By default, Hadoop is configured to run in a non-distributed mode, as a single Java process. This is useful for debugging.
>
> The following example copies the unpacked conf directory to use as input and then finds and displays every match of the given regular expression. Output is written to the given output directory.
>
> ```
>   $ mkdir input
>   $ cp etc/hadoop/*.xml input
>   $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar grep input output 'dfs[a-z.]+'
>   $ cat output/*
> ```

- 在hadoop目录下创建input文件夹，用于存放要分析的数据

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir input
```

- 将要分析的文件拷贝到input文件夹下

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cp etc/hadoop/*.xml input
```

- 运行hadoop命令，解析所有dfs开头的数据，同时将结果输出到output文件夹

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
```

- 查看输出

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cd output/
[ttshe@hadoop101 output]$ ll
总用量 4
-rw-r--r--. 1 ttshe root 11 4月   7 13:21 part-r-00000
-rw-r--r--. 1 ttshe root  0 4月   7 13:21 _SUCCESS
[ttshe@hadoop101 hadoop-2.7.2]$ cat output/*
1	dfsadmin
```



#### 官方wordCount案例

- 创建一个wcinput文件夹，并添加一个文件，在该文件中添加要使用的数据素材

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir wcinput
[ttshe@hadoop101 hadoop-2.7.2]$ cd wcinput/
[ttshe@hadoop101 wcinput]$ touch wc.input
[ttshe@hadoop101 wcinput]$ cat wc.input 
hadoop yarn
hadoop mapreduce
study
deep-learning
ttshe
dd
atguigu
```

- 执行命令

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput
```

- 查看结果

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cat wcoutput/*
atguigu	1
dd	1
deep-learning	1
hadoop	2
mapreduce	1
study	1
ttshe	1
yarn	1
```




### 伪分布式模式



#### 启动HDFS并运行MapReduce 程序

>  **Pseudo-Distributed Operation**
>  Hadoop can also be run on a single-node in a pseudo-distributed mode where each Hadoop daemon runs in a separate Java process.



##### 配置集群

- 配置 hadoop-env.sh
  - 这里env.sh可以看到注释上说明，只需要修改JAVA_HOME，其他都是可选的，在分布式配置的时候，需要修改JAVA_HOME
  ```shell
  [ttshe@hadoop101 hadoop]$ pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [ttshe@hadoop101 hadoop]$ echo $JAVA_HOME
  /opt/module/jdk1.8.0_144
  [ttshe@hadoop101 hadoop]$ vi hadoop-env.sh 
  # Set Hadoop-specific environment variables here.
  # The only required environment variable is JAVA_HOME.  All others are
  # optional.  When running a distributed configuration it is best to
  # set JAVA_HOME in this file, so that it is correctly defined on
  # remote nodes.
  # The java implementation to use.
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

- 配置core-site.xml

  - 关于配置项介绍，在官网配置页面的左下角可见：http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/core-default.xml

  | 参数           | 默认值                                     | 描述                                                         |
  | -------------- | ------------------------------------------ | ------------------------------------------------------------ |
  | fs.defaultFS   | file:/// 表示本地                          | The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, port, etc. for a filesystem.<br />指定HDFS中的**NameNode**的地址 |
  | hadoop.tmp.dir | /tmp/hadoop-${user.name} 表示在tmp文件夹下 | A base for other temporary directories.<br />指定Hadoop运行时产生的文件存储目录，一般需要磁盘比较大，否则文件会很多，需要搬移 |

  ```xml
  [ttshe@hadoop101 hadoop]$ vi core-site.xml 
  <configuration>
    <property>
        <name>fs.defaultFS</name>
        # 注意配置该项目后，本地模式不生效，如果还要使用本地模式，则需要去除该配置或者配置file:///
        <value>hdfs://hadoop101:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.7.2/data/tmp</value>
    </property>
  </configuration>
  ```

- 配置hdfs-site.xml
  - 在官网配置 http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml 可以查看

  | 参数            | 默认值 | 描述                                                         |
| --------------- | ------ | ------------------------------------------------------------ |
| dfs.replication | 3      | Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time.<br />指定HDFS的副本数量，只在集群中的副本的个数，因为是伪分布式配置，就一台机器，复制多余1个没有意义。 |

  ```xml
[ttshe@hadoop101 hadoop]$ vi hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
  ```



##### 启动集群

- ==格式化NameNode==（第一次启动时格式化，以后不要总格式化）

  ```shell
[ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs namenode -format
  ```

- 启动NameNode（关闭使用stop）

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode
  starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-namenode-hadoop101.out
  ```

- 启动DataNode

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode
  starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-ttshe-datanode-hadoop101.out
  ```

- 查看是否启动成功

  - 使用java的命令jps

  ```shell
  # 查看进程是否存在，存在则表示启动成功
  [ttshe@hadoop101 hadoop-2.7.2]$ jps -l
  8903 sun.tools.jps.Jps
  8680 org.apache.hadoop.hdfs.server.namenode.NameNode
  8812 org.apache.hadoop.hdfs.server.datanode.DataNode
  ```

- 通过Web查看HDFS文件系统

  访问：http://192.168.1.101:50070/dfshealth.html#tab-datanode

  推荐配置host（C:/Windows/System32/drivers/etc/hosts）

  ```shell
  192.168.1.100 hadoop100
  192.168.1.101 hadoop101
  192.168.1.102 hadoop102
  192.168.1.103 hadoop103
  192.168.1.104 hadoop104
  192.168.1.105 hadoop105
  192.168.1.106 hadoop106
  ```

  可以指定名称访问如http://hadoop101:50070/dfshealth.html#tab-datanode

  ![1554733334932](img/hadoop/02.hadoop入门07.png)

  重点关注Utilities中的Browse the file system，完全仿照Linux的目录树结构搜索数据。

- 查看日志

  ```shell
  [root@hadoop101 logs]# ll
  总用量 64
  -rw-r--r--. 1 ttshe root 24121 4月   8 00:08 hadoop-ttshe-datanode-hadoop101.log
  -rw-r--r--. 1 ttshe root   716 4月   8 00:08 hadoop-ttshe-datanode-hadoop101.out
  -rw-r--r--. 1 ttshe root 27765 4月   8 00:08 hadoop-ttshe-namenode-hadoop101.log
  -rw-r--r--. 1 ttshe root  5007 4月   8 22:24 hadoop-ttshe-namenode-hadoop101.out
  -rw-r--r--. 1 ttshe root     0 4月   8 00:06 SecurityAuth-ttshe.audit
  [root@hadoop101 logs]# pwd
  /opt/module/hadoop-2.7.2/logs
  ```

##### 操作集群

> 在HDFS系统上操作目录，和Linux上的命令一致

- 创建一个input文件夹

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -mkdir -p /user/ttshe/input
  ```

  在HDFS系统页面上可以查询得到相应的结果

  ![1554735248179](img/hadoop/02.hadoop入门08.png)

  注意Owner 和Group与Linux的区别

- 上传测试文件到HDFS中，将wcinput中的wc.input文件上传

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -put wcinput/wc.input /user/ttshe/input/
  ```

- 查看是否上传成功

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -ls /user/ttshe/input
  Found 1 items
  -rw-r--r--   1 ttshe supergroup         66 2019-04-08 22:57 /user/ttshe/input/wc.input
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/input/wc.input
  hadoop yarn
  hadoop mapreduce
  study
  deep-learning
  ttshe
  dd
  atguigu
  ```

- 运行MapReduce程序

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
  ```

- 查看结果

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/output/*
  atguigu	1
  dd	1
  deep-learning	1
  hadoop	2
  mapreduce	1
  study	1
  ttshe	1
  yarn	1
  ```

  通过浏览器可以查看

  ![1554736023270](img/hadoop/02.hadoop入门09.png)

##### 注意事项

- 不能一直格式化NameNode，格式化NameNode需要注意的事项

  ```shell
  # 查看当前name节点版本
  [root@hadoop101 current]# pwd
  /opt/module/hadoop-2.7.2/data/tmp/dfs/name/current # 在core-site.xml中配置的路径
  [root@hadoop101 current]# cat VERSION
  #Mon Apr 08 00:05:15 CST 2019
  namespaceID=392562494
  clusterID=CID-7ef31aad-4d5c-4aba-94f6-a4cfe9af7ae4
  cTime=0
  storageType=NAME_NODE
  blockpoolID=BP-1865658710-192.168.1.101-1554653114984
  layoutVersion=-63
  ```

  格式化NameNode，会产生新的集群ID，导致NameNode和DataNode的CID不一致（都在各自的current下存储），集群找不到以往数据，所以在格式化NameNode的时候，需要先删除data数据和log日志（rm -rf data/ logs/），然后再格式化NameNode

  ![1554738823304](img/hadoop/02.hadoop入门10.png)



#### 启动YARN并运行MapReduce程序

- 配置集群在YARN上运行MR
- 启动，测试集群增删改
- 在YARN上执行WordCount案例

##### 配置集群

- 配置yarn-env.sh

  - 配置参数说明：http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
  - 配置JAVA_HOME

  ```shell
  [root@hadoop101 hadoop]# pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [root@hadoop101 hadoop]# vim yarn-env.sh
  # 在23行的位置进行配置当前的JAVA_HOME
   22 # some Java parameters
   23 export JAVA_HOME=/opt/module/jdk1.8.0_144
   24 if [ "$JAVA_HOME" != "" ]; then
  ```

- 配置yarn-site.xml

  - 配置nodemanager
  - 配置resourcemanager

  ```xml
  <configuration>
      <!--reducer获取数据的方式 shuffle是mapreduce的核心，需要重点掌握的知识点 -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>
      <!-- 指定YARN的ResourceManager的地址,当前resourcemanager放在那台主机上运行 -->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hadoop101</value>
      </property>
  <!-- Site specific YARN configuration properties -->
  </configuration>
  ```

- 配置mapred-env.sh

  - 配置JAVA_HOME

  ```shell
  [root@hadoop101 hadoop]# vim mapred-env.sh
  # 可以在第16行找到注释掉的配置
  16 export JAVA_HOME=/opt/module/jdk1.8.0_144
  ```

- 配置mapred-site.xml

  - 配置参数说明：http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
  - 对mapred-site.xml.template 重命名为mapred-site.xml

  | 参数名                   | 默认值 | 说明                                                         |
  | ------------------------ | ------ | ------------------------------------------------------------ |
  | mapreduce.framework.name | local  | The runtime framework for executing MapReduce jobs. Can be one of local, classic or yarn.<br />说明默认的mapreduce是运行在本地的，这里要配置运行在yarn上 |

  ```xml
  [root@hadoop101 hadoop]# mv mapred-site.xml.template mapred-site.xml
  [root@hadoop101 hadoop]# vim mapred-site.xml 
  # 配置如下参数
  <configuration>
      <!-- 指定MR运行在YARN上 -->
      <property>
          <name>mapreduce.framework.name</name>           
          <value>yarn</value>
      </property>
  </configuration>
  ```



##### 启动集群

- 启动前必须保证NameNode和DataNode已经启动

- 启动ResourceManager

  ```shell
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh start resourcemanager
  starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-resourcemanager-hadoop101.out
  ```

- 启动NodeManager

  ```shell
  [root@hadoop101 hadoop-2.7.2]# sbin/yarn-daemon.sh start nodemanager
  starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-root-nodemanager-hadoop101.out
  ```

- 查看是否启动成功

  ```shell
  [root@hadoop101 hadoop-2.7.2]# jps
  11314 Jps
  8680 NameNode
  11178 NodeManager
  8812 DataNode
  10908 ResourceManager
  ```



##### 操作集群

- 通过Web访问YARN

  - http://hadoop101:8088/cluster

![1554822805719](img/hadoop/02.hadoop入门11.png)

- 删除系统上的output文件（之前启动HDFS运行MapReduce程序时，输出的文件，需要删除，由于下面操作MapReduce要重新生成一个output文件）

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -rm -R /user/ttshe/output
  19/04/09 23:17:04 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
  Deleted /user/ttshe/output
  ```

  - 注意用户要是创建output的用户，如ttshe，否则没有权限删除

- 执行MapReduce程序

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/ttshe/input /user/ttshe/output
  ```

- 查看结果

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -cat /user/ttshe/output/*
  atguigu	1
  dd	1
  deep-learning	1
  hadoop	2
  mapreduce	1
  study	1
  ttshe	1
  yarn	1
  ```

  ![1554823470152](img/hadoop/02.hadoop入门12.png)

  运行的过程可以在页面中观察，而History需要接下来配置就可以看到运行的记录。



##### 配置历史服务器

- 配置mapred-site.xml

  - 在原先的配置中增加历史的配置

  ```xml
  [ttshe@hadoop101 hadoop]$ pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [ttshe@hadoop101 hadoop]$ vim mapred-site.xml
  # 增加如下配置参数
  <!-- 历史服务器端地址 -->
  <property>
      <name>mapreduce.jobhistory.address</name>
      <value>hadoop101:10020</value>
  </property>
  <!-- 历史服务器web端地址 -->
  <property>
      <name>mapreduce.jobhistory.webapp.address</name>
      <value>hadoop101:19888</value>
  </property>
  ```

- 启动历史服务器

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ sbin/mr-jobhistory-daemon.sh start historyserver
  starting historyserver, logging to /opt/module/hadoop-2.7.2/logs/mapred-ttshe-historyserver-hadoop101.out
  [ttshe@hadoop101 hadoop-2.7.2]$ jps
  12208 Jps
  8680 NameNode
  8812 DataNode
  12158 JobHistoryServer
  ```

- 查看Web页面：http://hadoop101:19888/jobhistory

  ![1554824275728](img/hadoop/02.hadoop入门13.png)

  点击页面中的counters，查看MapReduce的运行情况

  ![1554824374314](img/hadoop/02.hadoop入门14.png)

  点击configuration，可以看到该job运行的配置信息

  ![1554824487172](img/hadoop/02.hadoop入门15.png)

  这里的logs需要开启配置日志信息

  

##### 配置日志的聚集	

- 概念：应用运行完成后，将程序运行日志信息上传到HDFS系统上
- 好处：用于查看程序的运行情况，方便开发调试





### 完全分布式模式











## 问题处理

- 不能通过网页查看HDFS文件系统

  解决方式：http://www.cnblogs.com/zlslch/p/6604189.html

  

- 执行hdfs命令报错：WARN util.NativeCodeLoader: Unable to load native-hadoop library

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ bin/hdfs dfs -mkdir -p /user/ttshe/input
  19/04/08 22:38:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
  # 原因是Linux的(GNU libc) 2.12 版本和Hadoop要求的`GLIBC_2.14' 版本不一致
  # 查看 Hadoop 异常信息
  [ttshe@hadoop101 native]$ pwd
  /opt/module/hadoop-2.7.2/lib/native
  [ttshe@hadoop101 native]$ ldd libhadoop.so.1.0.0 
  ./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by ./libhadoop.so.1.0.0)
  	linux-vdso.so.1 =>  (0x00007fff42ffc000)
  	libdl.so.2 => /lib64/libdl.so.2 (0x00007ffab97ee000)
  	libc.so.6 => /lib64/libc.so.6 (0x00007ffab9459000)
  	/lib64/ld-linux-x86-64.so.2 (0x000055f554143000)
  # 查看本地版本
  [ttshe@hadoop101 native]$ ldd --version
  ldd (GNU libc) 2.12
  # 可以在日志中配置忽略该错误
  [ttshe@hadoop101 hadoop]$ pwd
  /opt/module/hadoop-2.7.2/etc/hadoop
  [ttshe@hadoop101 hadoop]$ vim log4j.properties 
  log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR
  ```

  https://blog.csdn.net/u010003835/article/details/81127984

- 伪分布式
  - 在不同的用户下开启不同的服务，如在root下开启了NodeManager，那么在ttshe用户下使用jps就看不到该节点，而在ttshe下开启的节点服务，在root使用jps可以看到



















