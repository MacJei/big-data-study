# Hadoop 入门

## 大数据概论

> big data 指**无法再一定时间范围**内用常规软件工具进行捕捉，管理和处理的数据集合，需要新处理模式才能具有更强的决策力，洞察发现力，流程优化能力的**海量，高增长率和多样化的信息资产**。

主要解决：海量数据的==存储==，海量数据的==分析计算==问题

存储单位：bit，Byte，KB，MB，GB，**TB**，**PB**，**EB**，ZB

- 1 TB = 1024GB

- 1 PB = 1024TB

  

### 大数据特点 4V

- Volume 大量，目前，人类的所有印刷的数据量是200PB，历史上人类的总共说过的话的数据量大约是5EB，典型的个人计算机银盘的容量为TB量级，企业已接近EB

- Velocity 高速，大数据区别于传统数据的显著特征，从海量数据中快速获取期望的数据，数据处理的高效。

- Variety 多样

  - 结构化数据：数据库，文本
  - 非结构化数据：网络日志，音频，视频，图片，地理位置等

- Value 低价值密度，价值密度大小与数据总量大小成反比，最有价值的数据比较小，如何对有价值的数据提纯是当前大数据急需要解决的问题。

  

### 应用场景

- 物流仓储：大数据分析系统助力商家精细化运营，提升销量，节约成本

- 零售：分析用户消费习惯，给用户购买商品提供方便，提升商品销量

  - 典型案例：纸尿布+啤酒，在纸尿布的销量和啤酒的销量成正比，原因是有孩子的家庭买纸尿布的人是男性，从而一般会购买啤酒，那么将纸尿布和啤酒摆放的位置接近，可以提升销量。

- 旅游：深度结合大数据能力和旅游业的需求，共建旅游产业的智慧管理，智慧服务，智慧营销的未来

- 商品广告推荐：给用户推荐可能喜欢的商品

- 保险：海量数据挖掘以及风险预测，助力保险行业精准营销，提升精细化定价能力

- 金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险

- 房产：大数据全面助力房地产行业，打造精准营销，选择合适的地，建造合适楼，卖给合适的人

- 人工智能

  

### 大数据部门业务流程

- 产品人员提出需求（统计总用户数，日活跃用户数，回流用户数等）
- 数据部门搭建数据平台，分析数据指标
- 数据可视化（报表展示，邮件发送，大屏幕显示）



### 大数据部门组织结构

![1554542264243](img\hadoop\1.部门组织架构.jpg)



## 大数据生态 （Hadoop生态圈）

### Hadoop框架

- 一个由Apache基金会所开发的分布式系统基础架构

- 处理海量数据的==存储==，海量数据的==分析计算==问题

- 广义上而言，Hadoop通常是指一个更广泛的概念---Hadoop生态圈

![1554542688682](img\hadoop\02.hadoop入门02.png)



### Hadoop发展历史

- Lucene框架是Doug Cutting使用java开发的开源软件，实现与Google类似的全文搜索功能，提供了全文检索引擎架构，包括完整的查询引擎和索引引擎

- 2001年底Lucene成为Apache基金会的子项目

- 对于海量数据，Lucene面对与Google同样的困难，数据**存储困难**，**检索速度慢**

- 学习和模仿谷歌解决这些问题：微型版Nutch

- Google是Hadoop的思想之源，Google的三篇大数据论文

  - GFS —>HDFS
  - Map-Reduce —> MR
  - BigTable —>HBase

- 2003-2004，Google公开了部分GFS和MapReduce的思想细节，以此为基础Doug Cutting用业余时间完成了DFS以及MapReduce机制，使得Nutch性能飙升

- 2005年，Hadoop作为Lucene的子项目Nutch的一部分引入Apache基金会

- 2006年，Map-Reduce和Nutch Distributed File System （NDFS）分别被纳入到Hadoop中

- Hadoop来源是Doug Cutting儿子的玩具大象

  

### Hadoop三大发行版本

- Apache 版本：最基础，最原始的版本，入门学习使用
  - Apache Hadoop
  - 官网：http://hadoop.apache.org/releases.html
  - 下载：https://archive.apache.org/dist/hadoop/common/
- Cloudera 在中大型互联网企业中用的较多
  - 2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要包括支持，咨询服务，培训
  - 2009年，Hadoop创始人Doug Cutting加盟Cloudera公司
  - Cloudera公司产品主要为**CDH**，Cloudera Manager，Cloudera Support
  - CDH 是 Cloudera公司的Hadoop发行版本，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强
  - Cloudera Manager是集群的软件分发以及管理监控平台，可以在几个小时部署好一个Hadoop集群，并对集群节点以及服务进行实时监控
  - Cloudera Support 是对Hadoop的技术支持
  - Cloudera 开发并贡献了可实时处理大数据的Impala项目
  - 官网：https://www.cloudera.com/downloads/cdh/5-10-0.html
  - 下载：http://archive-primary.cloudera.com/cdh5/cdh/5/
- Hortonworks 文档较好
  - 2011年成立，是雅虎和谷歌风投公司Benchmark Capital合资组建
  - **公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码**
  - Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统
  - HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒
  - Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的Microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元
  - 官网：https://hortonworks.com/products/data-center/hdp/
  - 下载：https://hortonworks.com/downloads/#data-platform



### Hadoop优势

- 高可靠性：Hadoop底层维护多个数据副本，即使Hadoop某个计算单元出现故障，也不会导致数据丢失
- 高扩展性：在集群间分配任务数据，可以方便的扩展节点
- 高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度
- 高容错性：可以自动将失败的任务重新分配



### Hadoop组成

Hadoop1.x 和Hadoop 2.x的区别

![1554545221451](img\hadoop\02.hadoop入门03.png)

在Hadoop1.x的时候，MapReduce同时处理业务逻辑运算和资源调度，耦合性比较大，在Hadoop2.x的时候，增加了Yarn负责资源调度，而MapReduce只负责运算。



#### HDFS 架构

> Hadoop Distributed File System 分布式文件系统

- NameNode：nn 
  - 存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间，副本数，文件权限）
  - 存储每个文件块列表，块所在的DataNode等
  - 类似索引
- DataNode：dn
  - 在本地文件系统存储文件块数据，以及块数据的校验和
- Secondary NameNode：2nn
  - 监控HDFS状态的辅助后台程序
  - 每隔一段时间获取HDFS元数据的快照

#### Yarn 架构

![1554545941269](img\hadoop\02.hadoop入门04.png)



#### MapReduce架构

> 将计算过程分为2个阶段：map阶段，reduce阶段

- map阶段：并行处理输入数据

- reduce阶段：对map的结果进行汇总

  

### 大数据技术生态体系

![1554547844720](img\hadoop\02.hadoop入门05.png)

- Sqoop
  - 开源工具，主要在Hadoop，Hive与传统的数据库（Mysql）间进行数据传输，可以将一个关系型数据库中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中
- Flume
  - Cloudera提供的一个高可用，高可靠的分布式**海量日志**采集，集合，传输的系统，支持在日志系统中定制各种数据发送方，用于收集数据
  - 提供堆数据进行简单处理，并写入到各种数据接收方（可定制）的能力
- Kafka
  - 一种高吞吐量的分布式发布订阅消息系统
  - 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于刚数据在TB的消息存储也可以有长时间的稳定性
  - 高吞吐量：即使非常普通的硬件，Kafka也可以支持每秒百万的消息
  - 支持通过Kafka服务器和消费机集群来区分消息
  - 支持Hadoop**并行数据**加载
- Storm
  - 用于连续计算，对数据流进行连续查询，在计算时就将结果以流的形式输出给用户
- Spark
  - 当前最流行的开源大数据**内存计算**框架，就Hadoop上存储的大数据进行计算
- Oozie
  - 一个管理Hadoop作业（job）的工作流程调度管理系统
- Hbase
  - 分布式，面向列的开源数据库
  - 不同一般的关系型数据库，它适合于非结构化数据存储的数据库
- Hive
  - 基于Hadoop的一个**数据仓库工具**
  - 将结构化的数据映射为一张数据库表，提供简单的SQL查询功能，将SQL语句转换为MapReduce任务进行运行
  - 学习成本低，可以通过SQL快速实现简单的MapReduce统计，不用开发专门的MapReduce应用，适合数据仓库的统计分析
- R语言
  - 用于统计分析，绘图的语言，统计计算和统计制图的优秀工具
  - 属于GNU系统的一个自由，免费，源代码开放的软件
- Mahout
  - Apache Mahout 是一个可扩展的机器学习和数据挖掘库
- Zookeeper
  - Google的Chubby一个开源的实现
  - 针对大型分布式系统的可靠性协调系统
  - 功能：配置维护，名字服务，分布式同步，组服务等
  - 封装好复杂易出错的关键服务，将简单易用的接口和性能高效，功能稳定的系统提供给用户。

### 推荐系统架构图

![1554549003576](img\hadoop\02.hadoop入门06.png)



## Hadoop 运行环境搭建（重点）

### 虚拟机环境准备

- 克隆虚拟机

  - 选中VM左侧边框栏中要克隆的虚拟机：鼠标右键-> 管理 -> 克隆
  - 弹出对话框：下一步 -> 下一步 - 克隆类型：创建完整克隆，下一步- 填写虚拟机名称与路径，点击完成。

- 修改克隆虚拟机静态IP

  - 使用root登录后，输入命令 vim /etc/udev/rules.d/70-persistent-net.rules 对ip进行修改

    ```shell
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:d1:82:07", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
    
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:06:23:4e", ATTR{type}=="1", KERNEL=="eth*", NAME="eth1"
    ```

  - 删除 eth0 配置项，并将eth1的配置项的NAME改为eth0，并复制修改后该记录的ATTR的值(00:0c:29:06:23:4e)，修改后如下

    ```shell
    # PCI device 0x8086:0x100f (e1000)
    SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:06:23:4e", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
    ```

  - 命令修改IP和MAC地址，输入命令：vim /etc/sysconfig/network-scripts/ifcfg-eth0

    ```shell
    DEVICE=eth0
    HWADDR=00:0C:29:D1:82:07
    TYPE=Ethernet
    UUID=fa28742b-9453-4009-8074-1f2c21a83305
    ONBOOT=yes
    NM_CONTROLLED=yes
    BOOTPROTO=static
    IPADDR=192.168.1.100
    GATEWAY=192.168.1.2
    DNS1=114.114.114.114
    DNS2=8.8.8.8
    ```

    - 修改MAC地址，将HWADDR的值替换为复制的ATTR的值
    - 修改IP地址，这里将IPADDR修改为192.168.1.101

- 修改主机名

  - 输入命令：vim /etc/sysconfig/network

    ```shell
    NETWORKING=yes
    HOSTNAME=hadoop100
    ```

    - 这里将主机名称修改为hadoop101

  - 配置hosts，输入命令：vim /etc/hosts

    ```shell
    127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    192.168.1.100 hadoop100
    192.168.1.101 hadoop101
    192.168.1.102 hadoop102
    192.168.1.103 hadoop103
    192.168.1.104 hadoop104
    192.168.1.105 hadoop105
    192.168.1.106 hadoop106
    192.168.1.107 hadoop107
    192.168.1.108 hadoop108
    ```

    - 这里额外配置了其他主机和ip，以后会用到的映射

- 关闭防火墙

- 创建一个测试用户，如ttshe，配置用户具有root权限

- 在/opt目录下创建文件夹module，software，修改文件夹所有者为ttshe

  ```shell
  [ttshe@hadoop101 opt]$ mkdir module
  mkdir: 无法创建目录"module": 权限不够
  [ttshe@hadoop101 opt]$ sudo mkdir module software
  [sudo] password for ttshe: 
  [ttshe@hadoop101 opt]$ ll
  总用量 12
  drwxr-xr-x. 2 root root 4096 4月   7 11:44 module
  drwxr-xr-x. 2 root root 4096 10月  4 2017 rh
  drwxr-xr-x. 2 root root 4096 4月   7 11:44 software
  # 此时创建成功，但是所属主仍然是root，需要修改这2个文件的权限
  [ttshe@hadoop101 opt]$ sudo chown ttshe:ttshe module/ software/
  [ttshe@hadoop101 opt]$ ll
  总用量 12
  drwxr-xr-x. 2 ttshe ttshe 4096 4月   7 11:44 module
  drwxr-xr-x. 2 root  root  4096 10月  4 2017 rh
  drwxr-xr-x. 2 ttshe ttshe 4096 4月   7 11:44 software
  ```

- 重启服务：reboot

  - 输入ifconfig查看ip和mac是否修改成功
  - 使用主机和虚拟机相互ping一下，查看是否连通

- 删除克隆

  - 选中VM左侧边框栏中要删除的虚拟机，鼠标右键-> 管理 -> 从磁盘中删除

### 安装JDK

- 卸载现有JDK

  - 查询是否安装了Java，输入命令：rpm -qa | grep java
  ```shell
  [ttshe@hadoop101 opt]$ rpm -qa | grep java
  tzdata-java-2018i-1.el6.noarch
  java-1.6.0-openjdk-1.6.0.41-1.13.13.1.el6_8.x86_64
  java-1.7.0-openjdk-1.7.0.211-2.6.17.1.el6_10.x86_64
  ```

  - 如果JDK低于1.8版本，则卸载：sudo rpm -e 软件包

- 安装JDK，使用rz命令将JDK包传入opt的software目录下

  ```shell
  [ttshe@hadoop101 software]$ ll
  总用量 388252
  -rw-r--r--. 1 ttshe root 212046774 5月  23 2017 hadoop-2.7.2.tar.gz
  -rw-r--r--. 1 ttshe root 185515842 8月  19 2017 jdk-8u144-linux-x64.tar.gz
  ```

  - 解压缩JDK到module文件夹下

  ```shell
  [ttshe@hadoop101 software]$ tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/
  ```

- 配置环境变量

  - 获取JDK路径

  ```shell
  [ttshe@hadoop101 module]$ cd jdk1.8.0_144/
  [ttshe@hadoop101 jdk1.8.0_144]$ pwd
  /opt/module/jdk1.8.0_144
  ```

  - 打开/etc/profile文件

  ```shell
  [ttshe@hadoop101 jdk1.8.0_144]$ sudo vi /etc/profile
  # 在profile文件底部添加
  #JAVA_HOME
  export JAVA_HOME=/opt/module/jdk1.8.0_144
  export PATH=$PATH:$JAVA_HOME/bin
  ```

  - 保存后退出，并执行：source  /etc/profile
  - 测试JDK是否安装成功，如果没有生效，尝试重启一下

  ```shell
  [ttshe@hadoop101 jdk1.8.0_144]$ source /etc/profile
  [ttshe@hadoop101 jdk1.8.0_144]$ java -version
  java version "1.8.0_144"
  Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
  Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
  ```

### 安装Hadoop

- 下载地址：https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/

- 使用rz命令，将tar包放入到opt/software下

- 解压到opt/module下

  ```shell
  [ttshe@hadoop101 software]$ tar -zvxf hadoop-2.7.2.tar.gz -C /opt/module/
  ```

- 配置环境变量

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ pwd
  /opt/module/hadoop-2.7.2
  [ttshe@hadoop101 hadoop-2.7.2]$ sudo vi /etc/profile
  # 在profile文件最后添加
  # HADOOP_HOME
  export HADOOP_HOME=/opt/module/hadoop-2.7.2
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  # 保存后退出
  [ttshe@hadoop101 hadoop-2.7.2]$ source /etc/profile
  ```

- 测试是否安装成功

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ hadoop version
  Hadoop 2.7.2
  Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b165c4fe8a74265c792ce23f546c64604acf0e41
  ```

### Hadoop 目录结构

- 查看Hadoop目录结构

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ ll
  总用量 52
  # bin目录：存放Hadoop相关服务（HDFS，YARN）进行操作的脚本
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 bin
  # etc目录：Hadoop的配置文件目录
  drwxr-xr-x. 3 ttshe root  4096 1月  26 2016 etc
  # include 目录：包含外部调用的文件，如C的.h文件
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 include
  # lib目录：存放Hadoop的本地库（对数据进行压缩解压功能）
  # hadoop有些压缩解压的功能没有支持，使用自己编译的动态编译库来支持
  drwxr-xr-x. 3 ttshe root  4096 1月  26 2016 lib
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 libexec
  -rw-r--r--. 1 ttshe root 15429 1月  26 2016 LICENSE.txt
  -rw-r--r--. 1 ttshe root   101 1月  26 2016 NOTICE.txt
  -rw-r--r--. 1 ttshe root  1366 1月  26 2016 README.txt
  # sbin目录：存放启动或停止Hadoop相关服务的脚本
  drwxr-xr-x. 2 ttshe root  4096 1月  26 2016 sbin
  # share目录：存放hadoop的依赖jar包，文档，官方案例
  drwxr-xr-x. 4 ttshe root  4096 1月  26 2016 share
  ```

- 查看bin目录

  ```shell
  [ttshe@hadoop101 bin]$ ll
  总用量 452
  -rwxr-xr-x. 1 ttshe root 160351 1月  26 2016 container-executor
  -rwxr-xr-x. 1 ttshe root   6488 1月  26 2016 hadoop # 
  -rwxr-xr-x. 1 ttshe root   8786 1月  26 2016 hadoop.cmd
  -rwxr-xr-x. 1 ttshe root  12223 1月  26 2016 hdfs # 
  -rwxr-xr-x. 1 ttshe root   7478 1月  26 2016 hdfs.cmd
  -rwxr-xr-x. 1 ttshe root   5953 1月  26 2016 mapred
  -rwxr-xr-x. 1 ttshe root   6310 1月  26 2016 mapred.cmd
  -rwxr-xr-x. 1 ttshe root   1776 1月  26 2016 rcc
  -rwxr-xr-x. 1 ttshe root 205195 1月  26 2016 test-container-executor
  -rwxr-xr-x. 1 ttshe root  13352 1月  26 2016 yarn #
  -rwxr-xr-x. 1 ttshe root  11386 1月  26 2016 yarn.cmd
  ```

- 查看sbin目录

  ```shell
  [ttshe@hadoop101 hadoop-2.7.2]$ cd sbin/
  [ttshe@hadoop101 sbin]$ ll
  总用量 120
  -rwxr-xr-x. 1 ttshe root 2752 1月  26 2016 distribute-exclude.sh
  -rwxr-xr-x. 1 ttshe root 6452 1月  26 2016 hadoop-daemon.sh # 
  -rwxr-xr-x. 1 ttshe root 1360 1月  26 2016 hadoop-daemons.sh
  -rwxr-xr-x. 1 ttshe root 1640 1月  26 2016 hdfs-config.cmd
  -rwxr-xr-x. 1 ttshe root 1427 1月  26 2016 hdfs-config.sh
  -rwxr-xr-x. 1 ttshe root 2291 1月  26 2016 httpfs.sh
  -rwxr-xr-x. 1 ttshe root 3128 1月  26 2016 kms.sh
  -rwxr-xr-x. 1 ttshe root 4080 1月  26 2016 mr-jobhistory-daemon.sh
  -rwxr-xr-x. 1 ttshe root 1648 1月  26 2016 refresh-namenodes.sh
  -rwxr-xr-x. 1 ttshe root 2145 1月  26 2016 slaves.sh
  -rwxr-xr-x. 1 ttshe root 1779 1月  26 2016 start-all.cmd
  -rwxr-xr-x. 1 ttshe root 1471 1月  26 2016 start-all.sh #
  -rwxr-xr-x. 1 ttshe root 1128 1月  26 2016 start-balancer.sh
  -rwxr-xr-x. 1 ttshe root 1401 1月  26 2016 start-dfs.cmd
  -rwxr-xr-x. 1 ttshe root 3734 1月  26 2016 start-dfs.sh #
  -rwxr-xr-x. 1 ttshe root 1357 1月  26 2016 start-secure-dns.sh
  -rwxr-xr-x. 1 ttshe root 1571 1月  26 2016 start-yarn.cmd
  -rwxr-xr-x. 1 ttshe root 1347 1月  26 2016 start-yarn.sh #
  -rwxr-xr-x. 1 ttshe root 1770 1月  26 2016 stop-all.cmd
  -rwxr-xr-x. 1 ttshe root 1462 1月  26 2016 stop-all.sh
  -rwxr-xr-x. 1 ttshe root 1179 1月  26 2016 stop-balancer.sh
  -rwxr-xr-x. 1 ttshe root 1455 1月  26 2016 stop-dfs.cmd
  -rwxr-xr-x. 1 ttshe root 3206 1月  26 2016 stop-dfs.sh #
  -rwxr-xr-x. 1 ttshe root 1340 1月  26 2016 stop-secure-dns.sh
  -rwxr-xr-x. 1 ttshe root 1642 1月  26 2016 stop-yarn.cmd
  -rwxr-xr-x. 1 ttshe root 1340 1月  26 2016 stop-yarn.sh #
  -rwxr-xr-x. 1 ttshe root 4295 1月  26 2016 yarn-daemon.sh #
  -rwxr-xr-x. 1 ttshe root 1353 1月  26 2016 yarn-daemons.sh #
  ```



## Hadoop运行模式

> 浏览官网 http://hadoop.apache.org/ 
> http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

### 本地运行模式

#### 官方grep案例

> 查阅官方案例
>
> By default, Hadoop is configured to run in a non-distributed mode, as a single Java process. This is useful for debugging.
>
> The following example copies the unpacked conf directory to use as input and then finds and displays every match of the given regular expression. Output is written to the given output directory.
>
> ```
>   $ mkdir input
>   $ cp etc/hadoop/*.xml input
>   $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar grep input output 'dfs[a-z.]+'
>   $ cat output/*
> ```

- 在hadoop目录下创建input文件夹，用于存放要分析的数据

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir input
```

- 将要分析的文件拷贝到input文件夹下

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cp etc/hadoop/*.xml input
```

- 运行hadoop命令，解析所有dfs开头的数据，同时将结果输出到output文件夹

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'
```

- 查看输出

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cd output/
[ttshe@hadoop101 output]$ ll
总用量 4
-rw-r--r--. 1 ttshe root 11 4月   7 13:21 part-r-00000
-rw-r--r--. 1 ttshe root  0 4月   7 13:21 _SUCCESS
[ttshe@hadoop101 hadoop-2.7.2]$ cat output/*
1	dfsadmin
```

#### 官方wordCount案例

- 创建一个wcinput文件夹，并添加一个文件，在该文件中添加要使用的数据素材

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ mkdir wcinput
[ttshe@hadoop101 hadoop-2.7.2]$ cd wcinput/
[ttshe@hadoop101 wcinput]$ touch wc.input
[ttshe@hadoop101 wcinput]$ cat wc.input 
hadoop yarn
hadoop mapreduce
study
deep-learning
ttshe
dd
atguigu
```

- 执行命令

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput
```

- 查看结果

```shell
[ttshe@hadoop101 hadoop-2.7.2]$ cat wcoutput/*
atguigu	1
dd	1
deep-learning	1
hadoop	2
mapreduce	1
study	1
ttshe	1
yarn	1
```




### 伪分布式模式



### 完全分布式模式





























