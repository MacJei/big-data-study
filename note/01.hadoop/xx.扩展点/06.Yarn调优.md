### YARN参数调优

- yarn-site.xml
- 情景描述
  - 总共7台机器，每天几亿条数据，数据源->Flume->Kafka->HDFS->Hive
- 面临问题
  - 数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，==内存用了不到50%==
  - 但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。基于这种情况有没有优化方案
- 解决办法
  - 内存利用率不够。这个一般是Yarn的2个配置造成的
    - 单个任务可以申请的最大内存大小
    - Hadoop单个节点可用内存大小
  - 调节这两个参数能提高系统内存的利用率
  - yarn.nodemanager.resource.memory-mb
    - 表示该节点上YARN可使用的物理内存总量
    - 默认是8192MB
    - 注意如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量
  - yarn.scheduler.maximum-allocation-mb
    - 单个任务可申请的最多物理内存量
    - 默认是8192MB

