## 基准测试



### HDFS写性能

- 向HDFS集群写10个128M的文件

```bash
[ttshe@hadoop102 hadoop-2.7.2]$  hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB

19/10/04 17:35:16 INFO fs.TestDFSIO: TestDFSIO.1.8
19/10/04 17:35:16 INFO fs.TestDFSIO: nrFiles = 10
19/10/04 17:35:16 INFO fs.TestDFSIO: nrBytes (MB) = 128.0
19/10/04 17:35:16 INFO fs.TestDFSIO: bufferSize = 1000000
19/10/04 17:35:16 INFO fs.TestDFSIO: baseDir = /benchmarks/TestDFSIO
19/10/04 17:35:17 INFO fs.TestDFSIO: creating control file: 134217728 bytes, 10 files
19/10/04 17:35:18 INFO fs.TestDFSIO: created control files for: 10 files
19/10/04 17:35:18 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8032
19/10/04 17:35:18 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8032
19/10/04 17:35:18 INFO mapred.FileInputFormat: Total input paths to process : 10
19/10/04 17:35:19 INFO mapreduce.JobSubmitter: number of splits:10
19/10/04 17:35:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1570170764880_0001
19/10/04 17:35:19 INFO impl.YarnClientImpl: Submitted application application_1570170764880_0001
19/10/04 17:35:19 INFO mapreduce.Job: The url to track the job: http://hadoop103:8088/proxy/application_1570170764880_0001/
19/10/04 17:35:19 INFO mapreduce.Job: Running job: job_1570170764880_0001
19/10/04 17:35:25 INFO mapreduce.Job: Job job_1570170764880_0001 running in uber mode : false
19/10/04 17:35:25 INFO mapreduce.Job:  map 0% reduce 0%
19/10/04 17:35:35 INFO mapreduce.Job:  map 20% reduce 0%
19/10/04 17:35:44 INFO mapreduce.Job:  map 20% reduce 7%
19/10/04 17:35:50 INFO mapreduce.Job:  map 30% reduce 7%
19/10/04 17:35:52 INFO mapreduce.Job:  map 37% reduce 7%
19/10/04 17:35:53 INFO mapreduce.Job:  map 37% reduce 10%
19/10/04 17:35:54 INFO mapreduce.Job:  map 77% reduce 10%
19/10/04 17:35:57 INFO mapreduce.Job:  map 80% reduce 10%
19/10/04 17:35:58 INFO mapreduce.Job:  map 83% reduce 10%
19/10/04 17:35:59 INFO mapreduce.Job:  map 100% reduce 100%
19/10/04 17:36:00 INFO mapreduce.Job: Job job_1570170764880_0001 completed successfully
19/10/04 17:36:00 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=855
		FILE: Number of bytes written=1304923
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2350
		HDFS: Number of bytes written=1342177360
		HDFS: Number of read operations=43
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=12
	Job Counters 
		Killed map tasks=1
		Launched map tasks=11
		Launched reduce tasks=1
		Data-local map tasks=8
		Rack-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=250002
		Total time spent by all reduces in occupied slots (ms)=22609
		Total time spent by all map tasks (ms)=250002
		Total time spent by all reduce tasks (ms)=22609
		Total vcore-milliseconds taken by all map tasks=250002
		Total vcore-milliseconds taken by all reduce tasks=22609
		Total megabyte-milliseconds taken by all map tasks=256002048
		Total megabyte-milliseconds taken by all reduce tasks=23151616
	Map-Reduce Framework
		Map input records=10
		Map output records=50
		Map output bytes=749
		Map output materialized bytes=909
		Input split bytes=1230
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=909
		Reduce input records=50
		Reduce output records=5
		Spilled Records=100
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=9328
		CPU time spent (ms)=82930
		Physical memory (bytes) snapshot=3074449408
		Virtual memory (bytes) snapshot=23327510528
		Total committed heap usage (bytes)=2098200576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1120
	File Output Format Counters 
		Bytes Written=80
19/10/04 17:36:00 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
# 写的测试结果
19/10/04 17:36:00 INFO fs.TestDFSIO:            Date & time: Fri Oct 04 17:36:00 CST 2019
19/10/04 17:36:00 INFO fs.TestDFSIO:        Number of files: 10
19/10/04 17:36:00 INFO fs.TestDFSIO: Total MBytes processed: 1280.0
# 吞吐量
19/10/04 17:36:00 INFO fs.TestDFSIO:      Throughput mb/sec: 21.999553134076965
19/10/04 17:36:00 INFO fs.TestDFSIO: Average IO rate mb/sec: 37.18858337402344
19/10/04 17:36:00 INFO fs.TestDFSIO:  IO rate std deviation: 32.58706395698196
19/10/04 17:36:00 INFO fs.TestDFSIO:     Test exec time sec: 42.302
19/10/04 17:36:00 INFO fs.TestDFSIO: 
```



### HDFS读性能

- 读取HDFS集群10个128M的文件

```bash
[ttshe@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB

19/10/04 17:39:54 INFO fs.TestDFSIO: TestDFSIO.1.8
19/10/04 17:39:54 INFO fs.TestDFSIO: nrFiles = 10
19/10/04 17:39:54 INFO fs.TestDFSIO: nrBytes (MB) = 128.0
19/10/04 17:39:54 INFO fs.TestDFSIO: bufferSize = 1000000
19/10/04 17:39:54 INFO fs.TestDFSIO: baseDir = /benchmarks/TestDFSIO
19/10/04 17:39:55 INFO fs.TestDFSIO: creating control file: 134217728 bytes, 10 files
19/10/04 17:39:55 INFO fs.TestDFSIO: created control files for: 10 files
19/10/04 17:39:55 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8032
19/10/04 17:39:55 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8032
19/10/04 17:39:55 INFO mapred.FileInputFormat: Total input paths to process : 10
19/10/04 17:39:56 INFO mapreduce.JobSubmitter: number of splits:10
19/10/04 17:39:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1570170764880_0002
19/10/04 17:39:56 INFO impl.YarnClientImpl: Submitted application application_1570170764880_0002
19/10/04 17:39:56 INFO mapreduce.Job: The url to track the job: http://hadoop103:8088/proxy/application_1570170764880_0002/
19/10/04 17:39:56 INFO mapreduce.Job: Running job: job_1570170764880_0002
19/10/04 17:40:00 INFO mapreduce.Job: Job job_1570170764880_0002 running in uber mode : false
19/10/04 17:40:00 INFO mapreduce.Job:  map 0% reduce 0%
19/10/04 17:40:07 INFO mapreduce.Job:  map 10% reduce 0%
19/10/04 17:40:08 INFO mapreduce.Job:  map 90% reduce 0%
19/10/04 17:40:09 INFO mapreduce.Job:  map 100% reduce 0%
19/10/04 17:40:11 INFO mapreduce.Job:  map 100% reduce 100%
19/10/04 17:40:11 INFO mapreduce.Job: Job job_1570170764880_0002 completed successfully
19/10/04 17:40:11 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=847
		FILE: Number of bytes written=1304885
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1342179630
		HDFS: Number of bytes written=80
		HDFS: Number of read operations=53
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=10
		Launched reduce tasks=1
		Data-local map tasks=8
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=54925
		Total time spent by all reduces in occupied slots (ms)=1526
		Total time spent by all map tasks (ms)=54925
		Total time spent by all reduce tasks (ms)=1526
		Total vcore-milliseconds taken by all map tasks=54925
		Total vcore-milliseconds taken by all reduce tasks=1526
		Total megabyte-milliseconds taken by all map tasks=56243200
		Total megabyte-milliseconds taken by all reduce tasks=1562624
	Map-Reduce Framework
		Map input records=10
		Map output records=50
		Map output bytes=741
		Map output materialized bytes=901
		Input split bytes=1230
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=901
		Reduce input records=50
		Reduce output records=5
		Spilled Records=100
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=2153
		CPU time spent (ms)=13300
		Physical memory (bytes) snapshot=2896904192
		Virtual memory (bytes) snapshot=23212634112
		Total committed heap usage (bytes)=2170028032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1120
	File Output Format Counters 
		Bytes Written=80
19/10/04 17:40:11 INFO fs.TestDFSIO: ----- TestDFSIO ----- : read
19/10/04 17:40:11 INFO fs.TestDFSIO:            Date & time: Fri Oct 04 17:40:11 CST 2019
19/10/04 17:40:11 INFO fs.TestDFSIO:        Number of files: 10
19/10/04 17:40:11 INFO fs.TestDFSIO: Total MBytes processed: 1280.0
19/10/04 17:40:11 INFO fs.TestDFSIO:      Throughput mb/sec: 376.9140164899882
19/10/04 17:40:11 INFO fs.TestDFSIO: Average IO rate mb/sec: 588.0826416015625
19/10/04 17:40:11 INFO fs.TestDFSIO:  IO rate std deviation: 270.15683018744534
19/10/04 17:40:11 INFO fs.TestDFSIO:     Test exec time sec: 16.109
19/10/04 17:40:11 INFO fs.TestDFSIO: 
```

- 知道读取和写入速度，可以知道业务场景每日可以处理数据的速率

  

### 删除测试数据

```bash
[ttshe@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -clean
```



### 用Sort程序评测MapReduce

- 使用RandomWriter来产生随机数，每个节点运行10个Map任务，每个Map产生大约1G大小的二进制随机数

```bash
[ttshe@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar randomwriter random-data
```

- 执行sort

```bash
[ttshe@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar sort random-data sorted-data
```

- 验证数据是否真正排好序

```bash
[ttshe@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar testmapredsort -sortInput random-data -sortOutput sorted-data
```

- 注意：测试集群不好不要尝试，容易崩