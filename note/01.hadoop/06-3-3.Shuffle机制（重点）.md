# Shuffe 机制（重点）

> 数据组合排序的过程

**Map方法之后**

![1](img/04.mr11.png)

- 重点
  - partition分区
    - 默认依据key的hashcode进行分区
    - 每个key-value计算出分区编号partition，作为元数据存储在环形缓冲区内
  - WritableComparable 排序
    - 当从环形缓存区溢出，写出到本地磁盘，对每个分区进行==**快速排序**==
    - 多个写在磁盘上的分区进行==**归并排序**==
    - 最终形成排序完成的分区





**Reduce方法之前**

![1](img/04.mr12.png)



- 重点

  - ReduceTask 去==拉取==相应的分区数据

    - 先存储在内存中
      - 溢出，写在磁盘上
    - 最后归并排序

  - 归并排序

    - Reduce处理数据之间需要进行分区汇总

    - 将同一分区的数据分块写在磁盘上

    - 每写一次磁盘，进行一次==归并排序==

    - 最后对磁盘上所有的该分区文件进行一次归并排序

      

## Partition 分区



### 分区概念

- 将统计的==结果按照要求输出==一个或者多个文件（分区）
- 需求扩展
  - 将结果按照手机归属地的省份不同输出到不同的文件中



### 默认执行分区

- 默认分区按照key的hashCode对ReduceTasks个数取模

- 用户无法控制key可以存到哪个分区中

- 默认实现代码

  - 需要在Driver中添加`job.setNumReduceTasks(n);`
    - n默认为1，直接返回0号分区，不执行 `HashPartitioner` 
    - 设置为 >1的值，执行默认`HashPartitioner` 类对象方法
  - MapTask中调用

  ```java
  @Override
  public void write(K key, V value) throws IOException, InterruptedException {
      collector.collect(key, value,
                        partitioner.getPartition(key, value, partitions));
  }
  ```

  - 执行`partitioner.getPartition` 方法获取分区编号

  ```java
  package org.apache.hadoop.mapreduce.lib.partition;
  
  import org.apache.hadoop.classification.InterfaceAudience;
  import org.apache.hadoop.classification.InterfaceStability;
  import org.apache.hadoop.mapreduce.Partitioner;
  
  /** Partition keys by their {@link Object#hashCode()}. */
  @InterfaceAudience.Public
  @InterfaceStability.Stable
  public class HashPartitioner<K, V> extends Partitioner<K, V> {
  
    /** Use {@link Object#hashCode()} to partition. */
    public int getPartition(K key, V value,
                            int numReduceTasks) {
      return (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks;
    }
  }
  ```



### 自定义执行分区



#### 步骤

- 自定义类继承Partitioner，重写getPartition方法
- 在job驱动类中，设置自定义的Partitioner
- 自定义Partition后，要根据自定义Partition的逻辑设置相应数量的ReduceTask



#### 示例

- 需求
  - 在自定义序列化Bean的示例中，对手机号码输出到不同的文件中，进行分区
- 期望输出的数据
  - 136,137,138,139开头的分别放在独立的文件中，其他开头的放在一个文件中
- 代码
  - 自定义实现类

```java
package com.stt.demo.mr.Ch07_partition;

import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;

/**
   * Partitioner 的 key 和 value 是 MapTask阶段 输出的结果类型
   */
public class NumberPartitioner extends Partitioner<Text,FlowBean> {
    @Override
    public int getPartition(Text key, FlowBean value, int numPartitions) {
        String phone = key.toString();
        // 默认输出到0分区
        if(StringUtils.isEmpty(phone)){return 0;}
        if(phone.startsWith("136")){return 1;}
        if(phone.startsWith("137")){return 2;}
        if(phone.startsWith("138")){return 3;}
        if(phone.startsWith("139")){return 4;}
        return 0;
    }
}
```

- job中的配置，设置NumReduceTask

```java
package com.stt.demo.mr.Ch07_partition;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import java.io.IOException;

import static com.stt.demo.mr.Constant.*;

public class FlowCountDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        args = new String[]{
            INPUT_PATH_PREFIX+"ch07/input.txt", 	OUTPUT_PATH_PREFIX+"ch07/output"};

        // 配置信息以及job对象
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);
        job.setJarByClass(FlowCountDriver.class);

        job.setMapperClass(FlowCountMapper.class);
        job.setReducerClass(FlowCountReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(FlowBean.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(FlowBean.class);

        FileInputFormat.setInputPaths(job,new Path(args[0]));
        FileOutputFormat.setOutputPath(job,new Path(args[1]));
        // 设置自定义 分区操作类
        job.setPartitionerClass(NumberPartitioner.class);
        // 设置分区的个数
        job.setNumReduceTasks(5);

        boolean re = job.waitForCompletion(true);
        System.exit(re ? 0 : 1);
    }
}
```



#### 小结

- ReduceTask数量 > getPartition的结果数
  - 如设置是setNumReduceTasks(5)，但是在代码中getPartition的最大值是4，那么会建立以空的输出文件part-000xx
- ReduceTask数量 = 1
  - getPartition 的返回结果不生效，最终输出一个part-00000文件
- getPartition > ReduceTask数量 > 1
  - 抛出==IO异常==，文件不存在
- 分区号必须从0开始
- setNumReduceTasks定义分区个数后，会生成设定个数的分区供写入数据



## WritableComparable 排序操作

- MapTask 和 ReduceTask 都会对数据==按照Key进行排序==
- 属于Hadoop框架的默认行为
- 所有应用程序都会被排序
- 默认排序按照==字典顺序排序==
- 排序算法是==快速排序==
- MapTask 过程进行的排序
  - 环形缓存区到达阈值时，对缓存区内的数据进行一次==快速排序==
  - 写到磁盘
  - 所有数据处理都写在磁盘后，对磁盘所有文件进行==归并排序==
- ReduceTask 过程进行的排序
  - 从MapTask 上远程拷贝相应的数据
    - 文件大小超过阈值，写到磁盘
      - 如果磁盘的文件的数目达到一定个数，进行一次==归并排序==，合成一个文件
    - 文件大小没有超过阈值，写到内存
      - 在内存中的数据继续读取各个MapTaskde 同一分区数据
      - 进行==合并==，超过阈值或设定数据大小，输出到磁盘
  - 所有数据拷贝完成，对磁盘的所有数据统一进行==归并排序==



### 分类

- 部分排序
  - MapReduce 根据输入记录的key对数据集合进行排序
  - 保证输出的每个文件内部有序
- 全排序
  - 本质上是一个部分排序，不过ReduceTask是1
  - 最终结果为一个文件，内部有序
  - 处理大型文件效率低
  - 没有用到MapReduce的并行架构
- 辅助排序
  - GroupingComparator分组
  - 在Reduce端对key进行分组
  - 在接收key为bean对象时，让一个或多个字段相同的key进入到一个reduce方法中
- 二次排序
  - 在定义排序过程中，对compareTo方法中对多个属性进行依次大小比对



### 自定义排序

- 使用bean作为key进行对象传输
- 该bean实现WritableComparable 接口，重写compareTo方法
  - 等价于Writable是序列化接口，在此基础上实现排序功能



#### 示例

- 基于自定义序列化的数据结果进行自定义排序
  - 按照手机总流量大小进行分区排序（全排序就是分区设置为1）
- 要求Mapper阶段的key为bean对象，value为Text类型（手机号）



- 实现FlowBean

```java
package com.stt.demo.mr.Ch08_WritableComparable;

import lombok.Data;
import org.apache.hadoop.io.WritableComparable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import java.util.Objects;

/**
 * 用于统计流量的bean
 */
@Data
public class FlowBean implements WritableComparable<FlowBean>{

	private long upFlow;
	private long downFlow;
	private long sumFlow;

	// 反序列化时，需要反射调用空参构造函数
	public FlowBean(){
		super();
	}

	public FlowBean(long upFlow, long downFlow){
		this.upFlow = upFlow;
		this.downFlow = downFlow;
		this.sumFlow = upFlow + downFlow;
	}

	// 写序列化方法
	@Override
	public void write(DataOutput out) throws IOException {
		out.writeLong(upFlow);
		out.writeLong(downFlow);
		out.writeLong(sumFlow);
	}

	// 反序列化方法
	@Override
	public void readFields(DataInput in) throws IOException {
		// 反序列化方法必须要和序列化方法的执行顺序保持一致
		this.upFlow = in.readLong();
		this.downFlow = in.readLong();
		this.sumFlow = in.readLong();
	}

	public String toString(){
		return upFlow+"\t"+downFlow+"\t"+sumFlow;
	}

	@Override
	public int compareTo(FlowBean o) {
		// 按照流量总大小倒叙排列
		if(Objects.equals(sumFlow,o.getSumFlow())){
			return 0;
		}
		return sumFlow > o.getSumFlow() ? -1 : 1;
	}
}
```

- 实现mapper

```java
package com.stt.demo.mr.Ch08_WritableComparable;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

/**
 * 注意这里的key是FlowBean ,value是Text类型的手机号
 */
public class FlowCountMapper extends Mapper<LongWritable,Text, FlowBean,Text> {

	FlowBean k = new FlowBean();
	Text v = new Text();

	@Override
	protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		// 获取一行数据
		String line = value.toString();
		// 切割字段
		String[] fields = line.split("\t");
		// 封装对象
		String phoneNum = fields[0];
		// 取得上流量和下流量
		long upFlow = Long.parseLong(fields[1]);
		long downFlow = Long.parseLong(fields[2]);
		long sumFlow = Long.parseLong(fields[3]);

		v.set(phoneNum);
		k.setDownFlow(downFlow);
		k.setUpFlow(upFlow);
		k.setSumFlow(sumFlow);

		context.write(k,v);
	}
}
```

- reducer

```java
package com.stt.demo.mr.Ch08_WritableComparable;


import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class FlowCountReducer extends Reducer<FlowBean,Text,Text,FlowBean> {
	@Override
	protected void reduce(FlowBean key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
		// 已经排好序，循环输出，避免总流量相同情况
		for(Text v : values){
			context.write(v,key);
		}
	}
}
```

- partitioner

```java
package com.stt.demo.mr.Ch08_WritableComparable;

import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;

/**
 * Partitioner 的 key 和 value 是 MapTask阶段 输出的结果类型
 */
public class NumberPartitioner extends Partitioner<FlowBean,Text> {
	@Override
	public int getPartition(FlowBean key, Text value, int numPartitions) {
		String phone = value.toString();
		if(StringUtils.isEmpty(phone)){
			// 默认输出到0分区
			return 0;
		}
		if(phone.startsWith("136")){
			return 1;
		}
		if(phone.startsWith("137")){
			return 2;
		}
		if(phone.startsWith("138")){
			return 3;
		}
		if(phone.startsWith("139")){
			return 4;
		}
		return 0;
	}
}
```

- driver

```java
package com.stt.demo.mr.Ch08_WritableComparable;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

import static com.stt.demo.mr.Constant.INPUT_PATH_PREFIX;
import static com.stt.demo.mr.Constant.OUTPUT_PATH_PREFIX;

public class FlowCountDriver {

	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

		args = new String[]{INPUT_PATH_PREFIX+"ch08/input.txt", OUTPUT_PATH_PREFIX+"ch08/output"};

		// 配置信息以及job对象
		Configuration conf = new Configuration();
		Job job = Job.getInstance(conf);
		job.setJarByClass(FlowCountDriver.class);

		job.setMapperClass(FlowCountMapper.class);
		job.setReducerClass(FlowCountReducer.class);

		job.setMapOutputKeyClass(FlowBean.class);
		job.setMapOutputValueClass(Text.class);

		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(FlowBean.class);

		FileInputFormat.setInputPaths(job,new Path(args[0]));
		FileOutputFormat.setOutputPath(job,new Path(args[1]));
		// 设置自定义 分区操作类
		job.setPartitionerClass(NumberPartitioner.class);
		// 设置分区的个数
		job.setNumReduceTasks(5);

		boolean re = job.waitForCompletion(true);
		System.exit(re ? 0 : 1);
	}

}
```



## Combiner 合并

- MR程序中Mapper和Reducer之外的一种组件
- Combiner组件的父类是Reducer
  - 等于是在MapTask阶段执行一次Reducer操作，对数据进行初步合并
- 与Reducer的区别
  - Combiner在每个MapTask所在的节点处运行
  - Reducer在接收全局的所有Mapper的输出结果
- 作用
  - 对每个MapTask的输出进行局部汇总
  - 减少网络IO传输
- 使用前提
  - 不能影响整体的业务逻辑
    - 如不能使用在求平均数的场景
  - Combiner的输出与Reducer的输入KV要对应



### 自定义Combiner实现

> 以基本的wordCount为例

- 自定义一个Combiner 继承Reducer，重写Reduce方法

```java
package com.stt.demo.mr.Ch09_Combiner;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class WordCombiner extends Reducer<Text,IntWritable,Text,IntWritable>  {
	
	IntWritable val = new IntWritable();
	
	@Override
	protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
		int sum = 0;
		for(IntWritable v : values){
			sum += v.get();
		}
		val.set(sum);
		context.write(key,val);
	}
}
```

- 在job中进行登记

```java
// 登记combiner
job.setCombinerClass(WordCombiner.class);
```

- 观察执行结果

![1](img/04.mr13.png)





## GroupingComparator 分组，辅助排序

- 辅助排序
- 可以用于实现topN的功能
- ==在reduce之前对key进行分组==
  - 通过key的bean的某些字段判断进行输出



### 实现

- 自定义类继承`WritableComparator`
- 重写`compare`方法，创建构造器

```java
@Override
public int compare(WritableComparable a, WritableComparable b) {
    // 比较的业务逻辑
    return result;
}

protected OrderGroupingComparator() {
    // 注意，这里必须传参true
    super(OrderBean.class, true);
}
```



### 示例

- 需求
  - 取出每个订单中成交金额最大的

| 订单id  | 商品id | 成交金额 |
| ------- | ------ | -------- |
| 0000001 | Pdt_01 | 222.8    |
| 0000001 | Pdt_02 | 33.8     |
| 0000002 | Pdt_03 | 522.8    |
| 0000002 | Pdt_04 | 122.4    |
| 0000002 | Pdt_05 | 722.4    |
| 0000003 | Pdt_06 | 232.8    |
| 0000003 | Pdt_02 | 33.8     |

- 输入数据

```text
0000001	Pdt_01	222.8
0000002	Pdt_05	722.4
0000001	Pdt_02	33.8
0000003	Pdt_06	232.8
0000003	Pdt_02	33.8
0000002	Pdt_03	522.8
0000002	Pdt_04	122.4
0000002	Pdt_03	522.8
0000002	Pdt_04	122.4
0000002	Pdt_03	522.8
0000002	Pdt_04	122.4
```

- 分析

  - 利用“订单id和成交金额”作为key
    - 将Map阶段读取到的所有订单数据按照id升序排序
    - 二次排序：id相同再按照金额降序排序
    - 发送到Reduce
  - 在Reduce端利用groupingComparator将订单id相同的kv聚合成组，取第一个即是该订单中最贵商品

  ![1](img/04.mr14.png)

- 代码

- 实现OrderBean

```java
package com.stt.demo.mr.Ch10_GroupingComparator;

import lombok.Data;
import org.apache.hadoop.io.WritableComparable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import java.util.Objects;

@Data
public class OrderBean implements WritableComparable<OrderBean>{

	private int orderId;
	private double price;

	@Override
	public void write(DataOutput out) throws IOException {
		out.writeInt(orderId);
		out.writeDouble(price);
	}

	@Override
	public void readFields(DataInput in) throws IOException {
		orderId = in.readInt();
		price = in.readDouble();
	}

	public String toString(){
		return orderId + "\t" + price;
	}

	@Override
	public int compareTo(OrderBean o) {
		if(Objects.equals(orderId,o.getOrderId())){
			if(Objects.equals(price,o.getPrice())){
				return 0;
			}
			// 按照价格降序
			return price > o.getPrice() ? -1 : 1;
		}
		// 按照orderId默认升序
		return orderId > o.getOrderId() ? 1 : -1;
	}
}
```

- mapper

```java
package com.stt.demo.mr.Ch10_GroupingComparator;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class OrderMapper extends Mapper<LongWritable,Text,OrderBean,NullWritable> {

	OrderBean k = new OrderBean();

	@Override
	protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

		//0000001	Pdt_01	222.8
		String[] lines = value.toString().split("\\s+");

		k.setOrderId(Integer.parseInt(lines[0]));
		k.setPrice(Double.parseDouble(lines[2]));

		context.write(k,NullWritable.get());
	}
}
```

- groupingComparator

```java
package com.stt.demo.mr.Ch10_GroupingComparator;

import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.io.WritableComparator;

import java.util.Objects;

public class OrderGroupingComparator extends WritableComparator {

	// 这里必须要传递true，用于实例化，否则报异常
	protected OrderGroupingComparator(){
		super(OrderBean.class,true);
	}

	@Override
	public int compare(WritableComparable a, WritableComparable b) {
		// 在相同的id处进行分组处理
		// 由于在MapTask阶段进行了二次排序
		// 到此处compare的是排序后的key对象
		OrderBean aOrder = (OrderBean) a;
		OrderBean bOrder = (OrderBean) b;

		if(Objects.equals(aOrder.getOrderId(),bOrder.getOrderId())){
			return 0;
		}
		return aOrder.getOrderId() > bOrder.getOrderId() ? 1 : -1;
	}
}
```

- reducer

```java
package com.stt.demo.mr.Ch10_GroupingComparator;

import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class OrderReducer extends Reducer<OrderBean,NullWritable,OrderBean,NullWritable> {

	@Override
	protected void reduce(OrderBean key, Iterable<NullWritable> values, Context context) throws IOException, InterruptedException {
		context.write(key,NullWritable.get());
	}
}
```

- driver

```java
// 添加OrderGroupingComparator
job.setGroupingComparatorClass(OrderGroupingComparator.class);
```



### 源码分析

- 在`OrderGroupingComparator` 的 `compare` 方法上打上断点
- 在`OrderReducer` 的 `reduce` 上打上断点
- 执行后，step out 得到调用方法

```java
Reducer
	run()
    	while(content.nextKey())
            reduce(...) // reduce执行

ReduceContextImpl：nextKey()  
    while(nextKeyIsSame){ // 
		nextKeyValue() // 如果下一个相同则nextKeyIsSame = true，跳过，继续比较
    }
	return nextKeyValue() // nextKeyIsSame == false , 
   
nextKeyValue()
   WritableComparator:compare // 比较2个orderBean的id是否相同
       nextKeyIsSame = true ? false; // 给nextKeyIsSame设置值
   return true; // 始终返回true
```

- `nextKeyValue` 方法解析
  - 始终返回true
  - 预先到达下一个键值对
  - 比较当前key和下一个key，设置`nextKeyIsSame`的值
  - 每次调用切换到下一个键值对
    - key的切换：`key = keyDeserializer.deserialize(key)`
    - value的切换：`value = valueDeserializer.deserialize(value)`
    - 切换之前对 `buffer` 进行了 `reset` 操作

```java
public boolean nextKeyValue() throws IOException, InterruptedException {    
 ...
    DataInputBuffer nextKey = input.getKey();
    currentRawKey.set(nextKey.getData(), nextKey.getPosition(), 
                      nextKey.getLength() - nextKey.getPosition());
    buffer.reset(currentRawKey.getBytes(), 0, currentRawKey.getLength());
    // 对key进行反序列化操作，原因是节点之间远程通信传递数据，同时切换到下一个key
    key = keyDeserializer.deserialize(key);
    DataInputBuffer nextVal = input.getValue();
    buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength()
                 - nextVal.getPosition());
    value = valueDeserializer.deserialize(value);

    currentKeyLength = nextKey.getLength() - nextKey.getPosition();
    currentValueLength = nextVal.getLength() - nextVal.getPosition();

    if (isMarked) {
        backupStore.write(nextKey, nextVal);
    }

    hasMore = input.next();
    if (hasMore) {
        nextKey = input.getKey();
        nextKeyIsSame = 
            // 调用比较器比较
            comparator.compare(currentRawKey.getBytes(), 0, 
                       currentRawKey.getLength(),
                       nextKey.getData(),
                       nextKey.getPosition(),
                       nextKey.getLength() - nextKey.getPosition()) == 0;
    } else {
        nextKeyIsSame = false;
    }
    inputValueCounter.increment(1);
    return true;
}
```



### 扩展topN

- 需求扩展，如果获取分组的最大前2项
- 修改OrderReducer
  - 此时打印了该分组的所有key-value值
    - 按道理应该key都是一样的
  - 为什么会打印所有?

```java
package com.stt.demo.mr.Ch10_GroupingComparator;

import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class OrderReducer extends Reducer<OrderBean,NullWritable,OrderBean,NullWritable> {

	@Override
	protected void reduce(OrderBean key, Iterable<NullWritable> values, Context context) throws IOException, InterruptedException {
		for(NullWritable v : values){
             // 底层迭代循环方法被改写
            // key的引用与value的迭代变化而变化，始终保持k-v对的形式输出
			context.write(key,NullWritable.get());
		}
	}
}
```



#### 分析

- 如何做到，因为`OrderGroupingComparator`处理后每次只会有一个分组的头部的key进入reduce方法

- 查看源码

  - 关注reduce内的循环，会调用迭代器的next()方法

  ```java
  // 注意循环
  for(NullWritable v : values)
  ```

  - reduce方法的执行，在Reducer中被执行

  ```java
  // Reducer：：run(Context context)
  while (context.nextKey()) {
      reduce(context.getCurrentKey(), context.getValues(), context);
  
  // 注意，values的传值是通过 context.getValues()
      // 查看context对象
  public abstract class Context 
      implements ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> {
  }
      // 对应的实现ReduceContextImpl，查看getValues()方法
      // 是一个自定义的迭代器实现
  public Iterable<VALUEIN> getValues() {
      return iterable;
  }
      // 该迭代器有声明
  private ValueIterable iterable = new ValueIterable();
      
      // 找到ValueIterable类的实现
  protected class ValueIterable implements Iterable<VALUEIN> {
      private ValueIterator iterator = new ValueIterator();
      @Override
      public Iterator<VALUEIN> iterator() {
        return iterator;
      } 
  }
  	// 分析ValueIterator 对象的实现方法
  protected class ValueIterator implements ReduceContext.ValueIterator<VALUEIN>
      
      // 查看next方法
  public VALUEIN next() {
  	...
      try {
          // 重点：这里进行了nextKeyValue 的操作，key和value被更新了
          nextKeyValue();
          return value;
      } catch (IOException ie) {
       ...
      }
  }
  ```



#### 实现

- 修改 reducer 代码

```java
protected void reduce(OrderBean key, Iterable<NullWritable> values, Context context){ 
    // 获取前2名
    int topN = 2;
    for(NullWritable v : values){
        if(topN <= 0){
            break;
        }
        context.write(key,NullWritable.get());
        topN --;
    }
}
```

