# Hadoop相关总结

- Hadoop默认不支持LZO压缩，如果需要支持LZO压缩，需要添加jar包，并在hadoop的cores-site.xml文件中添加相关压缩配置
- Hadoop常用端口号
  - 50070
  - 19888
  - 8088
  - 9000
  - 8032
  - 8020
  - 50090
  - 50010
- Hadoop配置文件以及简单的Hadoop集群搭建
- HDFS读流程和写流程
- MapReduce的Shuffle过程及Hadoop优化（包括：压缩、小文件、集群优化）
  - map方法之后，reduce方法之前
  - 先到分区；环形缓冲区（100M）；进行分区和排序（80%进行溢写）；排序，快排算法；排序规则，key的索引按照字典顺序排序；对溢写的结果进行归并排序，放入相应的分区；reduce进行数据拉取，先放入内存中，不足后放入磁盘...
  - 在整个shuffle过程中有哪些优化
    - 数据在环形缓冲区，可以从100M调整到200M
    - 溢写比例从80%调整到90%
    - 目的，减少溢写的次数
    - 大量的溢写文件需要归并
      - 默认个数是10个
      - 增大merge的个数，15个到20个，前提是机器的性能可以
    - 归并的过程中可以对数据进行combiner
      - 注意求和汇总不影响
      - 求平均会影响
    - 归并之后，在磁盘上等待传输
      - 为了减少磁盘存储，进行压缩
    - 在MR中那些可以进行压缩
      - Map输入
        - 需要支持切片
      - Map输出
        - 速度尽可能的快
        - snappy，lzo
      - Reduce输出
        - 如果要永久的保存，需要压缩率高，gzip
        - 如果输出作为下一个MR的输入，考虑压缩支持切片
  - Reduce端
    - 一次默认拉取5个
    - 调整增加拉取的个数，前提是机器性能满足
    - 增大拉取的内存
  - MapTask默认的资源
    - ==mapreduce.map.memory.mb==
      - 资源上限 1G
      - 开发过程中可以扩大到4-6G
    - mapreduce.map.cpu.vcores
      - cpu  的核数，默认1
    - 失败重试的次数，默认4
  - ReduceTask默认的资源
    - ==maperduce.reduce.memory.mb==
      - 资源上限 1G
      - 开发过程中可以扩大到4-6G
    - mapreduce.reduce.cpu.vcores
      - cpu  的核数，默认1
    - 失败重试的次数，默认4
  - HDFS 小文件
    - Har归档
      - 对外一个整体，对内是小文件
      - 减少namenode的压力
    - 自定义MR，SequenceFile
    - JVM重用
    - ...
- Yarn的Job提交流程
  - 提交xml，jar，切片配置
  - 运行AppMaster
  - 排队，放入任务队列中
  - NManger定期领取任务
    - 将任务放入容器container
      - 获取相应的内存和资源
    - 启动AppMaster
    - 读取切片配置，发现需要执行2个MapTask
    - 给另外2个NM发送MapTask进行执行(也需要Container容器，分配内存和资源)
      - 计算结果，放入分区结果
    - Reduce从分区获取结果，进行处理，计算完成放入HDFS
- Yarn的默认调度器、调度器分类、以及他们之间的区别
  - FIFO调度
  - 容量调度
    - 默认调度
  - ==公平调度==
  - 区别
    - FIFO属于单队列，同一时间只有一个执行
    - 容量，多队列，每个队列同一时间只有一个执行，并发数是队列的个数
    - 公平，多队列，每个队列同一时间有多个执行，并发度大于等于队列个数
      - 谁缺额越多执行谁
  - 场景
    - 对并发要求高，cpu容量比较大，服务器性能好，选择公平调度
    - 中小型服务器一般，选择容量调度
- HDFS存储多目录
  - 在开发中需要变成多目录，预留多个插槽，防止磁盘满了需要重新配置重启
- Hadoop参数调优
  - NameNode和DataNode的心跳值需要调整
  - 镜像文件和编辑日志要分开
- 项目经验之基准测试
  - hdfs测试
    - 读性能，写性能
  - mr的计算能力，排序
  - kafka测试
  - flume监控