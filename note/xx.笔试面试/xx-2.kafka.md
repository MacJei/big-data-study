kafka挂了怎么办，数据重复的问题

# kafka搭建

- 根据日常维护数据量，搭建了3台

- kafka的数据保存7天，分区一般5-8个，副本数2
- 日常每日维护数据量在60G左右，7天数据+副本+25%约等于1T，考虑到以后的业务增长给了4T
- 机器数量：3台
- 日活10万，300条，2K= 60G
- 100 000 * 300 / 24 / 3600 = 230条/s  平均 230*2k
- 高峰期是10倍 2300 / s ，每条数据2k-3k 4.6M-6.9M/s
- 低谷期40/s
- 负责启动主题，用户行为，任务主题，勋章主题，消息通知，故障日志等
- 针对生产者，我们设置ack为1，leader收到消息后，回应生产者offset，当然可以设置为-1，这样的话可以保证消息完全不丢失（leader和follower都接收到数据）
- 针对消费者，配置partition.assignment.strategy使用range的分区策略进行消费
  - 本质是一个线程一个分区，不同的消费者可能不同的线程，那么消费的分区也是不同的
  - 当然可以选择roundRobin 轮询的方式，不过roundRobin要求消费者的消费线程数必须相同，否则会有数据倾斜，每个消费者订阅的主题必须相同，range没有这些限制，不需要对消费者的线程数全部相同
- kafka还有一个关于ISR同步的问题
  - 在follower会与leader进行数据的同步
  - 当leader挂了，会找一个在ISR in sync replication中选择一个follower
    - 如何选择follower，通过判断leader和follower中的延时条数和延时时间最少的，后面延时条数会丢失
  - 0.9版本中在一定时间默认是10s内如果与leader的数据差距大，则会放入OSR中
- 关于优化：kafka可以设置多目录，用于提高吞吐量
- 内存一般调整为4-5g